\chapter{Implementation & System Architecture}

% TODO use abreviations from list
% TODO add references

This chapter details the design and implementation of the prototype system, a practical realization of the conceptual framework for GenAI-driven security automation introduced in Chapter 4. The work is impemented through two distinct but interconnected codebases: a cloud-native infrastructure for the generative AI backend, and a Python-based application that orchestrates the analysis and policy generation workflow.

The primary goal of this implementation is to empirically validate the central hypothesis of the theoretical framework: that a hybrid approach, combining traditional static analysis with advanced Large Language Model (LLM) capabilities, can significantly enhance the automation of security policy generation for Infrastructure-as-Code (IaC). This chapter will demonstrate how the system architecture directly maps to the four-layered conceptual model—Data Ingestion, Data Processing, Code Generation, and Validation—and realizes the core principles of leveraging Retrieval-Augmented Generation (RAG) for contextual accuracy and integrating a Human-in-the-Loop (HITL) for safety and oversight.

We will first present the high-level architecture and the technology stack chosen to satisfy the functional requirements of a robust, scalable, and reproducible security pipeline. Subsequently, the chapter will provide a detailed examination of both the cloud infrastructure, deployed via Terraform, and the Python prototype, focusing on the specific modules that implement the core logic of the system. The chapter will conclude by illustrating the end-to-end workflow, from the initial analysis of a Terraform file to the generation and validation of a corresponding Rego security policy, thereby providing a comprehensive account of the system's practical application.

\section{Design Objectives & Functional Requirements}

% Refined Research Questions:


%    * RQ1 (Effectiveness and Automation): How can Generative AI technologies be effectively leveraged to automate security policy generation and management across
%      hyperscale cloud platforms?
%    * RQ2 (Architecture and Orchestration): What specific architectural patterns and validation mechanisms are required to ensure trust, accuracy, and effective
%      multi-cloud orchestration in GenAI-driven security automation?
%    * RQ3 (Measurement and Validation): How can the effectiveness of GenAI-driven security automation be quantitatively measured and validated, particularly in terms
%      of accuracy, reliability, and efficiency gains?
%    * RQ4 (Human-in-the-Loop): What is the optimal balance between automation and human oversight (Human-in-the-Loop) to maximize security outcomes and mitigate the
%      risks of GenAI-driven policy generation?

%   These questions are more closely aligned with the language and focus of your exposé.

The practical implementation of the prototype is guided by a set of specific design objectives and functional requirements. These objectives are derived directly from the core research questions and serve to translate the high-level scientific inquiry into concrete, measurable goals for the system. This section outlines these requirements and explicitly maps them to the corresponding research questions they are designed to address.

The primary design objectives for the prototype are as follows:

\begin{itemize}
    \item \textbf{Automated Policy Generation (RQ1):} The system must be able to automatically generate syntactically correct and logically sound security policies (in Rego) based on vulnerability findings in IaC (Terraform) files. This directly addresses the central question of how GenAI can be leveraged for automation.
    \item \textbf{Hybrid Analysis (RQ2):} The system must implement a hybrid analysis engine that combines traditional static analysis (SAST) with GenAI-driven contextual analysis. This is a core architectural requirement for exploring how to achieve accurate and trustworthy results.
    \item \textbf{Reproducible Infrastructure (RQ2):} The entire cloud-native backend, including the knowledge base and the GenAI service integration, must be defined and deployed using IaC (Terraform). This ensures the architecture is reproducible and verifiable.
    \item \textbf{High-Fidelity Policy Generation (RQ3):} The system must aim for a high degree of accuracy in its generated policies, with a target of \textbf{≥ 95\%} of generated policies being effective in mitigating the identified vulnerability. This provides a quantitative measure to validate the system's effectiveness.
    \item \textbf{Automated Validation (RQ3):} The system must include a multi-stage validation pipeline to automatically check generated policies for syntactic correctness and to ensure they do not introduce new security flaws. This is a key mechanism for measuring and ensuring the reliability of the output.
    \item \textbf{Human-in-the-Loop (HITL) Integration (RQ4):} The system must be designed to support a HITL workflow, allowing for human review and approval of generated policies, particularly for high-severity findings. This directly addresses the question of balancing automation with human oversight.
    \item \textbf{CI/CD Integration (RQ1, RQ4):} The prototype must be designed for seamless integration into a standard CI/CD pipeline. This demonstrates its practical utility in a modern DevOps environment and provides a mechanism for enforcing the HITL workflow.
\end{itemize}

The following table provides a clear mapping between these functional requirements and the research questions:

\begin{table}[h!]
\centering
\begin{tabular}{|l|p{6cm}|l|}
\hline
\textbf{Functional Requirement} & \textbf{Description} & \textbf{Corresponding RQ(s)} \\
\hline
Automated Policy Generation & Generate Rego policies from Terraform vulnerabilities. & RQ1 \\
\hline
Hybrid Analysis & Combine SAST and GenAI for deep, contextual analysis. & RQ2 \\
\hline
Reproducible Infrastructure & Define all cloud components as code (Terraform). & RQ2 \\
\hline
High-Fidelity Policy Generation & Achieve ≥ 95\% effectiveness in generated policies. & RQ3 \\
\hline
Automated Validation & Automatically verify syntax and security of generated policies. & RQ3 \\
\hline
Human-in-the-Loop (HITL) & Enable human review and approval of generated artifacts. & RQ4 \\
\hline
CI/CD Integration & Allow the system to be triggered and run within a CI/CD pipeline. & RQ1, RQ4 \\
\hline
\end{tabular}
\caption{Mapping of Functional Requirements to Research Questions}
\label{tab:req_rq_mapping}
\end{table}

This structured approach ensures that the implementation of the prototype directly contributes to answering the core research questions of this thesis.

\section{Technology & Tooling Stack}

The selection of the technology and tooling stack for this project was a deliberate process, guided by the design objectives of creating a reproducible, scalable, and industry-relevant prototype. The choices reflect a modern, cloud-native approach, emphasizing managed services and open standards to validate the conceptual framework effectively. This section briefly justifies the key technologies that constitute the system's foundation. The chosen stack is summarized in Table~\ref{tab:tech_stack}.

\begin{table}[h!]
\centering
\begin{tabular}{|l|l|p{7cm}|}
\hline
\textbf{Component} & \textbf{Technology} & \textbf{Justification} \\
\hline
Cloud Platform & Amazon Web Services (AWS) & As the leading hyperscale cloud provider, AWS offers a mature and extensive ecosystem of services, robust APIs, and comprehensive documentation. Its managed AI service, AWS Bedrock, is central to the project's architecture. \\
\hline
Generative AI Service & AWS Bedrock & Provides API access to a variety of high-performance foundation models without the operational overhead of self-hosting. This aligns with the objective of a fully-managed GenAI pipeline and allows the research to focus on application logic rather than MLOps. The Anthropic Claude model was selected for its advanced reasoning capabilities and large context window. \\
\hline
Infrastructure as Code & HashiCorp Terraform & As the de-facto industry standard for IaC, Terraform's declarative syntax and cloud-agnostic nature ensure the approach is both reproducible and broadly applicable. It is the input format for the security analysis pipeline. \\
\hline
Policy as Code & OPA (Rego) & The Open Policy Agent (OPA) is a CNCF-graduated project and a general-purpose policy engine. Its declarative language, Rego, is purpose-built for expressing policies over complex JSON/YAML data, making it an ideal target for generating preventative controls for IaC. \\
\hline
Orchestration & Python 3.12 & Python's extensive ecosystem, including the Boto3 library for AWS, and its strength in scripting and automation make it the ideal choice for orchestrating the multi-stage workflow, which involves invoking external scanners, calling cloud APIs, and managing file I/O. \\
\hline
CI/CD & GitHub Actions & Provides a tightly integrated platform for version control and workflow automation. It enables the seamless implementation of a CI/CD pipeline to trigger scans, orchestrate the policy generation and validation, and manage the Human-in-the-Loop approval process. \\
\hline
\end{tabular}
\caption{Technology and Tooling Stack}
\label{tab:tech_stack}
\end{table}

\section{High-Level Architecture}

This section presents the high-level architecture of the GenAI-driven security automation framework. The design translates the conceptual model from Chapter 4 into a concrete system that orchestrates static analysis tools, generative AI, and validation workflows. The architecture is best understood as a sequential data pipeline, illustrated in Figure~\ref{fig:component_diagram}, which depicts the primary components and their interactions.

\begin{figure}[h!]
\centering
% Placeholder for component diagram
\caption{High-Level Component Diagram}
\label{fig:component_diagram}
\end{figure}

The end-to-end data flow, visualized in Figure~\ref{fig:data_flow_diagram}, begins with a developer committing Terraform code and culminates in a validated Rego policy.

\begin{figure}[h!]
\centering
% Placeholder for data-flow diagram
\caption{End-to-End Data Flow Diagram}
\label{fig:data_flow_diagram}
\end{figure}

The system's responsibilities are segregated into four logical tiers, directly corresponding to the layers of the conceptual framework. The process begins at the \textbf{Data Ingestion Layer}, which serves as the entry point, receiving Terraform configurations from a CI/CD trigger, parsing the IaC files, and preparing them for analysis. From there, the artifacts are passed to the \textbf{Data Processing Layer}, the core analysis engine. This layer first subjects the IaC to a baseline scan using a traditional SAST tool (Checkov) to identify known vulnerability patterns. The resulting report, along with the original IaC, is then fed into the GenAI Analysis Engine (AWS Bedrock) for a deep, contextual analysis to identify complex misconfigurations and reduce false positives. Subsequently, the \textbf{Code Generation Layer} takes the enriched vulnerability report as input, queries the RAG-enabled knowledge base for relevant security best practices, and prompts the LLM via the AWS Bedrock API to generate a corresponding Rego policy. Finally, the \textbf{Validation Layer} acts as a quality gate. Here, the newly generated Rego policy is subjected to automated checks, including syntax validation with the OPA parser and a security self-scan, before being presented to the Human-in-the-Loop for final approval.

This layered architecture ensures a clear separation of concerns and provides a robust, end-to-end workflow for translating identified risks in IaC into validated, enforceable security policies.

\section{Cloud-Infrastructure Codebase (IaC)}

\subsection{Repository Layout}
% Explain folder structure shown in the screenshot (e.g., terraform/database, terraform/knowledge_base).

\subsection{Core Terraform Modules}
% Describe Bedrock, knowledge-base S3 buckets, Lambda warmers, IAM roles, VPC endpoints, etc.

\subsection{Prompt & Knowledge-Base Management}
% Outline prompt-versioning strategy and RAG storage schema.

\subsection{Security Controls}
% Shared-responsibility matrix, least-privilege IAM, S3 encryption, logging.

\subsection{Deployment Workflow}
% GitHub Actions “deploy_knowledgebase.yml", artefact promotion, environment parity.

\section{Prototype Application Codebase}

\subsection{Repository Layout}
% Summarise folders in src/,config/, tests/.

\subsection{Module-Level Description}
% - analyzer: static-scanner wrapper
% policy_generator: RAG prompt builder & Bedrock client
% validator: Rego syntax & semantic checks
% metrics: coverage, false-positive reduction
% Explain main control loop in main.py.

\subsection{Testing Strategy}
% PyTest layout, fixture design, Cl gate, coverage targets.

\subsection{Packaging & Dependency Management}
% requirements.txt, Dockerfile (if any), version pinning.

\section{End-to-End Workflow}
% Step-by-step sequence from Terraform push → static scan → GenAl analysis → policy commit → Rego evaluation. A sequence diagram is helpful here.

\section{CI/CD & DevSecOps Integration}
% - GitHub Actions pipelines (deploy_knowledgebase, destroy_knowledgebase, prototype checks)
% Quality gates (unit tests, Rego tests, policy coverage ≥ 90%).

\section{Observability & Runtime Telemetry}
% Metrics (MTTD, policy-generation latency), structured logging (JSON Logs + AWS CloudWatch), dashboards.

\section{Limitations & Trade-offs}
% Model latency vs. cost, Terraform state confidentiality, policy false-negatives, Bedrock service quotas.

\section{Summary}
% Recap key design choices and link forward to the Results chapter.