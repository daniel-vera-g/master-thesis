
%----------------------------------------------------------------------------------------
%	ABSTRACT PAGE
%----------------------------------------------------------------------------------------

\begin{abstract}
\addchaptertocentry{\abstractname} % Add the abstract to the table of contents
This thesis addresses the challenge of automating cloud security policy generation using Generative AI (GenAI), focusing on the integration of Large Language Models (LLMs) with traditional static analysis in a Retrieval-Augmented Generation (RAG) framework. Motivated by the need for scalable, context-aware, and reliable security automation in complex cloud environments, the research follows a Design Science Research paradigm, progressing through literature review, conceptual framework development, prototype implementation, and empirical evaluation.

The primary contributions are: (1) a novel conceptual framework that combines the speed of static analysis with the contextual reasoning of LLMs, grounded in curated data and validated through a Human-in-the-Loop (HITL) process; and (2) a functional prototype empirically evaluated on Infrastructure-as-Code for AWS using Terraform and tfsec. Results demonstrate measurable improvements in policy efficacy, generation speed, and contextual detection quality compared to static-only baselines, while highlighting the necessity of human oversight for nuanced decision-making.

The findings advance the shift-left security paradigm by providing a blueprint for embedding automated, preventative controls early in the development lifecycle. Limitations include the narrow technology focus and prototype scope, suggesting future research directions in broader stack generalization and GenAI optimization. This work offers a practical guide for integrating GenAI into DevSecOps pipelines, bridging the gap between rapid development and robust security assurance.
\end{abstract}

