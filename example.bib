
@article{weedon_generative_2023,
	title = {Generative {AI}: security implications for business automation},
	volume = {2023},
	issn = {1353-4858, 1872-9371},
	shorttitle = {Generative {AI}},
	url = {http://www.magonlinelibrary.com/doi/10.12968/S1353-4858%2823%2970045-7},
	doi = {10.12968/S1353-4858(23)70045-7},
	abstract = {AI tools such as ChatGPT certainly appear to offer significant benefits to organisations looking to save costs and improve efficiency. But the technology is being adopted with an enthusiasm that leaves little room for the careful consideration of potential security vulnerabilities. So how do you embrace this revolution without putting yourself at risk?},
	language = {en},
	number = {9},
	urldate = {2024-09-07},
	journal = {Network Security},
	author = {Weedon, Scott},
	month = sep,
	year = {2023},
	pages = {S1353--4858(23)70045--7},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/3ICS935N/ba42b88132000be4ea8cf6b9a119f6b71d0b07f1.html:text/html},
}

@misc{haryanto_secgenai_2024,
	title = {{SecGenAI}: {Enhancing} {Security} of {Cloud}-based {Generative} {AI} {Applications} within {Australian} {Critical} {Technologies} of {National} {Interest}},
	shorttitle = {{SecGenAI}},
	url = {http://arxiv.org/abs/2407.01110},
	doi = {10.48550/arXiv.2407.01110},
	abstract = {The rapid advancement of Generative AI (GenAI) technologies offers transformative opportunities within Australia's critical technologies of national interest while introducing unique security challenges. This paper presents SecGenAI, a comprehensive security framework for cloud-based GenAI applications, with a focus on Retrieval-Augmented Generation (RAG) systems. SecGenAI addresses functional, infrastructure, and governance requirements, integrating end-to-end security analysis to generate specifications emphasizing data privacy, secure deployment, and shared responsibility models. Aligned with Australian Privacy Principles, AI Ethics Principles, and guidelines from the Australian Cyber Security Centre and Digital Transformation Agency, SecGenAI mitigates threats such as data leakage, adversarial attacks, and model inversion. The framework's novel approach combines advanced machine learning techniques with robust security measures, ensuring compliance with Australian regulations while enhancing the reliability and trustworthiness of GenAI systems. This research contributes to the field of intelligent systems by providing actionable strategies for secure GenAI implementation in industry, fostering innovation in AI applications, and safeguarding national interests.},
	urldate = {2024-08-26},
	publisher = {arXiv},
	author = {Haryanto, Christoforus Yoga and Vu, Minh Hieu and Nguyen, Trung Duc and Lomempow, Emily and Nurliana, Yulia and Taheri, Sona},
	month = jul,
	year = {2024},
	note = {arXiv:2407.01110 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
	annote = {Comment: 10 pages, 4 figures, 9 tables, submitted to the 2024 11th International Conference on Soft Computing \& Machine Intelligence (ISCMI 2024)},
	annote = {Comment: 10 pages, 4 figures, 9 tables, submitted to the 2024 11th International Conference on Soft Computing \& Machine Intelligence (ISCMI 2024)},
	annote = {Comment: 10 pages, 4 figures, 9 tables, submitted to the 2024 11th International Conference on Soft Computing \& Machine Intelligence (ISCMI 2024)},
	file = {arXiv Fulltext PDF:/Users/d.veragilliard/Zotero/storage/Y87CT6NW/Haryanto et al. - 2024 - SecGenAI Enhancing Security of Cloud-based Genera.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/7S4ZGDKG/2407.html:text/html},
}

@article{senior_software_engineer_cisco_systems_inc_usa_next-gen_2024,
	title = {Next-{Gen} {Firewalls}: {Enhancing} {Cloud} {Security} with {Generative} {AI}},
	volume = {3},
	shorttitle = {Next-{Gen} {Firewalls}},
	url = {https://www.onlinescientificresearch.com/articles/nextgen-firewalls-enhancing-cloud-security-with-generative-ai.pdf},
	doi = {10.47363/JAICC/2024(3)404},
	abstract = {Next-generation firewalls are available and use machine learning and generative modeling to enhance the detection of hard-to-detect cyber threats. These systems incorporate advanced security controls, policies, and protocols with Layer 7 of the OSI model. This chapter updates these steep AI-based protection systems and applications.},
	number = {4},
	urldate = {2025-03-31},
	journal = {J Arti Inte \& Cloud Comp},
	author = {{Senior Software Engineer, Cisco Systems Inc, USA} and Lekkala, Seshagirirao},
	month = aug,
	year = {2024},
	pages = {1--9},
	annote = {[TLDR] Next-generation firewalls are available and use machine learning and generative modeling to enhance the detection of hard-to-detect cyber threats to update steep AI-based protection systems and applications.},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/D9LSZDNH/4373239ca9de9d5ab0dbf0b2e60bf1885beca545.html:text/html},
}

@article{patel_generative_2025,
	title = {Generative {AI} for {Automated} {Security} {Operations} in {Cloud} {Computing}},
	copyright = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10849302/},
	doi = {10.1109/ICAIC63015.2025.10849302},
	abstract = {New opportunities in cloud computing have brought many new risks that require effective protection of dynamic distributed environments. Introducing a new formative technology, generative AI, to cloud security has far-reaching benefits for automating threat detection, real-time incident addressing, and vulnerability management. This paper focuses on extending generative AI with cloud security tools like AWS GuardDuty and Google Cloud Security Command Center; the contemplation of accuracy enhancement and response efficiency highlights its aim. Concerning actual applications such as SOAR systems, the study demonstrates how media industry giants, such as Netflix and JPMorgan Chase, have used AI to minimize risk factors while increasing operational efficiency. The paper also discusses the significant increase in response time, enhanced detection accuracy, and the shift to proactive security strategies brought by generative AI. Drawing attention to AI systemsâ€™ opportunities, the study examines the subsequent issues connected with AI applications, including over-dependence on AI tools, adversarial risk to models, and the complex nature of decisionmaking in the context of AI systems. The present study also highlights the importance of generative AI in strengthening the defense of the cloud environment, but, at the same time, it recognizes the significance of preventive efforts and planned action plans to manage these technologies efficiently.},
	urldate = {2025-03-31},
	journal = {2025 IEEE 4th International Conference on AI in Cybersecurity (ICAIC)},
	author = {Patel, Advait and Pandey, Pravin and Ragothaman, Hariharan and Molleti, Ramasankar and Peddinti, Diwakar Reddy},
	month = feb,
	year = {2025},
	note = {Conference Name: 2025 IEEE 4th International Conference on AI in Cybersecurity (ICAIC)
ISBN: 9798331518882
Place: Houston, TX, USA
Publisher: IEEE},
	pages = {1--7},
	annote = {[TLDR] This paper focuses on extending generative AI with cloud security tools like AWS GuardDuty and Google Cloud Security Command Center, and discusses the significant increase in response time, enhanced detection accuracy, and the shift to proactive security strategies brought by generative AI.},
	annote = {[TLDR] This paper focuses on extending generative AI with cloud security tools like AWS GuardDuty and Google Cloud Security Command Center, and discusses the significant increase in response time, enhanced detection accuracy, and the shift to proactive security strategies brought by generative AI.},
}

@article{seth_ai_2025,
	title = {{AI} and {Generative} {AI}-{Driven} {Automation} for {Multi}-{Cloud} and {Hybrid} {Cloud} {Architectures}: {Enhancing} {Security}, {Performance}, and {Operational} {Efficiency}},
	copyright = {https://doi.org/10.15223/policy-029},
	shorttitle = {{AI} and {Generative} {AI}-{Driven} {Automation} for {Multi}-{Cloud} and {Hybrid} {Cloud} {Architectures}},
	url = {https://ieeexplore.ieee.org/document/10903928/},
	doi = {10.1109/CCWC62904.2025.10903928},
	abstract = {The emergence of cloud and hybrid cloud structures presents eCommerce firms with the adaptability and robustness needed to manage expansion and varying user requirements effectively. However, this also brings about challenges concerning security enhancements, distribution of workloads, and cost-effectiveness optimization. Traditional cloud management models often need help to meet these evolving demands efficiently. This research presents a system that leverages Artificial Intelligence (AI) and Generative AI (Gen AI) to effectively automate and enhance cloud and hybrid infrastructures for ecommerce websites. The system adapts infrastructure to traffic times like holidays or sales events by utilizing AI to scale resources as needed. It conserves resources during low user activity periods such as overnight. Ensuring optimal system performance and availability during peak traffic times while cutting costs during traffic periods is essential for cost-effectiveness and efficient resource management. In addition, AI-powered security automation safeguards against changing cyber dangers, and compliance automation guarantees conformity with rules like PCI DSS for payment handling. This report also delves into merging Gen AI into cloud coordination systems, facilitating workflows, and enhancing eCommerce processes. The outcome is a significant drop in operational expenses, a quicker service rollout, and decreased security breaches. Through real-world eCommerce case studies, this paper provides actionable insights for cloud engineers and architects on leveraging AI-driven cloud management to enhance performance, security, and cost-efficiency in multi-cloud and hybrid environments, ensuring seamless user experiences and business continuity.},
	urldate = {2025-04-08},
	journal = {2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC)},
	author = {Seth, Dhruv Kumar and Ratra, Karan Kumar and Sundareswaran, Aneeshkumar P},
	month = jan,
	year = {2025},
	note = {Conference Name: 2025 IEEE 15th Annual Computing and Communication Workshop and Conference (CCWC)
ISBN: 9798331507695
Place: Las Vegas, NV, USA
Publisher: IEEE},
	pages = {00784--00793},
	annote = {[TLDR] This research presents a system that leverages Artificial Intelligence (AI) and Generative AI (Gen AI) to effectively automate and enhance cloud and hybrid infrastructures for ecommerce websites, resulting in a significant drop in operational expenses, a quicker service rollout, and decreased security breaches.},
	annote = {[TLDR] This research presents a system that leverages Artificial Intelligence (AI) and Generative AI (Gen AI) to effectively automate and enhance cloud and hybrid infrastructures for ecommerce websites, resulting in a significant drop in operational expenses, a quicker service rollout, and decreased security breaches.},
}

@article{khanna_enhancing_2024,
	title = {{ENHANCING} {CLOUD} {SECURITY} {WITH} {GENERATIVE} {AI}: {EMERGING} {STRATEGIES} {AND} {APPLICATIONS}},
	volume = {3},
	issn = {2295-5152},
	shorttitle = {{ENHANCING} {CLOUD} {SECURITY} {WITH} {GENERATIVE} {AI}},
	url = {https://iaeme.com/Home/article_id/JARET_03_01_021},
	abstract = {This article explores the potential of generative AI for enhancing cloud security. With the rapid adoption of cloud technologies and the increasing sophistication of cyber threats, traditional security measures often struggle to keep pace. Generative AI, with its ability to learn from vast amounts of data and generate intelligent outputs, presents a powerful tool to address these challenges. The article delves into the fundamentals of generative AI and its specific applications in cloud security, including anomaly detection, threat intelligence, and automated response mechanisms. It also discusses the challenges and future directions in this field, highlighting the need for large and diverse datasets, addressing adversarial attacks, improving model interpretability, and considering the ethical implications of using generative AI in cloud security.},
	language = {en},
	number = {1},
	urldate = {2025-04-08},
	journal = {JARET},
	author = {Khanna, Karan},
	month = jun,
	year = {2024},
	note = {Number: 1
Publisher: IAEME Publication},
	pages = {234--244},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/WATZ45IV/Khanna - 2024 - ENHANCING CLOUD SECURITY WITH GENERATIVE AI EMERGING STRATEGIES AND APPLICATIONS.pdf:application/pdf},
}

@misc{noauthor_securing_2023,
	title = {Securing generative {AI}: {An} introduction to the {Generative} {AI} {Security} {Scoping} {Matrix} {\textbar} {AWS} {Security} {Blog}},
	shorttitle = {Securing generative {AI}},
	url = {https://aws.amazon.com/blogs/security/securing-generative-ai-an-introduction-to-the-generative-ai-security-scoping-matrix/},
	language = {en-US},
	urldate = {2025-04-08},
	month = oct,
	year = {2023},
	note = {Section: Amazon Bedrock},
}

@misc{noauthor_zero-trust_nodate,
	title = {Zero-{Trust} {Architecture} ({ZTA}): {Designing} an {AI}-{Powered} {Cloud} {Security} {Framework} for {LLMs}' {Black} {Box} {Problems} {\textbar} {Semantic} {Scholar}},
	url = {https://www.semanticscholar.org/paper/Zero-Trust-Architecture-(ZTA)%3A-Designing-an-Cloud-Dash/ce5062561a36f15ec1cd203705736d7ab335e9a9},
	urldate = {2025-04-08},
	file = {Zero-Trust Architecture (ZTA)\: Designing an AI-Powered Cloud Security Framework for LLMs' Black Box Problems | Semantic Scholar:/Users/d.veragilliard/Zotero/storage/7W7KMKP9/ce5062561a36f15ec1cd203705736d7ab335e9a9.html:text/html},
}

@misc{noauthor_devsecops_nodate,
	title = {{DevSecOps} {Sentinel}: {GenAI}-{Driven} {Agentic} {Workflows} for {Comprehensive} {Supply} {Chain} {Security} {\textbar} {Semantic} {Scholar}},
	url = {https://www.semanticscholar.org/paper/DevSecOps-Sentinel%3A-GenAI-Driven-Agentic-Workflows-Pillala-Azarpazhooh/c6936c7dcb49d540014eeb733bbacf2fd5b6c91a},
	urldate = {2025-04-08},
}

@techreport{tabassi_artificial_2023,
	address = {Gaithersburg, MD},
	title = {Artificial {Intelligence} {Risk} {Management} {Framework} ({AI} {RMF} 1.0)},
	url = {http://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf},
	abstract = {As directed by the National Artificial Intelligence Initiative Act of 2020 (P.L. 116-283), the goal of the AI RMF is to offer a resource to the organizations designing, developing, deploying, or using AI systems to help manage the many risks of AI and promote trustworthy and responsible development and use of AI systems. The Framework is intended to be voluntary, rights-preserving, non-sector specific, and use-case agnostic, providing flexibility to organizations of all sizes and in all sectors and throughout society to implement the approaches in the Framework.   The AI RMF is intended to be practical, to adapt to the AI landscape as AI technologies continue to develop, and to be operationalized by organizations in varying degrees and capacities so society can benefit from AI while also being protected from its potential harms.},
	language = {en},
	number = {NIST AI 100-1},
	urldate = {2025-04-08},
	institution = {National Institute of Standards and Technology (U.S.)},
	author = {Tabassi, Elham},
	month = jan,
	year = {2023},
	doi = {10.6028/NIST.AI.100-1},
	pages = {NIST AI 100--1},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/IFJQD782/Tabassi - 2023 - Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf:application/pdf},
}

@article{nyoto_cyber_2024,
	title = {Cyber {Security} {Risks} in the {Rapid} {Development} of {Generative} {Artificial} {Intelligence}: {A} {Systematic} {Literature} {Review}},
	volume = {1},
	issn = {3063-0630},
	shorttitle = {Cyber {Security} {Risks} in the {Rapid} {Development} of {Generative} {Artificial} {Intelligence}},
	url = {https://journal.unilak.ac.id/index.php/ComniTech/article/view/24539},
	abstract = {This study aims to identify the cybersecurity risks arising from the use of Generative Artificial Intelligence (GenAI). By employing a systematic literature review (SLR) method and following the PRISMA 2020 guidelines, this research systematically selects and analyzes relevant literature to discover and understand the risks associated with the use of GenAI. From the seventeen studies successfully collected and reviewed, various cybersecurity risks were identified, including phishing attacks, social engineering, ransomware, malware, deepfakes, misinformation, data leakage, misuse of personal data, executable attack code generation, privacy risks, and intellectual property violations. These findings provide crucial insights into the potential threats that may emerge from the irresponsible use of GenAI. The study is designed to offer valuable information for various stakeholders in their risk mitigation efforts and in the development of relevant regulations concerning the ethical use of GenAI. It is hoped that these findings will serve as a solid foundation for developing more effective security strategies and policies to address the challenges posed by this technology, and encourage the implementation of improved protective measures to tackle emerging risks.},
	language = {en},
	number = {2},
	urldate = {2025-04-08},
	journal = {ComniTech : Journal of Computational Intelligence and Informatics},
	author = {Nyoto, Rebecca La Volla and Devega, Mariza and Nyoto, Nyoto},
	month = dec,
	year = {2024},
	keywords = {cybersecurity, generative artificial intelligence (GenAI), systematic literature review.},
	pages = {57--66},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/9VNR6T4Q/Nyoto et al. - 2024 - Cyber Security Risks in the Rapid Development of Generative Artificial Intelligence A Systematic Li.pdf:application/pdf},
}

@misc{yigit_review_2024,
	title = {Review of {Generative} {AI} {Methods} in {Cybersecurity}},
	url = {http://arxiv.org/abs/2403.08701},
	doi = {10.48550/arXiv.2403.08701},
	abstract = {Over the last decade, Artificial Intelligence (AI) has become increasingly popular, especially with the use of chatbots such as ChatGPT, Gemini, and DALL-E. With this rise, large language models (LLMs) and Generative AI (GenAI) have also become more prevalent in everyday use. These advancements strengthen cybersecurity's defensive posture and open up new attack avenues for adversaries as well. This paper provides a comprehensive overview of the current state-of-the-art deployments of GenAI, covering assaults, jailbreaking, and applications of prompt injection and reverse psychology. This paper also provides the various applications of GenAI in cybercrimes, such as automated hacking, phishing emails, social engineering, reverse cryptography, creating attack payloads, and creating malware. GenAI can significantly improve the automation of defensive cyber security processes through strategies such as dataset construction, safe code development, threat intelligence, defensive measures, reporting, and cyberattack detection. In this study, we suggest that future research should focus on developing robust ethical norms and innovative defense mechanisms to address the current issues that GenAI creates and to also further encourage an impartial approach to its future application in cybersecurity. Moreover, we underscore the importance of interdisciplinary approaches further to bridge the gap between scientific developments and ethical considerations.},
	urldate = {2025-04-08},
	publisher = {arXiv},
	author = {Yigit, Yagmur and Buchanan, William J. and Tehrani, Madjid G. and Maglaras, Leandros},
	month = mar,
	year = {2024},
	note = {arXiv:2403.08701 [cs]},
	keywords = {Computer Science - Cryptography and Security},
	annote = {Comment: 40 pages},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/93NDWF8C/Yigit et al. - 2024 - Review of Generative AI Methods in Cybersecurity.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/P2VFTJVJ/2403.html:text/html},
}

@incollection{feffer_red-teaming_2025,
	title = {Red-{Teaming} for {Generative} {AI}: {Silver} {Bullet} or {Security} {Theater}?},
	shorttitle = {Red-{Teaming} for {Generative} {AI}},
	abstract = {In response to rising concerns surrounding the safety, security, and trustworthiness of Generative AI (GenAI) models, practitioners and regulators alike have pointed to AI red-teaming as a key component of their strategies for identifying and mitigating these risks. However, despite AI red-teaming's central role in policy discussions and corporate messaging, significant questions remain about what precisely it means, what role it can play in regulation, and how it relates to conventional red-teaming practices as originally conceived in the field of cybersecurity. In this work, we identify recent cases of red-teaming activities in the AI industry and conduct an extensive survey of relevant research literature to characterize the scope, structure, and criteria for AI red-teaming practices. Our analysis reveals that prior methods and practices of AI red-teaming diverge along several axes, including the purpose of the activity (which is often vague), the artifact under evaluation, the setting in which the activity is conducted (e.g., actors, resources, and methods), and the resulting decisions it informs (e.g., reporting, disclosure, and mitigation). In light of our findings, we argue that while red-teaming may be a valuable big-tent idea for characterizing GenAI harm mitigations, and that industry may effectively apply red-teaming and other strategies behind closed doors to safeguard AI, gestures towards red-teaming (based on public definitions) as a panacea for every possible risk verge on security theater. To move toward a more robust toolbox of evaluations for generative AI, we synthesize our recommendations into a question bank meant to guide and scaffold future AI red-teaming practices.},
	urldate = {2025-04-08},
	booktitle = {Proceedings of the 2024 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {AAAI Press},
	author = {Feffer, Michael and Sinha, Anusha and Deng, Wesley H. and Lipton, Zachary C. and Heidari, Hoda},
	month = feb,
	year = {2025},
	pages = {421--437},
}

@article{vootkuri_multi-cloud_2024,
	title = {Multi-{Cloud} {Data} {Strategy} \& {Security} for {Generative} {AI}},
	volume = {12},
	abstract = {The rapid growth of generative artificial intelligence has fundamentally changed the requirements for cloud computing infrastructure, including requisites such as innovative approaches to resource management and development strategies. A multi-cloud strategy involves leveraging multiple cloud providers to execute an application to optimize data management, storage, and processing capabilities for training and inference. This comprehensive research paper aims to study the evolving paradigm of multi-cloud strategies tailored for Generative Artificial intelligence (Gen-AI) using the multi-cloud platforms to enhance their infrastructure, reliability, and security and how the costs are optimized by effectively reducing vendor lock-ins and provide a chance to strategically leverage a variety of providers and their skills to meet specific company demands. The paper demonstrates multi cloud data strategy and security frameworks for Gen AI applications. The research discusses how to protect GenAI using different strategies in enterprise ecosystems.},
	language = {en},
	number = {01},
	author = {Vootkuri, Chaitanya},
	year = {2024},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/UWZHX4FU/Vootkuri - 2024 - Multi-Cloud Data Strategy & Security for Generative AI.pdf:application/pdf},
}

@article{sushil_prabhu_prabhakaran_integration_2024,
	title = {Integration {Patterns} in {Unified} {AI} and {Cloud} {Platforms}: {A} {Systematic} {Review} of {Process} {Automation} {Technologies}},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by/4.0},
	issn = {2456-3307},
	shorttitle = {Integration {Patterns} in {Unified} {AI} and {Cloud} {Platforms}},
	url = {https://ijsrcseit.com/index.php/home/article/view/CSEIT241061229},
	doi = {10.32628/CSEIT241061229},
	abstract = {This article comprehensively analyzes unified AI and cloud platforms, examining their role in transforming process automation and decision systems across industries. The article investigates the architectural frameworks and integration patterns that enable the convergence of AI tools, machine learning operations, and workflow orchestration within cloud-native environments. The article explores key innovations, including federated AI implementations, real-time data processing architectures, and multi-cloud integration patterns. It provides insights into their practical applications across finance, healthcare, retail, and manufacturing sectors. The article identifies critical success factors in platform implementation, including integrating MLOps frameworks, automated decision engines, and compliance tools for AI governance. Through case study analysis and architectural evaluation, we demonstrate how unified platforms address traditional challenges in AI deployment while enabling scalable, cost-efficient solutions. The findings reveal emerging patterns in platform architecture that facilitate seamless integration of edge computing, real-time analytics, and distributed AI systems, contributing to the broader understanding of enterprise AI implementation strategies. This article provides valuable insights for researchers and practitioners in cloud engineering, artificial intelligence, and systems integration while highlighting future directions for platform evolution and standardization.},
	number = {6},
	urldate = {2025-04-08},
	journal = {Int. J. Sci. Res. Comput. Sci. Eng. Inf. Technol},
	author = {{Sushil Prabhu Prabhakaran}},
	month = dec,
	year = {2024},
	pages = {1932--1940},
	annote = {[TLDR] This article comprehensively analyzes unified AI and cloud platforms, examining their role in transforming process automation and decision systems across industries and revealing emerging patterns in platform architecture that facilitate seamless integration of edge computing, real-time analytics, and distributed AI systems.},
}

@article{bringhenti_security_2023,
	title = {Security automation for multi-cluster orchestration in {Kubernetes}},
	copyright = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10175419/},
	doi = {10.1109/NetSoft57336.2023.10175419},
	abstract = {In the latest years, multi-domain Kubernetes architectures composed of multiple clusters have been getting more frequent, so as to provide higher workload isolation, resource availability flexibility and scalability for application deployment. However, manually configuring their security may lead to inconsistencies among policies defined in different clusters, or it may require knowledge that the administrator of each domain cannot have. Therefore, this paper proposes an automatic approach for the automatic generation of the network security policies to be deployed in each cluster of a multi-domain Kubernetes deployment. The objectives of this approach are to reduce of configuration errors that human administrators commonly make, and to create transparent cross-cluster communications. This approach has been implemented as a framework named Multi-Cluster Orchestrator, which has been validated in realistic use cases to assess its benefits to Kubernetes orchestration.},
	urldate = {2025-04-08},
	journal = {2023 IEEE 9th International Conference on Network Softwarization (NetSoft)},
	author = {Bringhenti, Daniele and Sisto, Riccardo and Valenza, Fulvio},
	month = jun,
	year = {2023},
	note = {Conference Name: 2023 IEEE 9th International Conference on Network Softwarization (NetSoft)
ISBN: 9798350399806
Place: Madrid, Spain
Publisher: IEEE},
	pages = {480--485},
	annote = {[TLDR] An automatic approach for the automatic generation of the network security policies to be deployed in each cluster of a multi-domain Kubernetes deployment is proposed to reduce of configuration errors that human administrators commonly make, and to create transparent cross-cluster communications.},
}

@article{hammar_digital_2023,
	title = {Digital {Twins} for {Security} {Automation}},
	copyright = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10154288/},
	doi = {10.1109/NOMS56928.2023.10154288},
	abstract = {We present a novel emulation system for creating high-fidelity digital twins of IT infrastructures. The digital twins replicate key functionality of the corresponding infrastructures and allow to play out security scenarios in a safe environment. We show that this capability can be used to automate the process of finding effective security policies for a target infrastructure. In our approach, a digital twin of the target infrastructure is used to run security scenarios and collect data. The collected data is then used to instantiate simulations of Markov decision processes and learn effective policies through reinforcement learning, whose performances are validated in the digital twin. This closed-loop learning process executes iteratively and provides continuously evolving and improving security policies. We apply our approach to an intrusion response scenario. Our results show that the digital twin provides the necessary evaluative feedback to learn near-optimal intrusion response policies.},
	urldate = {2025-04-08},
	journal = {NOMS 2023-2023 IEEE/IFIP Network Operations and Management Symposium},
	author = {Hammar, Kim and Stadler, Rolf},
	month = may,
	year = {2023},
	note = {Conference Name: NOMS 2023-2023 IEEE/IFIP Network Operations and Management Symposium
ISBN: 9781665477161
Place: Miami, FL, USA
Publisher: IEEE},
	pages = {1--6},
	annote = {[TLDR] This work presents a novel emulation system for creating high-fidelity digital twins of IT infrastructures that provides the necessary evaluative feedback to learn near-optimal intrusion response policies.},
}

@article{surathunmanun_exploring_2024,
	title = {Exploring the {Role} of {Generative} {Artificial} {Intelligence} in the {Energy} {Sector}: {A} {Comprehensive} {Literature} {Review}},
	copyright = {https://doi.org/10.15223/policy-029},
	shorttitle = {Exploring the {Role} of {Generative} {Artificial} {Intelligence} in the {Energy} {Sector}},
	url = {https://ieeexplore.ieee.org/document/10795598/},
	doi = {10.1109/ICUE63019.2024.10795598},
	abstract = {Generative Artificial Intelligence (GenAI) enhances productivity by creating data, forecasting, optimizing, and understanding human language. In the energy sector, it is projected to have a \$240 billion global economic impact, though research remains limited. This paper reviews GenAI's benefits, challenges, and research gaps in the energy sector, also focusing on climate change efforts. A PRISMA-SCR-based literature review from January 2022 to May 2024 was conducted using IEEE Xplore, ScienceDirect, ACM Digital Library, and Google Scholar. GenAI tools extracted data, verified by researchers. Analysis of 33 papers shows GenAI excels in knowledge integration and prediction. It generates synthetic electricity demand data, manages grids, forecasts energy demand, and optimizes renewable energy systems. Key challenges include hallucinations, data biases, privacy concerns, misuse, and system errors. Solutions involve improving training data, system fine-tuning, human oversight, and security measures. Research gaps include synthetic data realism, model evaluation standards, and integrating GenAI with blockchain and IoT.},
	urldate = {2025-04-08},
	journal = {2024 International Conference on Sustainable Energy: Energy Transition and Net-Zero Climate Future (ICUE)},
	author = {Surathunmanun, Surasak and Ongsakul, Weerakorn and Singh, Jai Govind},
	month = oct,
	year = {2024},
	note = {Conference Name: 2024 International Conference on Sustainable Energy: Energy Transition and Net-Zero Climate Future (ICUE)
ISBN: 9798331517076
Place: Pattaya City, Thailand
Publisher: IEEE},
	pages = {1--11},
	annote = {[TLDR] GenAI's benefits, challenges, and research gaps in the energy sector are reviewed, also focusing on climate change efforts.},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/T6QIN8FX/69dd137c561619884ee4aecd95f81a351b7ce328.html:text/html},
}
