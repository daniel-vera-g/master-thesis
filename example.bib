
@article{weedon_generative_2023,
	title = {Generative {AI}: security implications for business automation},
	volume = {2023},
	issn = {1353-4858, 1872-9371},
	url = {http://www.magonlinelibrary.com/doi/10.12968/S1353-4858%2823%2970045-7},
	doi = {10.12968/S1353-4858(23)70045-7},
	shorttitle = {Generative {AI}},
	abstract = {{AI} tools such as {ChatGPT} certainly appear to offer significant benefits to organisations looking to save costs and improve efficiency. But the technology is being adopted with an enthusiasm that leaves little room for the careful consideration of potential security vulnerabilities. So how do you embrace this revolution without putting yourself at risk?},
	pages = {S1353--4858(23)70045--7},
	number = {9},
	journaltitle = {Network Security},
	author = {Weedon, Scott},
	urldate = {2024-09-07},
	date = {2023-09},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/3ICS935N/ba42b88132000be4ea8cf6b9a119f6b71d0b07f1.html:text/html},
}

@misc{haryanto_secgenai_2024,
	title = {{SecGenAI}: Enhancing Security of Cloud-based Generative {AI} Applications within Australian Critical Technologies of National Interest},
	url = {http://arxiv.org/abs/2407.01110},
	doi = {10.48550/arXiv.2407.01110},
	shorttitle = {{SecGenAI}},
	abstract = {The rapid advancement of Generative {AI} ({GenAI}) technologies offers transformative opportunities within Australia's critical technologies of national interest while introducing unique security challenges. This paper presents {SecGenAI}, a comprehensive security framework for cloud-based {GenAI} applications, with a focus on Retrieval-Augmented Generation ({RAG}) systems. {SecGenAI} addresses functional, infrastructure, and governance requirements, integrating end-to-end security analysis to generate specifications emphasizing data privacy, secure deployment, and shared responsibility models. Aligned with Australian Privacy Principles, {AI} Ethics Principles, and guidelines from the Australian Cyber Security Centre and Digital Transformation Agency, {SecGenAI} mitigates threats such as data leakage, adversarial attacks, and model inversion. The framework's novel approach combines advanced machine learning techniques with robust security measures, ensuring compliance with Australian regulations while enhancing the reliability and trustworthiness of {GenAI} systems. This research contributes to the field of intelligent systems by providing actionable strategies for secure {GenAI} implementation in industry, fostering innovation in {AI} applications, and safeguarding national interests.},
	number = {{arXiv}:2407.01110},
	publisher = {{arXiv}},
	author = {Haryanto, Christoforus Yoga and Vu, Minh Hieu and Nguyen, Trung Duc and Lomempow, Emily and Nurliana, Yulia and Taheri, Sona},
	urldate = {2024-08-26},
	date = {2024-07-01},
	eprinttype = {arxiv},
	eprint = {2407.01110 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/d.veragilliard/Zotero/storage/Y87CT6NW/Haryanto et al. - 2024 - SecGenAI Enhancing Security of Cloud-based Genera.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/7S4ZGDKG/2407.html:text/html},
}

@article{senior_software_engineer_cisco_systems_inc_usa_next-gen_2024,
	title = {Next-Gen Firewalls: Enhancing Cloud Security with Generative {AI}},
	volume = {3},
	url = {https://www.onlinescientificresearch.com/articles/nextgen-firewalls-enhancing-cloud-security-with-generative-ai.pdf},
	doi = {10.47363/JAICC/2024(3)404},
	shorttitle = {Next-Gen Firewalls},
	abstract = {Next-generation firewalls are available and use machine learning and generative modeling to enhance the detection of hard-to-detect cyber threats. These systems incorporate advanced security controls, policies, and protocols with Layer 7 of the {OSI} model. This chapter updates these steep {AI}-based protection systems and applications.},
	pages = {1--9},
	number = {4},
	journaltitle = {J Arti Inte \& Cloud Comp},
	author = {{Senior Software Engineer, Cisco Systems Inc, USA} and Lekkala, Seshagirirao},
	urldate = {2025-03-31},
	date = {2024-08-30},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/D9LSZDNH/4373239ca9de9d5ab0dbf0b2e60bf1885beca545.html:text/html},
}

@article{patel_generative_2025,
	title = {Generative {AI} for Automated Security Operations in Cloud Computing},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10849302/},
	doi = {10.1109/ICAIC63015.2025.10849302},
	abstract = {New opportunities in cloud computing have brought many new risks that require effective protection of dynamic distributed environments. Introducing a new formative technology, generative {AI}, to cloud security has far-reaching benefits for automating threat detection, real-time incident addressing, and vulnerability management. This paper focuses on extending generative {AI} with cloud security tools like {AWS} {GuardDuty} and Google Cloud Security Command Center; the contemplation of accuracy enhancement and response efficiency highlights its aim. Concerning actual applications such as {SOAR} systems, the study demonstrates how media industry giants, such as Netflix and {JPMorgan} Chase, have used {AI} to minimize risk factors while increasing operational efficiency. The paper also discusses the significant increase in response time, enhanced detection accuracy, and the shift to proactive security strategies brought by generative {AI}. Drawing attention to {AI} systems’ opportunities, the study examines the subsequent issues connected with {AI} applications, including over-dependence on {AI} tools, adversarial risk to models, and the complex nature of decisionmaking in the context of {AI} systems. The present study also highlights the importance of generative {AI} in strengthening the defense of the cloud environment, but, at the same time, it recognizes the significance of preventive efforts and planned action plans to manage these technologies efficiently.},
	pages = {1--7},
	journaltitle = {2025 {IEEE} 4th International Conference on {AI} in Cybersecurity ({ICAIC})},
	author = {Patel, Advait and Pandey, Pravin and Ragothaman, Hariharan and Molleti, Ramasankar and Peddinti, Diwakar Reddy},
	urldate = {2025-03-31},
	date = {2025-02-05},
	note = {Conference Name: 2025 {IEEE} 4th International Conference on {AI} in Cybersecurity ({ICAIC})
{ISBN}: 9798331518882
Place: Houston, {TX}, {USA}
Publisher: {IEEE}},
}

@article{seth_ai_2025,
	title = {{AI} and Generative {AI}-Driven Automation for Multi-Cloud and Hybrid Cloud Architectures: Enhancing Security, Performance, and Operational Efficiency},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10903928/},
	doi = {10.1109/CCWC62904.2025.10903928},
	shorttitle = {{AI} and Generative {AI}-Driven Automation for Multi-Cloud and Hybrid Cloud Architectures},
	abstract = {The emergence of cloud and hybrid cloud structures presents {eCommerce} firms with the adaptability and robustness needed to manage expansion and varying user requirements effectively. However, this also brings about challenges concerning security enhancements, distribution of workloads, and cost-effectiveness optimization. Traditional cloud management models often need help to meet these evolving demands efficiently. This research presents a system that leverages Artificial Intelligence ({AI}) and Generative {AI} (Gen {AI}) to effectively automate and enhance cloud and hybrid infrastructures for ecommerce websites. The system adapts infrastructure to traffic times like holidays or sales events by utilizing {AI} to scale resources as needed. It conserves resources during low user activity periods such as overnight. Ensuring optimal system performance and availability during peak traffic times while cutting costs during traffic periods is essential for cost-effectiveness and efficient resource management. In addition, {AI}-powered security automation safeguards against changing cyber dangers, and compliance automation guarantees conformity with rules like {PCI} {DSS} for payment handling. This report also delves into merging Gen {AI} into cloud coordination systems, facilitating workflows, and enhancing {eCommerce} processes. The outcome is a significant drop in operational expenses, a quicker service rollout, and decreased security breaches. Through real-world {eCommerce} case studies, this paper provides actionable insights for cloud engineers and architects on leveraging {AI}-driven cloud management to enhance performance, security, and cost-efficiency in multi-cloud and hybrid environments, ensuring seamless user experiences and business continuity.},
	pages = {00784--00793},
	journaltitle = {2025 {IEEE} 15th Annual Computing and Communication Workshop and Conference ({CCWC})},
	author = {Seth, Dhruv Kumar and Ratra, Karan Kumar and Sundareswaran, Aneeshkumar P},
	urldate = {2025-04-08},
	date = {2025-01-06},
	note = {Conference Name: 2025 {IEEE} 15th Annual Computing and Communication Workshop and Conference ({CCWC})
{ISBN}: 9798331507695
Place: Las Vegas, {NV}, {USA}
Publisher: {IEEE}},
}

@article{khanna_enhancing_2024,
	title = {{ENHANCING} {CLOUD} {SECURITY} {WITH} {GENERATIVE} {AI}: {EMERGING} {STRATEGIES} {AND} {APPLICATIONS}},
	volume = {3},
	issn = {2295-5152},
	url = {https://iaeme.com/Home/article_id/JARET_03_01_021},
	shorttitle = {{ENHANCING} {CLOUD} {SECURITY} {WITH} {GENERATIVE} {AI}},
	abstract = {This article explores the potential of generative {AI} for enhancing cloud security. With the rapid adoption of cloud technologies and the increasing sophistication of cyber threats, traditional security measures often struggle to keep pace. Generative {AI}, with its ability to learn from vast amounts of data and generate intelligent outputs, presents a powerful tool to address these challenges. The article delves into the fundamentals of generative {AI} and its specific applications in cloud security, including anomaly detection, threat intelligence, and automated response mechanisms. It also discusses the challenges and future directions in this field, highlighting the need for large and diverse datasets, addressing adversarial attacks, improving model interpretability, and considering the ethical implications of using generative {AI} in cloud security.},
	pages = {234--244},
	number = {1},
	journaltitle = {{JARET}},
	author = {Khanna, Karan},
	urldate = {2025-04-08},
	date = {2024-06-14},
	langid = {english},
	note = {Number: 1
Publisher: {IAEME} Publication},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/WATZ45IV/Khanna - 2024 - ENHANCING CLOUD SECURITY WITH GENERATIVE AI EMERGING STRATEGIES AND APPLICATIONS.pdf:application/pdf},
}

@online{noauthor_securing_2023,
	title = {Securing generative {AI}: An introduction to the Generative {AI} Security Scoping Matrix {\textbar} {AWS} Security Blog},
	url = {https://aws.amazon.com/blogs/security/securing-generative-ai-an-introduction-to-the-generative-ai-security-scoping-matrix/},
	shorttitle = {Securing generative {AI}},
	urldate = {2025-04-08},
	date = {2023-10-19},
	langid = {american},
	note = {Section: Amazon Bedrock},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/748SVXTA/securing-generative-ai-an-introduction-to-the-generative-ai-security-scoping-matrix.html:text/html},
}

@online{noauthor_zero-trust_nodate,
	title = {Zero-Trust Architecture ({ZTA}): Designing an {AI}-Powered Cloud Security Framework for {LLMs}' Black Box Problems {\textbar} Semantic Scholar},
	url = {https://www.semanticscholar.org/paper/Zero-Trust-Architecture-(ZTA)%3A-Designing-an-Cloud-Dash/ce5062561a36f15ec1cd203705736d7ab335e9a9},
	urldate = {2025-04-08},
	file = {Zero-Trust Architecture (ZTA)\: Designing an AI-Powered Cloud Security Framework for LLMs' Black Box Problems | Semantic Scholar:/Users/d.veragilliard/Zotero/storage/7W7KMKP9/ce5062561a36f15ec1cd203705736d7ab335e9a9.html:text/html},
}

@online{noauthor_devsecops_nodate,
	title = {{DevSecOps} Sentinel: {GenAI}-Driven Agentic Workflows for Comprehensive Supply Chain Security {\textbar} Semantic Scholar},
	url = {https://www.semanticscholar.org/paper/DevSecOps-Sentinel%3A-GenAI-Driven-Agentic-Workflows-Pillala-Azarpazhooh/c6936c7dcb49d540014eeb733bbacf2fd5b6c91a},
	urldate = {2025-04-08},
}

@report{tabassi_artificial_2023,
	location = {Gaithersburg, {MD}},
	title = {Artificial Intelligence Risk Management Framework ({AI} {RMF} 1.0)},
	url = {http://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf},
	abstract = {As directed by the National Artificial Intelligence Initiative Act of 2020 (P.L. 116-283), the goal of the {AI} {RMF} is to offer a resource to the organizations designing, developing, deploying, or using {AI} systems to help manage the many risks of {AI} and promote trustworthy and responsible development and use of {AI} systems. The Framework is intended to be voluntary, rights-preserving, non-sector specific, and use-case agnostic, providing flexibility to organizations of all sizes and in all sectors and throughout society to implement the approaches in the Framework.   The {AI} {RMF} is intended to be practical, to adapt to the {AI} landscape as {AI} technologies continue to develop, and to be operationalized by organizations in varying degrees and capacities so society can benefit from {AI} while also being protected from its potential harms.},
	pages = {NIST AI 100--1},
	number = {{NIST} {AI} 100-1},
	institution = {National Institute of Standards and Technology (U.S.)},
	author = {Tabassi, Elham},
	urldate = {2025-04-08},
	date = {2023-01-26},
	langid = {english},
	doi = {10.6028/NIST.AI.100-1},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/IFJQD782/Tabassi - 2023 - Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf:application/pdf},
}

@article{nyoto_cyber_2024,
	title = {Cyber Security Risks in the Rapid Development of Generative Artificial Intelligence: A Systematic Literature Review},
	volume = {1},
	issn = {3063-0630},
	url = {https://journal.unilak.ac.id/index.php/ComniTech/article/view/24539},
	shorttitle = {Cyber Security Risks in the Rapid Development of Generative Artificial Intelligence},
	abstract = {This study aims to identify the cybersecurity risks arising from the use of Generative Artificial Intelligence ({GenAI}). By employing a systematic literature review ({SLR}) method and following the {PRISMA} 2020 guidelines, this research systematically selects and analyzes relevant literature to discover and understand the risks associated with the use of {GenAI}. From the seventeen studies successfully collected and reviewed, various cybersecurity risks were identified, including phishing attacks, social engineering, ransomware, malware, deepfakes, misinformation, data leakage, misuse of personal data, executable attack code generation, privacy risks, and intellectual property violations. These findings provide crucial insights into the potential threats that may emerge from the irresponsible use of {GenAI}. The study is designed to offer valuable information for various stakeholders in their risk mitigation efforts and in the development of relevant regulations concerning the ethical use of {GenAI}. It is hoped that these findings will serve as a solid foundation for developing more effective security strategies and policies to address the challenges posed by this technology, and encourage the implementation of improved protective measures to tackle emerging risks.},
	pages = {57--66},
	number = {2},
	journaltitle = {{ComniTech} : Journal of Computational Intelligence and Informatics},
	author = {Nyoto, Rebecca La Volla and Devega, Mariza and Nyoto, Nyoto},
	urldate = {2025-04-08},
	date = {2024-12-29},
	langid = {english},
	keywords = {cybersecurity, generative artificial intelligence ({GenAI}), systematic literature review.},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/9VNR6T4Q/Nyoto et al. - 2024 - Cyber Security Risks in the Rapid Development of Generative Artificial Intelligence A Systematic Li.pdf:application/pdf},
}

@misc{yigit_review_2024,
	title = {Review of Generative {AI} Methods in Cybersecurity},
	url = {http://arxiv.org/abs/2403.08701},
	doi = {10.48550/arXiv.2403.08701},
	abstract = {Over the last decade, Artificial Intelligence ({AI}) has become increasingly popular, especially with the use of chatbots such as {ChatGPT}, Gemini, and {DALL}-E. With this rise, large language models ({LLMs}) and Generative {AI} ({GenAI}) have also become more prevalent in everyday use. These advancements strengthen cybersecurity's defensive posture and open up new attack avenues for adversaries as well. This paper provides a comprehensive overview of the current state-of-the-art deployments of {GenAI}, covering assaults, jailbreaking, and applications of prompt injection and reverse psychology. This paper also provides the various applications of {GenAI} in cybercrimes, such as automated hacking, phishing emails, social engineering, reverse cryptography, creating attack payloads, and creating malware. {GenAI} can significantly improve the automation of defensive cyber security processes through strategies such as dataset construction, safe code development, threat intelligence, defensive measures, reporting, and cyberattack detection. In this study, we suggest that future research should focus on developing robust ethical norms and innovative defense mechanisms to address the current issues that {GenAI} creates and to also further encourage an impartial approach to its future application in cybersecurity. Moreover, we underscore the importance of interdisciplinary approaches further to bridge the gap between scientific developments and ethical considerations.},
	number = {{arXiv}:2403.08701},
	publisher = {{arXiv}},
	author = {Yigit, Yagmur and Buchanan, William J. and Tehrani, Madjid G. and Maglaras, Leandros},
	urldate = {2025-04-08},
	date = {2024-03-19},
	eprinttype = {arxiv},
	eprint = {2403.08701 [cs]},
	keywords = {Computer Science - Cryptography and Security},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/93NDWF8C/Yigit et al. - 2024 - Review of Generative AI Methods in Cybersecurity.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/P2VFTJVJ/2403.html:text/html},
}

@incollection{feffer_red-teaming_2025,
	title = {Red-Teaming for Generative {AI}: Silver Bullet or Security Theater?},
	shorttitle = {Red-Teaming for Generative {AI}},
	abstract = {In response to rising concerns surrounding the safety, security, and trustworthiness of Generative {AI} ({GenAI}) models, practitioners and regulators alike have pointed to {AI} red-teaming as a key component of their strategies for identifying and mitigating these risks. However, despite {AI} red-teaming's central role in policy discussions and corporate messaging, significant questions remain about what precisely it means, what role it can play in regulation, and how it relates to conventional red-teaming practices as originally conceived in the field of cybersecurity. In this work, we identify recent cases of red-teaming activities in the {AI} industry and conduct an extensive survey of relevant research literature to characterize the scope, structure, and criteria for {AI} red-teaming practices. Our analysis reveals that prior methods and practices of {AI} red-teaming diverge along several axes, including the purpose of the activity (which is often vague), the artifact under evaluation, the setting in which the activity is conducted (e.g., actors, resources, and methods), and the resulting decisions it informs (e.g., reporting, disclosure, and mitigation). In light of our findings, we argue that while red-teaming may be a valuable big-tent idea for characterizing {GenAI} harm mitigations, and that industry may effectively apply red-teaming and other strategies behind closed doors to safeguard {AI}, gestures towards red-teaming (based on public definitions) as a panacea for every possible risk verge on security theater. To move toward a more robust toolbox of evaluations for generative {AI}, we synthesize our recommendations into a question bank meant to guide and scaffold future {AI} red-teaming practices.},
	pages = {421--437},
	booktitle = {Proceedings of the 2024 {AAAI}/{ACM} Conference on {AI}, Ethics, and Society},
	publisher = {{AAAI} Press},
	author = {Feffer, Michael and Sinha, Anusha and Deng, Wesley H. and Lipton, Zachary C. and Heidari, Hoda},
	urldate = {2025-04-08},
	date = {2025-02-07},
}

@article{vootkuri_multi-cloud_2024,
	title = {Multi-Cloud Data Strategy \& Security for Generative {AI}},
	volume = {12},
	abstract = {The rapid growth of generative artificial intelligence has fundamentally changed the requirements for cloud computing infrastructure, including requisites such as innovative approaches to resource management and development strategies. A multi-cloud strategy involves leveraging multiple cloud providers to execute an application to optimize data management, storage, and processing capabilities for training and inference. This comprehensive research paper aims to study the evolving paradigm of multi-cloud strategies tailored for Generative Artificial intelligence (Gen-{AI}) using the multi-cloud platforms to enhance their infrastructure, reliability, and security and how the costs are optimized by effectively reducing vendor lock-ins and provide a chance to strategically leverage a variety of providers and their skills to meet specific company demands. The paper demonstrates multi cloud data strategy and security frameworks for Gen {AI} applications. The research discusses how to protect {GenAI} using different strategies in enterprise ecosystems.},
	number = {1},
	author = {Vootkuri, Chaitanya},
	date = {2024},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/UWZHX4FU/Vootkuri - 2024 - Multi-Cloud Data Strategy & Security for Generative AI.pdf:application/pdf},
}

@article{sushil_prabhu_prabhakaran_integration_2024,
	title = {Integration Patterns in Unified {AI} and Cloud Platforms: A Systematic Review of Process Automation Technologies},
	volume = {10},
	rights = {https://creativecommons.org/licenses/by/4.0},
	issn = {2456-3307},
	url = {https://ijsrcseit.com/index.php/home/article/view/CSEIT241061229},
	doi = {10.32628/CSEIT241061229},
	shorttitle = {Integration Patterns in Unified {AI} and Cloud Platforms},
	abstract = {This article comprehensively analyzes unified {AI} and cloud platforms, examining their role in transforming process automation and decision systems across industries. The article investigates the architectural frameworks and integration patterns that enable the convergence of {AI} tools, machine learning operations, and workflow orchestration within cloud-native environments. The article explores key innovations, including federated {AI} implementations, real-time data processing architectures, and multi-cloud integration patterns. It provides insights into their practical applications across finance, healthcare, retail, and manufacturing sectors. The article identifies critical success factors in platform implementation, including integrating {MLOps} frameworks, automated decision engines, and compliance tools for {AI} governance. Through case study analysis and architectural evaluation, we demonstrate how unified platforms address traditional challenges in {AI} deployment while enabling scalable, cost-efficient solutions. The findings reveal emerging patterns in platform architecture that facilitate seamless integration of edge computing, real-time analytics, and distributed {AI} systems, contributing to the broader understanding of enterprise {AI} implementation strategies. This article provides valuable insights for researchers and practitioners in cloud engineering, artificial intelligence, and systems integration while highlighting future directions for platform evolution and standardization.},
	pages = {1932--1940},
	number = {6},
	journaltitle = {Int. J. Sci. Res. Comput. Sci. Eng. Inf. Technol},
	author = {{Sushil Prabhu Prabhakaran}},
	urldate = {2025-04-08},
	date = {2024-12-15},
}

@article{bringhenti_security_2023,
	title = {Security automation for multi-cluster orchestration in Kubernetes},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10175419/},
	doi = {10.1109/NetSoft57336.2023.10175419},
	abstract = {In the latest years, multi-domain Kubernetes architectures composed of multiple clusters have been getting more frequent, so as to provide higher workload isolation, resource availability flexibility and scalability for application deployment. However, manually configuring their security may lead to inconsistencies among policies defined in different clusters, or it may require knowledge that the administrator of each domain cannot have. Therefore, this paper proposes an automatic approach for the automatic generation of the network security policies to be deployed in each cluster of a multi-domain Kubernetes deployment. The objectives of this approach are to reduce of configuration errors that human administrators commonly make, and to create transparent cross-cluster communications. This approach has been implemented as a framework named Multi-Cluster Orchestrator, which has been validated in realistic use cases to assess its benefits to Kubernetes orchestration.},
	pages = {480--485},
	journaltitle = {2023 {IEEE} 9th International Conference on Network Softwarization ({NetSoft})},
	author = {Bringhenti, Daniele and Sisto, Riccardo and Valenza, Fulvio},
	urldate = {2025-04-08},
	date = {2023-06-19},
	note = {Conference Name: 2023 {IEEE} 9th International Conference on Network Softwarization ({NetSoft})
{ISBN}: 9798350399806
Place: Madrid, Spain
Publisher: {IEEE}},
}

@article{hammar_digital_2023,
	title = {Digital Twins for Security Automation},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10154288/},
	doi = {10.1109/NOMS56928.2023.10154288},
	abstract = {We present a novel emulation system for creating high-fidelity digital twins of {IT} infrastructures. The digital twins replicate key functionality of the corresponding infrastructures and allow to play out security scenarios in a safe environment. We show that this capability can be used to automate the process of finding effective security policies for a target infrastructure. In our approach, a digital twin of the target infrastructure is used to run security scenarios and collect data. The collected data is then used to instantiate simulations of Markov decision processes and learn effective policies through reinforcement learning, whose performances are validated in the digital twin. This closed-loop learning process executes iteratively and provides continuously evolving and improving security policies. We apply our approach to an intrusion response scenario. Our results show that the digital twin provides the necessary evaluative feedback to learn near-optimal intrusion response policies.},
	pages = {1--6},
	journaltitle = {{NOMS} 2023-2023 {IEEE}/{IFIP} Network Operations and Management Symposium},
	author = {Hammar, Kim and Stadler, Rolf},
	urldate = {2025-04-08},
	date = {2023-05-08},
	note = {Conference Name: {NOMS} 2023-2023 {IEEE}/{IFIP} Network Operations and Management Symposium
{ISBN}: 9781665477161
Place: Miami, {FL}, {USA}
Publisher: {IEEE}},
}

@article{surathunmanun_exploring_2024,
	title = {Exploring the Role of Generative Artificial Intelligence in the Energy Sector: A Comprehensive Literature Review},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10795598/},
	doi = {10.1109/ICUE63019.2024.10795598},
	shorttitle = {Exploring the Role of Generative Artificial Intelligence in the Energy Sector},
	abstract = {Generative Artificial Intelligence ({GenAI}) enhances productivity by creating data, forecasting, optimizing, and understanding human language. In the energy sector, it is projected to have a \$240 billion global economic impact, though research remains limited. This paper reviews {GenAI}'s benefits, challenges, and research gaps in the energy sector, also focusing on climate change efforts. A {PRISMA}-{SCR}-based literature review from January 2022 to May 2024 was conducted using {IEEE} Xplore, {ScienceDirect}, {ACM} Digital Library, and Google Scholar. {GenAI} tools extracted data, verified by researchers. Analysis of 33 papers shows {GenAI} excels in knowledge integration and prediction. It generates synthetic electricity demand data, manages grids, forecasts energy demand, and optimizes renewable energy systems. Key challenges include hallucinations, data biases, privacy concerns, misuse, and system errors. Solutions involve improving training data, system fine-tuning, human oversight, and security measures. Research gaps include synthetic data realism, model evaluation standards, and integrating {GenAI} with blockchain and {IoT}.},
	pages = {1--11},
	journaltitle = {2024 International Conference on Sustainable Energy: Energy Transition and Net-Zero Climate Future ({ICUE})},
	author = {Surathunmanun, Surasak and Ongsakul, Weerakorn and Singh, Jai Govind},
	urldate = {2025-04-08},
	date = {2024-10-21},
	note = {Conference Name: 2024 International Conference on Sustainable Energy: Energy Transition and Net-Zero Climate Future ({ICUE})
{ISBN}: 9798331517076
Place: Pattaya City, Thailand
Publisher: {IEEE}},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/T6QIN8FX/69dd137c561619884ee4aecd95f81a351b7ce328.html:text/html},
}

@online{noauthor_securing_nodate,
	title = {Securing Generative {AI}: Introduction to the Generative {AI} Security Scoping Matrix},
	url = {https://aws.amazon.com/ai/generative-ai/security/scoping-matrix/},
	shorttitle = {Securing Generative {AI}},
	abstract = {Explore how to secure generative {AI} applications with {AWS}. This webpage introduces the Generative {AI} Security Scoping Matrix, providing essential guidelines for securing {AI} infrastructure, models, and applications. Learn best practices for implementing effective security measures to protect your {AI} investments.},
	titleaddon = {Amazon Web Services, Inc.},
	urldate = {2025-04-09},
	langid = {american},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/PPEMLSLJ/scoping-matrix.html:text/html},
}

@online{resources_australias_2024,
	title = {Australia’s {AI} Ethics Principles {\textbar} Australia’s Artificial Intelligence Ethics Principles {\textbar} Department of Industry Science and Resources},
	url = {https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-principles/australias-ai-ethics-principles},
	abstract = {Consider these voluntary principles to ensure {AI} is safe, secure and reliable.},
	titleaddon = {https://www.industry.gov.au/node/91877},
	author = {Resources, Department of Industry Science and},
	urldate = {2025-04-09},
	date = {2024-10-11},
	langid = {australian},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/EYMMH8PS/australias-ai-ethics-principles.html:text/html},
}

@online{noauthor_isoiec_nodate,
	title = {{ISO}/{IEC} 38500:2024},
	url = {https://www.iso.org/standard/81684.html},
	shorttitle = {{ISO}/{IEC} 38500},
	abstract = {Information technology — Governance of {IT} for the organization},
	titleaddon = {{ISO}},
	urldate = {2025-04-09},
	langid = {english},
	file = {d11300:/Users/d.veragilliard/Zotero/storage/HBJ39RQS/d11300.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/UU4JNT3B/81684.html:text/html},
}

@article{zhou_study_2010,
	title = {The study on network intrusion detection system of Snort},
	doi = {10.1109/ICNDS.2010.5479341},
	abstract = {Network security is a complex and systematic project. The intrusion detection system is the first line of defense against network security. Snort is a famous intrusion detection system in the field of open source software. It is widely used in the intrusion prevention and detection domain in the world. In this paper, we explain how Snort implements the intrusion detection, which includes building the compiling environment and analysizing the work-flow and rule tree. This paper will provide a valuable reference for the study of Snort.},
	author = {Zhou, Zhimin and Zhongwen, Chen and Tiecheng, Zhou and Xiaohui, Guan},
	date = {2010-05-01},
}

@article{page_prisma_2021,
	title = {The {PRISMA} 2020 statement: an updated guideline for reporting systematic reviews},
	issn = {1756-1833},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.n71},
	doi = {10.1136/bmj.n71},
	shorttitle = {The {PRISMA} 2020 statement},
	abstract = {{POINTS} To ensure a systematic review is valuable to users, authors should prepare a transparent, complete, and accurate account of why the review was done, what they did, and what they found The {PRISMA} 2020 statement provides updated reporting guidance for systematic reviews that reflects advances in methods to identify, select, appraise, and synthesise studies The {PRISMA} 2020 statement consists of a 27-item checklist, an expanded checklist that details reporting recommendations for each item, the {PRISMA} 2020 abstract checklist, and revised flow diagrams for original and updated reviews We anticipate that the {PRISMA} 2020 statement will benefit authors, editors, and peer reviewers of systematic reviews, and different users of reviews, including guideline developers, policy makers, healthcare providers, patients, and other stakeholders {BMJ}: {firPsrtopteucbtliesdhbeyd} caosp1y0r.i1g1h3t,6/ibncmlju.ndi7n1gofnor2u9sMesarrcehla2te02d1t.{oDtoexwtnalonadddeadtafromimnihnttg},{psA}:I//twrawinwi.nbgm, ja.cnodms/imoinla1r2teAcphrinlo2l0o2gi5ebs.y guest.},
	pages = {n71},
	journaltitle = {{BMJ}},
	author = {Page, Matthew J and {McKenzie}, Joanne E and Bossuyt, Patrick M and Boutron, Isabelle and Hoffmann, Tammy C and Mulrow, Cynthia D and Shamseer, Larissa and Tetzlaff, Jennifer M and Akl, Elie A and Brennan, Sue E and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M and Hróbjartsson, Asbjørn and Lalu, Manoj M and Li, Tianjing and Loder, Elizabeth W and Mayo-Wilson, Evan and {McDonald}, Steve and {McGuinness}, Luke A and Stewart, Lesley A and Thomas, James and Tricco, Andrea C and Welch, Vivian A and Whiting, Penny and Moher, David},
	urldate = {2025-04-12},
	date = {2021-03-29},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/29PKSQ2J/Page et al. - 2021 - The PRISMA 2020 statement an updated guideline for reporting systematic reviews.pdf:application/pdf},
}
