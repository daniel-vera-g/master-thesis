
@article{weedon_generative_2023,
	title = {Generative {AI}: security implications for business automation},
	volume = {2023},
	issn = {1353-4858, 1872-9371},
	url = {http://www.magonlinelibrary.com/doi/10.12968/S1353-4858%2823%2970045-7},
	doi = {10.12968/S1353-4858(23)70045-7},
	shorttitle = {Generative {AI}},
	abstract = {{AI} tools such as {ChatGPT} certainly appear to offer significant benefits to organisations looking to save costs and improve efficiency. But the technology is being adopted with an enthusiasm that leaves little room for the careful consideration of potential security vulnerabilities. So how do you embrace this revolution without putting yourself at risk?},
	pages = {S1353--4858(23)70045--7},
	number = {9},
	journaltitle = {Network Security},
	author = {Weedon, Scott},
	urldate = {2024-09-07},
	date = {2023-09},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/3ICS935N/ba42b88132000be4ea8cf6b9a119f6b71d0b07f1.html:text/html},
}

@misc{haryanto_secgenai_2024,
	title = {{SecGenAI}: Enhancing Security of Cloud-based Generative {AI} Applications within Australian Critical Technologies of National Interest},
	url = {http://arxiv.org/abs/2407.01110},
	doi = {10.48550/arXiv.2407.01110},
	shorttitle = {{SecGenAI}},
	abstract = {The rapid advancement of Generative {AI} ({GenAI}) technologies offers transformative opportunities within Australia's critical technologies of national interest while introducing unique security challenges. This paper presents {SecGenAI}, a comprehensive security framework for cloud-based {GenAI} applications, with a focus on Retrieval-Augmented Generation ({RAG}) systems. {SecGenAI} addresses functional, infrastructure, and governance requirements, integrating end-to-end security analysis to generate specifications emphasizing data privacy, secure deployment, and shared responsibility models. Aligned with Australian Privacy Principles, {AI} Ethics Principles, and guidelines from the Australian Cyber Security Centre and Digital Transformation Agency, {SecGenAI} mitigates threats such as data leakage, adversarial attacks, and model inversion. The framework's novel approach combines advanced machine learning techniques with robust security measures, ensuring compliance with Australian regulations while enhancing the reliability and trustworthiness of {GenAI} systems. This research contributes to the field of intelligent systems by providing actionable strategies for secure {GenAI} implementation in industry, fostering innovation in {AI} applications, and safeguarding national interests.},
	number = {{arXiv}:2407.01110},
	publisher = {{arXiv}},
	author = {Haryanto, Christoforus Yoga and Vu, Minh Hieu and Nguyen, Trung Duc and Lomempow, Emily and Nurliana, Yulia and Taheri, Sona},
	urldate = {2024-08-26},
	date = {2024-07-01},
	eprinttype = {arxiv},
	eprint = {2407.01110 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Cryptography and Security, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/d.veragilliard/Zotero/storage/Y87CT6NW/Haryanto et al. - 2024 - SecGenAI Enhancing Security of Cloud-based Genera.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/7S4ZGDKG/2407.html:text/html},
}

@article{senior_software_engineer_cisco_systems_inc_usa_next-gen_2024,
	title = {Next-Gen Firewalls: Enhancing Cloud Security with Generative {AI}},
	volume = {3},
	url = {https://www.onlinescientificresearch.com/articles/nextgen-firewalls-enhancing-cloud-security-with-generative-ai.pdf},
	doi = {10.47363/JAICC/2024(3)404},
	shorttitle = {Next-Gen Firewalls},
	abstract = {Next-generation firewalls are available and use machine learning and generative modeling to enhance the detection of hard-to-detect cyber threats. These systems incorporate advanced security controls, policies, and protocols with Layer 7 of the {OSI} model. This chapter updates these steep {AI}-based protection systems and applications.},
	pages = {1--9},
	number = {4},
	journaltitle = {J Arti Inte \& Cloud Comp},
	author = {{Senior Software Engineer, Cisco Systems Inc, USA} and Lekkala, Seshagirirao},
	urldate = {2025-03-31},
	date = {2024-08-30},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/D9LSZDNH/4373239ca9de9d5ab0dbf0b2e60bf1885beca545.html:text/html},
}

@article{patel_generative_2025,
	title = {Generative {AI} for Automated Security Operations in Cloud Computing},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10849302/},
	doi = {10.1109/ICAIC63015.2025.10849302},
	abstract = {New opportunities in cloud computing have brought many new risks that require effective protection of dynamic distributed environments. Introducing a new formative technology, generative {AI}, to cloud security has far-reaching benefits for automating threat detection, real-time incident addressing, and vulnerability management. This paper focuses on extending generative {AI} with cloud security tools like {AWS} {GuardDuty} and Google Cloud Security Command Center; the contemplation of accuracy enhancement and response efficiency highlights its aim. Concerning actual applications such as {SOAR} systems, the study demonstrates how media industry giants, such as Netflix and {JPMorgan} Chase, have used {AI} to minimize risk factors while increasing operational efficiency. The paper also discusses the significant increase in response time, enhanced detection accuracy, and the shift to proactive security strategies brought by generative {AI}. Drawing attention to {AI} systems’ opportunities, the study examines the subsequent issues connected with {AI} applications, including over-dependence on {AI} tools, adversarial risk to models, and the complex nature of decisionmaking in the context of {AI} systems. The present study also highlights the importance of generative {AI} in strengthening the defense of the cloud environment, but, at the same time, it recognizes the significance of preventive efforts and planned action plans to manage these technologies efficiently.},
	pages = {1--7},
	journaltitle = {2025 {IEEE} 4th International Conference on {AI} in Cybersecurity ({ICAIC})},
	author = {Patel, Advait and Pandey, Pravin and Ragothaman, Hariharan and Molleti, Ramasankar and Peddinti, Diwakar Reddy},
	urldate = {2025-03-31},
	date = {2025-02-05},
	note = {Conference Name: 2025 {IEEE} 4th International Conference on {AI} in Cybersecurity ({ICAIC})
{ISBN}: 9798331518882
Place: Houston, {TX}, {USA}
Publisher: {IEEE}},
}

@article{seth_ai_2025,
	title = {{AI} and Generative {AI}-Driven Automation for Multi-Cloud and Hybrid Cloud Architectures: Enhancing Security, Performance, and Operational Efficiency},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10903928/},
	doi = {10.1109/CCWC62904.2025.10903928},
	shorttitle = {{AI} and Generative {AI}-Driven Automation for Multi-Cloud and Hybrid Cloud Architectures},
	abstract = {The emergence of cloud and hybrid cloud structures presents {eCommerce} firms with the adaptability and robustness needed to manage expansion and varying user requirements effectively. However, this also brings about challenges concerning security enhancements, distribution of workloads, and cost-effectiveness optimization. Traditional cloud management models often need help to meet these evolving demands efficiently. This research presents a system that leverages Artificial Intelligence ({AI}) and Generative {AI} (Gen {AI}) to effectively automate and enhance cloud and hybrid infrastructures for ecommerce websites. The system adapts infrastructure to traffic times like holidays or sales events by utilizing {AI} to scale resources as needed. It conserves resources during low user activity periods such as overnight. Ensuring optimal system performance and availability during peak traffic times while cutting costs during traffic periods is essential for cost-effectiveness and efficient resource management. In addition, {AI}-powered security automation safeguards against changing cyber dangers, and compliance automation guarantees conformity with rules like {PCI} {DSS} for payment handling. This report also delves into merging Gen {AI} into cloud coordination systems, facilitating workflows, and enhancing {eCommerce} processes. The outcome is a significant drop in operational expenses, a quicker service rollout, and decreased security breaches. Through real-world {eCommerce} case studies, this paper provides actionable insights for cloud engineers and architects on leveraging {AI}-driven cloud management to enhance performance, security, and cost-efficiency in multi-cloud and hybrid environments, ensuring seamless user experiences and business continuity.},
	pages = {00784--00793},
	journaltitle = {2025 {IEEE} 15th Annual Computing and Communication Workshop and Conference ({CCWC})},
	author = {Seth, Dhruv Kumar and Ratra, Karan Kumar and Sundareswaran, Aneeshkumar P},
	urldate = {2025-04-08},
	date = {2025-01-06},
	note = {Conference Name: 2025 {IEEE} 15th Annual Computing and Communication Workshop and Conference ({CCWC})
{ISBN}: 9798331507695
Place: Las Vegas, {NV}, {USA}
Publisher: {IEEE}},
}

@article{khanna_enhancing_2024,
	title = {{ENHANCING} {CLOUD} {SECURITY} {WITH} {GENERATIVE} {AI}: {EMERGING} {STRATEGIES} {AND} {APPLICATIONS}},
	volume = {3},
	issn = {2295-5152},
	url = {https://iaeme.com/Home/article_id/JARET_03_01_021},
	shorttitle = {{ENHANCING} {CLOUD} {SECURITY} {WITH} {GENERATIVE} {AI}},
	abstract = {This article explores the potential of generative {AI} for enhancing cloud security. With the rapid adoption of cloud technologies and the increasing sophistication of cyber threats, traditional security measures often struggle to keep pace. Generative {AI}, with its ability to learn from vast amounts of data and generate intelligent outputs, presents a powerful tool to address these challenges. The article delves into the fundamentals of generative {AI} and its specific applications in cloud security, including anomaly detection, threat intelligence, and automated response mechanisms. It also discusses the challenges and future directions in this field, highlighting the need for large and diverse datasets, addressing adversarial attacks, improving model interpretability, and considering the ethical implications of using generative {AI} in cloud security.},
	pages = {234--244},
	number = {1},
	journaltitle = {{JARET}},
	author = {Khanna, Karan},
	urldate = {2025-04-08},
	date = {2024-06-14},
	langid = {english},
	note = {Number: 1
Publisher: {IAEME} Publication},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/WATZ45IV/Khanna - 2024 - ENHANCING CLOUD SECURITY WITH GENERATIVE AI EMERGING STRATEGIES AND APPLICATIONS.pdf:application/pdf},
}

@online{noauthor_securing_2023,
	title = {Securing generative {AI}: An introduction to the Generative {AI} Security Scoping Matrix {\textbar} {AWS} Security Blog},
	url = {https://aws.amazon.com/blogs/security/securing-generative-ai-an-introduction-to-the-generative-ai-security-scoping-matrix/},
	shorttitle = {Securing generative {AI}},
	urldate = {2025-04-08},
	date = {2023-10-19},
	langid = {american},
	note = {Section: Amazon Bedrock},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/748SVXTA/securing-generative-ai-an-introduction-to-the-generative-ai-security-scoping-matrix.html:text/html},
}

@report{tabassi_artificial_2023,
	location = {Gaithersburg, {MD}},
	title = {Artificial Intelligence Risk Management Framework ({AI} {RMF} 1.0)},
	url = {http://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf},
	abstract = {As directed by the National Artificial Intelligence Initiative Act of 2020 (P.L. 116-283), the goal of the {AI} {RMF} is to offer a resource to the organizations designing, developing, deploying, or using {AI} systems to help manage the many risks of {AI} and promote trustworthy and responsible development and use of {AI} systems. The Framework is intended to be voluntary, rights-preserving, non-sector specific, and use-case agnostic, providing flexibility to organizations of all sizes and in all sectors and throughout society to implement the approaches in the Framework.   The {AI} {RMF} is intended to be practical, to adapt to the {AI} landscape as {AI} technologies continue to develop, and to be operationalized by organizations in varying degrees and capacities so society can benefit from {AI} while also being protected from its potential harms.},
	pages = {NIST AI 100--1},
	number = {{NIST} {AI} 100-1},
	institution = {National Institute of Standards and Technology (U.S.)},
	author = {Tabassi, Elham},
	urldate = {2025-04-08},
	date = {2023-01-26},
	langid = {english},
	doi = {10.6028/NIST.AI.100-1},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/IFJQD782/Tabassi - 2023 - Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf:application/pdf;PDF:/Users/d.veragilliard/Zotero/storage/5EPR3V9L/Tabassi - 2023 - Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf:application/pdf},
}

@article{nyoto_cyber_2024,
	title = {Cyber Security Risks in the Rapid Development of Generative Artificial Intelligence: A Systematic Literature Review},
	volume = {1},
	issn = {3063-0630},
	url = {https://journal.unilak.ac.id/index.php/ComniTech/article/view/24539},
	shorttitle = {Cyber Security Risks in the Rapid Development of Generative Artificial Intelligence},
	abstract = {This study aims to identify the cybersecurity risks arising from the use of Generative Artificial Intelligence ({GenAI}). By employing a systematic literature review ({SLR}) method and following the {PRISMA} 2020 guidelines, this research systematically selects and analyzes relevant literature to discover and understand the risks associated with the use of {GenAI}. From the seventeen studies successfully collected and reviewed, various cybersecurity risks were identified, including phishing attacks, social engineering, ransomware, malware, deepfakes, misinformation, data leakage, misuse of personal data, executable attack code generation, privacy risks, and intellectual property violations. These findings provide crucial insights into the potential threats that may emerge from the irresponsible use of {GenAI}. The study is designed to offer valuable information for various stakeholders in their risk mitigation efforts and in the development of relevant regulations concerning the ethical use of {GenAI}. It is hoped that these findings will serve as a solid foundation for developing more effective security strategies and policies to address the challenges posed by this technology, and encourage the implementation of improved protective measures to tackle emerging risks.},
	pages = {57--66},
	number = {2},
	journaltitle = {{ComniTech} : Journal of Computational Intelligence and Informatics},
	author = {Nyoto, Rebecca La Volla and Devega, Mariza and Nyoto, Nyoto},
	urldate = {2025-04-08},
	date = {2024-12-29},
	langid = {english},
	keywords = {cybersecurity, generative artificial intelligence ({GenAI}), systematic literature review.},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/9VNR6T4Q/Nyoto et al. - 2024 - Cyber Security Risks in the Rapid Development of Generative Artificial Intelligence A Systematic Li.pdf:application/pdf},
}

@misc{yigit_review_2024,
	title = {Review of Generative {AI} Methods in Cybersecurity},
	url = {http://arxiv.org/abs/2403.08701},
	doi = {10.48550/arXiv.2403.08701},
	abstract = {Over the last decade, Artificial Intelligence ({AI}) has become increasingly popular, especially with the use of chatbots such as {ChatGPT}, Gemini, and {DALL}-E. With this rise, large language models ({LLMs}) and Generative {AI} ({GenAI}) have also become more prevalent in everyday use. These advancements strengthen cybersecurity's defensive posture and open up new attack avenues for adversaries as well. This paper provides a comprehensive overview of the current state-of-the-art deployments of {GenAI}, covering assaults, jailbreaking, and applications of prompt injection and reverse psychology. This paper also provides the various applications of {GenAI} in cybercrimes, such as automated hacking, phishing emails, social engineering, reverse cryptography, creating attack payloads, and creating malware. {GenAI} can significantly improve the automation of defensive cyber security processes through strategies such as dataset construction, safe code development, threat intelligence, defensive measures, reporting, and cyberattack detection. In this study, we suggest that future research should focus on developing robust ethical norms and innovative defense mechanisms to address the current issues that {GenAI} creates and to also further encourage an impartial approach to its future application in cybersecurity. Moreover, we underscore the importance of interdisciplinary approaches further to bridge the gap between scientific developments and ethical considerations.},
	number = {{arXiv}:2403.08701},
	publisher = {{arXiv}},
	author = {Yigit, Yagmur and Buchanan, William J. and Tehrani, Madjid G. and Maglaras, Leandros},
	urldate = {2025-04-08},
	date = {2024-03-19},
	eprinttype = {arxiv},
	eprint = {2403.08701 [cs]},
	keywords = {Computer Science - Cryptography and Security},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/93NDWF8C/Yigit et al. - 2024 - Review of Generative AI Methods in Cybersecurity.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/P2VFTJVJ/2403.html:text/html},
}

@incollection{feffer_red-teaming_2025,
	title = {Red-Teaming for Generative {AI}: Silver Bullet or Security Theater?},
	shorttitle = {Red-Teaming for Generative {AI}},
	abstract = {In response to rising concerns surrounding the safety, security, and trustworthiness of Generative {AI} ({GenAI}) models, practitioners and regulators alike have pointed to {AI} red-teaming as a key component of their strategies for identifying and mitigating these risks. However, despite {AI} red-teaming's central role in policy discussions and corporate messaging, significant questions remain about what precisely it means, what role it can play in regulation, and how it relates to conventional red-teaming practices as originally conceived in the field of cybersecurity. In this work, we identify recent cases of red-teaming activities in the {AI} industry and conduct an extensive survey of relevant research literature to characterize the scope, structure, and criteria for {AI} red-teaming practices. Our analysis reveals that prior methods and practices of {AI} red-teaming diverge along several axes, including the purpose of the activity (which is often vague), the artifact under evaluation, the setting in which the activity is conducted (e.g., actors, resources, and methods), and the resulting decisions it informs (e.g., reporting, disclosure, and mitigation). In light of our findings, we argue that while red-teaming may be a valuable big-tent idea for characterizing {GenAI} harm mitigations, and that industry may effectively apply red-teaming and other strategies behind closed doors to safeguard {AI}, gestures towards red-teaming (based on public definitions) as a panacea for every possible risk verge on security theater. To move toward a more robust toolbox of evaluations for generative {AI}, we synthesize our recommendations into a question bank meant to guide and scaffold future {AI} red-teaming practices.},
	pages = {421--437},
	booktitle = {Proceedings of the 2024 {AAAI}/{ACM} Conference on {AI}, Ethics, and Society},
	publisher = {{AAAI} Press},
	author = {Feffer, Michael and Sinha, Anusha and Deng, Wesley H. and Lipton, Zachary C. and Heidari, Hoda},
	urldate = {2025-04-08},
	date = {2025-02-07},
}

@article{vootkuri_multi-cloud_2024,
	title = {Multi-Cloud Data Strategy \& Security for Generative {AI}},
	volume = {12},
	abstract = {The rapid growth of generative artificial intelligence has fundamentally changed the requirements for cloud computing infrastructure, including requisites such as innovative approaches to resource management and development strategies. A multi-cloud strategy involves leveraging multiple cloud providers to execute an application to optimize data management, storage, and processing capabilities for training and inference. This comprehensive research paper aims to study the evolving paradigm of multi-cloud strategies tailored for Generative Artificial intelligence (Gen-{AI}) using the multi-cloud platforms to enhance their infrastructure, reliability, and security and how the costs are optimized by effectively reducing vendor lock-ins and provide a chance to strategically leverage a variety of providers and their skills to meet specific company demands. The paper demonstrates multi cloud data strategy and security frameworks for Gen {AI} applications. The research discusses how to protect {GenAI} using different strategies in enterprise ecosystems.},
	number = {1},
	author = {Vootkuri, Chaitanya},
	date = {2024},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/UWZHX4FU/Vootkuri - 2024 - Multi-Cloud Data Strategy & Security for Generative AI.pdf:application/pdf},
}

@article{sushil_prabhu_prabhakaran_integration_2024,
	title = {Integration Patterns in Unified {AI} and Cloud Platforms: A Systematic Review of Process Automation Technologies},
	volume = {10},
	rights = {https://creativecommons.org/licenses/by/4.0},
	issn = {2456-3307},
	url = {https://ijsrcseit.com/index.php/home/article/view/CSEIT241061229},
	doi = {10.32628/CSEIT241061229},
	shorttitle = {Integration Patterns in Unified {AI} and Cloud Platforms},
	abstract = {This article comprehensively analyzes unified {AI} and cloud platforms, examining their role in transforming process automation and decision systems across industries. The article investigates the architectural frameworks and integration patterns that enable the convergence of {AI} tools, machine learning operations, and workflow orchestration within cloud-native environments. The article explores key innovations, including federated {AI} implementations, real-time data processing architectures, and multi-cloud integration patterns. It provides insights into their practical applications across finance, healthcare, retail, and manufacturing sectors. The article identifies critical success factors in platform implementation, including integrating {MLOps} frameworks, automated decision engines, and compliance tools for {AI} governance. Through case study analysis and architectural evaluation, we demonstrate how unified platforms address traditional challenges in {AI} deployment while enabling scalable, cost-efficient solutions. The findings reveal emerging patterns in platform architecture that facilitate seamless integration of edge computing, real-time analytics, and distributed {AI} systems, contributing to the broader understanding of enterprise {AI} implementation strategies. This article provides valuable insights for researchers and practitioners in cloud engineering, artificial intelligence, and systems integration while highlighting future directions for platform evolution and standardization.},
	pages = {1932--1940},
	number = {6},
	journaltitle = {Int. J. Sci. Res. Comput. Sci. Eng. Inf. Technol},
	author = {{Sushil Prabhu Prabhakaran}},
	urldate = {2025-04-08},
	date = {2024-12-15},
}

@article{bringhenti_security_2023,
	title = {Security automation for multi-cluster orchestration in Kubernetes},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10175419/},
	doi = {10.1109/NetSoft57336.2023.10175419},
	abstract = {In the latest years, multi-domain Kubernetes architectures composed of multiple clusters have been getting more frequent, so as to provide higher workload isolation, resource availability flexibility and scalability for application deployment. However, manually configuring their security may lead to inconsistencies among policies defined in different clusters, or it may require knowledge that the administrator of each domain cannot have. Therefore, this paper proposes an automatic approach for the automatic generation of the network security policies to be deployed in each cluster of a multi-domain Kubernetes deployment. The objectives of this approach are to reduce of configuration errors that human administrators commonly make, and to create transparent cross-cluster communications. This approach has been implemented as a framework named Multi-Cluster Orchestrator, which has been validated in realistic use cases to assess its benefits to Kubernetes orchestration.},
	pages = {480--485},
	journaltitle = {2023 {IEEE} 9th International Conference on Network Softwarization ({NetSoft})},
	author = {Bringhenti, Daniele and Sisto, Riccardo and Valenza, Fulvio},
	urldate = {2025-04-08},
	date = {2023-06-19},
	note = {Conference Name: 2023 {IEEE} 9th International Conference on Network Softwarization ({NetSoft})
{ISBN}: 9798350399806
Place: Madrid, Spain
Publisher: {IEEE}},
}

@article{hammar_digital_2023,
	title = {Digital Twins for Security Automation},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10154288/},
	doi = {10.1109/NOMS56928.2023.10154288},
	abstract = {We present a novel emulation system for creating high-fidelity digital twins of {IT} infrastructures. The digital twins replicate key functionality of the corresponding infrastructures and allow to play out security scenarios in a safe environment. We show that this capability can be used to automate the process of finding effective security policies for a target infrastructure. In our approach, a digital twin of the target infrastructure is used to run security scenarios and collect data. The collected data is then used to instantiate simulations of Markov decision processes and learn effective policies through reinforcement learning, whose performances are validated in the digital twin. This closed-loop learning process executes iteratively and provides continuously evolving and improving security policies. We apply our approach to an intrusion response scenario. Our results show that the digital twin provides the necessary evaluative feedback to learn near-optimal intrusion response policies.},
	pages = {1--6},
	journaltitle = {{NOMS} 2023-2023 {IEEE}/{IFIP} Network Operations and Management Symposium},
	author = {Hammar, Kim and Stadler, Rolf},
	urldate = {2025-04-08},
	date = {2023-05-08},
	note = {Conference Name: {NOMS} 2023-2023 {IEEE}/{IFIP} Network Operations and Management Symposium
{ISBN}: 9781665477161
Place: Miami, {FL}, {USA}
Publisher: {IEEE}},
}

@article{surathunmanun_exploring_2024,
	title = {Exploring the Role of Generative Artificial Intelligence in the Energy Sector: A Comprehensive Literature Review},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10795598/},
	doi = {10.1109/ICUE63019.2024.10795598},
	shorttitle = {Exploring the Role of Generative Artificial Intelligence in the Energy Sector},
	abstract = {Generative Artificial Intelligence ({GenAI}) enhances productivity by creating data, forecasting, optimizing, and understanding human language. In the energy sector, it is projected to have a \$240 billion global economic impact, though research remains limited. This paper reviews {GenAI}'s benefits, challenges, and research gaps in the energy sector, also focusing on climate change efforts. A {PRISMA}-{SCR}-based literature review from January 2022 to May 2024 was conducted using {IEEE} Xplore, {ScienceDirect}, {ACM} Digital Library, and Google Scholar. {GenAI} tools extracted data, verified by researchers. Analysis of 33 papers shows {GenAI} excels in knowledge integration and prediction. It generates synthetic electricity demand data, manages grids, forecasts energy demand, and optimizes renewable energy systems. Key challenges include hallucinations, data biases, privacy concerns, misuse, and system errors. Solutions involve improving training data, system fine-tuning, human oversight, and security measures. Research gaps include synthetic data realism, model evaluation standards, and integrating {GenAI} with blockchain and {IoT}.},
	pages = {1--11},
	journaltitle = {2024 International Conference on Sustainable Energy: Energy Transition and Net-Zero Climate Future ({ICUE})},
	author = {Surathunmanun, Surasak and Ongsakul, Weerakorn and Singh, Jai Govind},
	urldate = {2025-04-08},
	date = {2024-10-21},
	note = {Conference Name: 2024 International Conference on Sustainable Energy: Energy Transition and Net-Zero Climate Future ({ICUE})
{ISBN}: 9798331517076
Place: Pattaya City, Thailand
Publisher: {IEEE}},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/T6QIN8FX/69dd137c561619884ee4aecd95f81a351b7ce328.html:text/html},
}

@online{noauthor_securing_nodate,
	title = {Securing Generative {AI}: Introduction to the Generative {AI} Security Scoping Matrix},
	url = {https://aws.amazon.com/ai/generative-ai/security/scoping-matrix/},
	shorttitle = {Securing Generative {AI}},
	abstract = {Explore how to secure generative {AI} applications with {AWS}. This webpage introduces the Generative {AI} Security Scoping Matrix, providing essential guidelines for securing {AI} infrastructure, models, and applications. Learn best practices for implementing effective security measures to protect your {AI} investments.},
	titleaddon = {Amazon Web Services, Inc.},
	urldate = {2025-04-09},
	langid = {american},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/PPEMLSLJ/scoping-matrix.html:text/html},
}

@online{resources_australias_2024,
	title = {Australia’s {AI} Ethics Principles {\textbar} Australia’s Artificial Intelligence Ethics Principles {\textbar} Department of Industry Science and Resources},
	url = {https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-principles/australias-ai-ethics-principles},
	abstract = {Consider these voluntary principles to ensure {AI} is safe, secure and reliable.},
	titleaddon = {https://www.industry.gov.au/node/91877},
	author = {Resources, Department of Industry Science and},
	urldate = {2025-04-09},
	date = {2024-10-11},
	langid = {australian},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/EYMMH8PS/australias-ai-ethics-principles.html:text/html},
}

@online{noauthor_isoiec_nodate,
	title = {{ISO}/{IEC} 38500:2024},
	url = {https://www.iso.org/standard/81684.html},
	shorttitle = {{ISO}/{IEC} 38500},
	abstract = {Information technology — Governance of {IT} for the organization},
	titleaddon = {{ISO}},
	urldate = {2025-04-09},
	langid = {english},
	file = {d11300:/Users/d.veragilliard/Zotero/storage/HBJ39RQS/d11300.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/UU4JNT3B/81684.html:text/html},
}

@article{zhou_study_2010,
	title = {The study on network intrusion detection system of Snort},
	doi = {10.1109/ICNDS.2010.5479341},
	abstract = {Network security is a complex and systematic project. The intrusion detection system is the first line of defense against network security. Snort is a famous intrusion detection system in the field of open source software. It is widely used in the intrusion prevention and detection domain in the world. In this paper, we explain how Snort implements the intrusion detection, which includes building the compiling environment and analysizing the work-flow and rule tree. This paper will provide a valuable reference for the study of Snort.},
	author = {Zhou, Zhimin and Zhongwen, Chen and Tiecheng, Zhou and Xiaohui, Guan},
	date = {2010-05-01},
}

@article{page_prisma_2021,
	title = {The {PRISMA} 2020 statement: an updated guideline for reporting systematic reviews},
	issn = {1756-1833},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.n71},
	doi = {10.1136/bmj.n71},
	shorttitle = {The {PRISMA} 2020 statement},
	abstract = {{POINTS} To ensure a systematic review is valuable to users, authors should prepare a transparent, complete, and accurate account of why the review was done, what they did, and what they found The {PRISMA} 2020 statement provides updated reporting guidance for systematic reviews that reflects advances in methods to identify, select, appraise, and synthesise studies The {PRISMA} 2020 statement consists of a 27-item checklist, an expanded checklist that details reporting recommendations for each item, the {PRISMA} 2020 abstract checklist, and revised flow diagrams for original and updated reviews We anticipate that the {PRISMA} 2020 statement will benefit authors, editors, and peer reviewers of systematic reviews, and different users of reviews, including guideline developers, policy makers, healthcare providers, patients, and other stakeholders {BMJ}: {firPsrtopteucbtliesdhbeyd} caosp1y0r.i1g1h3t,6/ibncmlju.ndi7n1gofnor2u9sMesarrcehla2te02d1t.{oDtoexwtnalonadddeadtafromimnihnttg},{psA}:I//twrawinwi.nbgm, ja.cnodms/imoinla1r2teAcphrinlo2l0o2gi5ebs.y guest.},
	pages = {n71},
	journaltitle = {{BMJ}},
	author = {Page, Matthew J and {McKenzie}, Joanne E and Bossuyt, Patrick M and Boutron, Isabelle and Hoffmann, Tammy C and Mulrow, Cynthia D and Shamseer, Larissa and Tetzlaff, Jennifer M and Akl, Elie A and Brennan, Sue E and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M and Hróbjartsson, Asbjørn and Lalu, Manoj M and Li, Tianjing and Loder, Elizabeth W and Mayo-Wilson, Evan and {McDonald}, Steve and {McGuinness}, Luke A and Stewart, Lesley A and Thomas, James and Tricco, Andrea C and Welch, Vivian A and Whiting, Penny and Moher, David},
	urldate = {2025-04-12},
	date = {2021-03-29},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/29PKSQ2J/Page et al. - 2021 - The PRISMA 2020 statement an updated guideline for reporting systematic reviews.pdf:application/pdf},
}

@article{mell_nist_nodate,
	title = {The {NIST} Definition of Cloud Computing},
	author = {Mell, Peter and Grance, Timothy},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/63CCNWW2/Mell and Grance - The NIST Definition of Cloud Computing.pdf:application/pdf},
}

@misc{abimbola_cloud_2021,
	title = {Cloud Computing Concept and Roots},
	url = {http://arxiv.org/abs/2102.00981},
	doi = {10.48550/arXiv.2102.00981},
	abstract = {Cloud computing is a particular implementation of distributed computing. It inherited many properties of distributed computing such as scalability, reliability and distribution transparency. The transparency middle layer abstracts the underlying platform away from the end user. Virtualization technology is the foundation of Cloud computing. Virtual machine provides abstraction of the physical server resources and securely isolates different users in multi-tenant environment. To the Cloud services consumer, all the computing power and resources are accessed through high speed internet access by client platforms. This eliminates the cost to build and maintain local data center. Resource pooling and rapid elasticity are the main characters of Cloud computing. The scalability of Cloud computing comes from resources which can span multiple data centers and geographic regions. There is virtually no limitation on the amount of resources available from Cloud. New processing and storage resources can be added into the Cloud resource pool seamlessly.},
	number = {{arXiv}:2102.00981},
	publisher = {{arXiv}},
	author = {Abimbola, Bola},
	urldate = {2025-04-15},
	date = {2021-02-09},
	eprinttype = {arxiv},
	eprint = {2102.00981 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/9ITFYC7G/Abimbola - 2021 - Cloud Computing Concept and Roots.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/6NP6GTQI/2102.html:text/html},
}

@inproceedings{nikita_enterprise_2023,
	title = {Enterprise Security Architecture For Cloud Computing: A Review},
	url = {https://ieeexplore.ieee.org/document/10307676},
	doi = {10.1109/ICCCNT56998.2023.10307676},
	shorttitle = {Enterprise Security Architecture For Cloud Computing},
	abstract = {Cloud computing has transformed {IT} in recent years by isolating application and data resources from foundational structures. Providing high-quality service, however, necessitates guaranteeing cloud computing security. Security risks develop when apps run outside of the defined firewall and into the public domain. Any security compromise in a cloud component might be catastrophic for both the organization (the client) and the supplier. As a result, we present in this study a framework and technique for cloud security that can detect cloud computing security concerns.},
	eventtitle = {2023 14th International Conference on Computing Communication and Networking Technologies ({ICCCNT})},
	pages = {1--7},
	booktitle = {2023 14th International Conference on Computing Communication and Networking Technologies ({ICCCNT})},
	author = {Nikita, Nikita and Parashar, Gaurav},
	urldate = {2025-04-15},
	date = {2023-07},
	note = {{ISSN}: 2473-7674},
	keywords = {Cloud computing, Cloud computing security, Computer architecture, Data protection, Firewalls (computing), Network security, Organizations, Security Architecture, Security Frameworks, Stars},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/WADIF3DE/10307676.html:text/html},
}

@article{moura_review_nodate,
	title = {Review and Analysis of Networking Challenges in Cloud Computing},
	author = {Moura, Jose},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/JRK8RUIK/Moura - Review and Analysis of Networking Challenges in Cloud Computing.pdf:application/pdf},
}

@online{blog_blueprint_2024,
	title = {Blueprint for {AI} Agents in Cybersecurity},
	url = {https://www.cybersec-automation.com/p/blueprint-for-ai-agents-in-cybersecurity},
	abstract = {Leveraging {AI} Agents to Evolve Cybersecurity Practices},
	titleaddon = {Cyber Security Automation and Orchestration},
	author = {Blog, Cyber Automation \{and\} Autonomous {SOC}},
	urldate = {2025-04-18},
	date = {2024-07-11},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/Q8TCUBKF/blueprint-for-ai-agents-in-cybersecurity.html:text/html},
}

@online{noauthor_agentic_nodate,
	title = {Agentic {AI} Threat Modeling Framework: {MAESTRO} {\textbar} {CSA}},
	url = {https://cloudsecurityalliance.org/blog/2025/02/06/agentic-ai-threat-modeling-framework-maestro},
	shorttitle = {Agentic {AI} Threat Modeling Framework},
	abstract = {{MAESTRO} (Multi-Agent Environment, Security, Threat, Risk, \& Outcome) is a novel threat modeling framework for Agentic {AI}. Assess risks across the {AI} lifecycle.},
	urldate = {2025-04-18},
}

@online{noauthor_cyber_nodate,
	title = {Cyber Swarm: the rise of the machines Potential application of {AI} agents in offensive and defensive cybersecurity},
	url = {https://eviden.com/publications/digital-security-magazine/ai-and-cybersecurity/ai-agents-system-2-thinking/},
	shorttitle = {Cyber Swarm},
	abstract = {Explore the concept of System 2 thinking, its application through multi-agent systems, and their roles in strengthening offensive and defensive cybersecurity},
	titleaddon = {Eviden},
	urldate = {2025-04-18},
	langid = {american},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/D5NY9QWF/ai-agents-system-2-thinking.html:text/html},
}

@article{ramasankar_molleti_automated_2024,
	title = {Automated threat detection and response using {LLM} agents},
	volume = {24},
	issn = {25819615},
	url = {https://wjarr.com/node/15847},
	doi = {10.30574/wjarr.2024.24.2.3329},
	abstract = {The increase of cyber threats from individual cases to a worldwide problem is the reason why people have shifted their cybersecurity perspectives. Basic defense processes, originally well understood and effective, fail to match modern attacks’ complexity and velocity. Taking into consideration {LLMs} as a recent addition to {AI}, this paper aims at discussing their application in integrating threat detection and response automation systems. As a result, {LLMs}, which have higher capabilities for natural language processing, deliver a revolutionary perspective regarding cybersecurity. Since {LLM} agents can review massive amounts of security data, distinguish patterns, and create contextually appropriate responses, they can bridge the gap between emerging threats and stable security systems. The paper examines the tools used by {LLM} agents, such as natural language processing to analyse the logs, contextual anomaly detection, pattern identification in network traffic, and the analysis of the user’s behaviour. Also, it describes how {LLM} agents can support automated threat handling in the context of threat identification, alert prioritization, context-driven response generation, security policy enforcement, and threat handling. The integration of {LLM} agents into already known systems, including {SIEM} systems and {AI}-Ops platforms, is also considered, which allows for further conclusions on the opportunities to create proactive cybersecurity systems. However, open dilemmas such as adversarial attacks and interpretability are still present, the future for {LLM} agents in cybersecurity is still bright, and there are more possibilities in multi-modal threat analysis and quantum-safe {LLM}-based cryptography.},
	pages = {079--090},
	number = {2},
	journaltitle = {World J. Adv. Res. Rev.},
	author = {{Ramasankar Molleti} and {Vinod Goje} and {Puneet Luthra} and {Prathap Raghavan}},
	urldate = {2025-04-18},
	date = {2024-11-30},
}

@article{kaswan_generative_2023,
	title = {Generative {AI}: A Review on Models and Applications},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10421601/},
	doi = {10.1109/ICCSAI59793.2023.10421601},
	shorttitle = {Generative {AI}},
	abstract = {Generative Artificial Intelligence ({AI}) stands as a transformative paradigm in machine learning, enabling the creation of complex and realistic data from latent representations. This review paper comprehensively surveys the landscape of Generative {AI}, encompassing its foundational concepts, diverse models, training methodologies, applications, challenges, recent advancements, evaluation metrics, and ethical dimensions. The paper begins by introducing Generative {AI}'s significance across various domains, presenting its pivotal role in producing synthetic data with applications spanning image synthesis, text generation, music composition, drug discovery, and more. The objectives lie in elucidating the foundational concepts, delving into model intricacies, unveiling the training procedures, exploring its application landscape, addressing challenges, envisioning future directions, and discussing ethical ramifications. The foundational section elucidates the diverse array of generative models, including Generative Adversarial Networks ({GANs}), Variational Autoencoders ({VAEs}), flow-based models, Generative Reinforcement Learning ({GRL}), and advanced hybrid architectures. Subsequently, evaluation metrics ranging from Inception Score to perceptual similarity metrics and human evaluations are surveyed to assess generative model performance. Finally, ethical considerations underscore the necessity for addressing biases, misuse, intellectual property concerns, and the call for responsible {AI} development and regulation in the Generative {AI} landscape.},
	pages = {699--704},
	journaltitle = {2023 International Conference on Communication, Security and Artificial Intelligence ({ICCSAI})},
	author = {Kaswan, Kuldeep Singh and Dhatterwal, Jagjit Singh and Malik, Kiran and Baliyan, Anupam},
	urldate = {2025-04-18},
	date = {2023-11-23},
	note = {Conference Name: 2023 International Conference on Communication, Security and Artificial Intelligence ({ICCSAI})
{ISBN}: 9798350369960
Place: Greater Noida, India
Publisher: {IEEE}},
}

@article{gatla_advancements_2024,
	title = {Advancements in Generative {AI}: Exploring Fundamentals and Evolution},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10594003/},
	doi = {10.1109/ICECCC61767.2024.10594003},
	shorttitle = {Advancements in Generative {AI}},
	abstract = {Generative Artificial Intelligence ({AI}) has emerged as a transformative field with far-reaching implications across various domains. This review manuscript provides a advancements in generative {AI}, focusing on its fundamental concepts, methodologies, and evolutionary trends. We begin by elucidating the foundational principles underlying generative {AI} techniques, including autoregressive models, Variational Autoencoders ({VAEs}), and Generative Adversarial Networks ({GANs}). Subsequently, we delve into the evolution of generative {AI}, discussing recent advancements, challenges, and potential future directions. Through an in-depth analysis of research literature and real-world applications, this manuscript aims to offer insights into the current landscape of generative {AI} and its profound impact on diverse sectors.},
	pages = {1--5},
	journaltitle = {2024 International Conference on Electronics, Computing, Communication and Control Technology ({ICECCC})},
	author = {Gatla, Ranjith Kumar and Gatla, Anitha and Sridhar, Patti and Kumar, Devineni Gireesh and Rao, D S Naga Malleswara},
	urldate = {2025-04-18},
	date = {2024-05-02},
	note = {Conference Name: 2024 International Conference on Electronics, Computing, Communication and Control Technology ({ICECCC})
{ISBN}: 9798350371802
Place: Bengaluru, India
Publisher: {IEEE}},
}

@online{noauthor_generative_nodate,
	title = {Generative Artificial Intelligence: A Systematic Review and Applications},
	url = {https://arxiv.org/html/2405.11029v1},
	urldate = {2025-04-18},
	file = {Generative Artificial Intelligence\: A Systematic Review and Applications:/Users/d.veragilliard/Zotero/storage/FEFNVU47/2405.html:text/html},
}

@misc{vaswani_attention_2023,
	title = {Attention Is All You Need},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 {BLEU} on the {WMT} 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 {BLEU}. On the {WMT} 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art {BLEU} score of 41.8 after training for 3.5 days on eight {GPUs}, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	number = {{arXiv}:1706.03762},
	publisher = {{arXiv}},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	urldate = {2025-04-18},
	date = {2023-08-02},
	eprinttype = {arxiv},
	eprint = {1706.03762 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/UE4FQBLZ/Vaswani et al. - 2023 - Attention Is All You Need.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/4Y7WG8PL/1706.html:text/html},
}

@misc{goodfellow_generative_2014,
	title = {Generative Adversarial Networks},
	url = {http://arxiv.org/abs/1406.2661},
	doi = {10.48550/arXiv.1406.2661},
	abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
	number = {{arXiv}:1406.2661},
	publisher = {{arXiv}},
	author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	urldate = {2025-04-18},
	date = {2014-06-10},
	eprinttype = {arxiv},
	eprint = {1406.2661 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/BTTJYYPT/Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/IJBL4GLQ/1406.html:text/html},
}

@article{vijay_ramamoorthi_review_2024,
	title = {A Review of {AI} and Multi-Agent Systems for Cloud Performance and Security},
	volume = {10},
	rights = {https://creativecommons.org/licenses/by/4.0},
	issn = {2456-3307},
	url = {https://ijsrcseit.com/index.php/home/article/view/CSEIT24105112},
	doi = {10.32628/CSEIT24105112},
	abstract = {Cloud computing has become a critical backbone for distributed systems, offering scalability and flexibility across diverse industries. However, ensuring optimal performance and robust security in such dynamic environments presents significant challenges, including inefficient task scheduling, suboptimal resource utilization, and persistent security threats such as data breaches and Distributed Denial of Service ({DDoS}) attacks. This paper examines the transformative potential of Artificial Intelligence ({AI}) and Multi-Agent Systems ({MAS}) in addressing these complexities. {AI}-driven solutions, including real-time anomaly detection, predictive analytics, and resource optimization, are combined with {MAS} frameworks that leverage decentralized, autonomous agents for distributed decision-making and proactive threat mitigation. The integration of {AI} and {MAS} enables dynamic adaptation to workload fluctuations, enhances resource efficiency, and provides robust security measures in multi-cloud and large-scale systems. The paper further explores key challenges in implementing these technologies, such as scalability and integration across heterogeneous environments, and identifies promising research directions to advance their adoption. By synthesizing empirical evidence and recent advancements, this study highlights the critical role of {AI} and {MAS} in shaping the future of cloud performance and security.},
	pages = {326--337},
	number = {4},
	journaltitle = {Int. J. Sci. Res. Comput. Sci. Eng. Inf. Technol},
	author = {{Vijay Ramamoorthi}},
	urldate = {2025-04-18},
	date = {2024-07-15},
}

@article{kalava_best_2024,
	title = {Best {AI} Framework Guide: Build Production-Ready Agents That Work},
	volume = {03},
	issn = {25836129},
	url = {https://isjem.com/download/best-ai-framework-guide-build-production-ready-agents-that-work/},
	doi = {10.55041/ISJEM02191},
	shorttitle = {Best {AI} Framework Guide},
	abstract = {Artificial Intelligence ({AI}) frameworks serve as the foundation for building scalable, production-ready {AI} agents
that enable automation, decision-making, and intelligent interactions. This paper explores the architecture, core
components, and best practices for selecting, deploying, and optimizing {AI} agent frameworks. Additionally, it
addresses security considerations, compliance standards, performance enhancements, and real-world integration
strategies for enterprise adoption.
Keywords
Artificial Intelligence, {AI} Agents, Automation, Scalability, Security, Optimization, Enterprise {AI}},
	pages = {1--9},
	number = {12},
	journaltitle = {{ISJEM}},
	author = {Kalava, Sudheer Peddineni},
	urldate = {2025-04-18},
	date = {2024-12-17},
}

@online{hansen_introducing_2023,
	title = {Introducing Google’s Secure {AI} Framework},
	url = {https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/},
	abstract = {Today Google released released the Secure {AI} Framework to help collaboratively secure {AI} technology.},
	titleaddon = {Google},
	author = {Hansen, Royal and Venables, Phil},
	urldate = {2025-04-25},
	date = {2023-06-08},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/TC3VRHGX/introducing-googles-secure-ai-framework.html:text/html},
}

@online{editor_llm_nodate,
	title = {{LLM} Applications Cybersecurity and Governance Checklist v1.1 - English},
	url = {https://genai.owasp.org/resource/llm-applications-cybersecurity-and-governance-checklist-english/},
	abstract = {The {OWASP} Top 10 for {LLM} Applications Cybersecurity and Governance Checklist is for leaders across executive, tech, cybersecurity, privacy, compliance, and legal areas, {DevSecOps}, {MLSecOps}, and Cybersecurity teams and defenders. It is intended for people who are striving to stay ahead in the fast-moving {AI} world, aiming not just to leverage {AI} for corporate success […]},
	titleaddon = {{OWASP} Top 10 for {LLM} \& Generative {AI} Security},
	author = {Editor, {OWASPGenAIProject}},
	urldate = {2025-04-27},
	langid = {american},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/YDXV4DIE/llm-applications-cybersecurity-and-governance-checklist-english.html:text/html},
}

@online{editor_llm_nodate-1,
	title = {{LLM} and Generative {AI} Security Center of Excellence Guide},
	url = {https://genai.owasp.org/resource/llm-and-generative-ai-security-center-of-excellence-guide/},
	abstract = {As generative {AI} technologies evolve and integrate into various aspects of business and society, the need for robust governance, security, and policy management becomes paramount. Establishing a Center of Excellence ({COE}) for Generative {AI} Security aims to bring together diverse groups such as security, legal, data science, operations, and end-users to foster collaboration, develop best […]},
	titleaddon = {{OWASP} Top 10 for {LLM} \& Generative {AI} Security},
	author = {Editor, {OWASPGenAIProject}},
	urldate = {2025-04-27},
	langid = {american},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/9UE7J798/llm-and-generative-ai-security-center-of-excellence-guide.html:text/html},
}

@article{pillala_devsecops_2024,
	title = {{DevSecOps} Sentinel: {GenAI}-Driven Agentic Workflows for Comprehensive Supply Chain Security},
	volume = {18},
	rights = {Copyright (c) 2024 Gyani Pillala,Damoon Azarpazhooh,Scott Baxter},
	issn = {1913-8989},
	url = {https://ccsenet.org/journal/index.php/cis/article/view/0/51118},
	doi = {10.5539/cis.v18n1p39},
	shorttitle = {{DevSecOps} Sentinel},
	abstract = {A growing number of security challenges are born out of the complexity of modern software supply chains that span microservices, containerization, and cloud-native architectures. The increasing rate of new cyber-threats, and the need to quickly deploy software updates after a security incident, typically outpaces traditional {DevSecOps} security practices. In this paper, we propose a novel {DevSecOps} Sentinel system, which employs Generative {AI} ({GenAI}) driven agentic workflows to improve software supply chain security holistically.

In this paper, we elaborate on the architecture of {DevSecOps} Sentinel: by integrating cutting-edge {GenAI} models, and by deploying intelligent agentic workflows. Then we dive into how the system impacts our software development life cycle from code writing to production and beyond. Our results indicate that agentic workflows powered by {GenAI} are a viable method to tackle the intricate security issues of modern software supply chains. Integrating the analysis capability of {AI} and marrying this with the strengths that come from agentic systems, {DevSecOps} Sentinel reveals a way forward for organizations seeking to strengthen their security profile in an ever more hostile digital world - to build better software — faster, safer, and reliable.},
	pages = {p39},
	number = {1},
	journaltitle = {Computer and Information Science},
	author = {Pillala, Gyani and Azarpazhooh, Damoon and Baxter, Scott},
	urldate = {2025-04-27},
	date = {2024-12-20},
	langid = {english},
	note = {Number: 1},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/BPBW7V3V/Pillala et al. - 2024 - DevSecOps Sentinel GenAI-Driven Agentic Workflows for Comprehensive Supply Chain Security.pdf:application/pdf},
}

@misc{dash_zero-trust_2024,
	location = {Rochester, {NY}},
	title = {Zero-Trust Architecture ({ZTA}): Designing an {AI}-Powered Cloud Security Framework for {LLMs}' Black Box Problems},
	url = {https://papers.ssrn.com/abstract=4726625},
	doi = {10.2139/ssrn.4726625},
	shorttitle = {Zero-Trust Architecture ({ZTA})},
	abstract = {Businesses are becoming more interested in developing and testing Large Language Models ({LLMs}) in their own settings to support decision-making and growth as a result of the rapid emergence of {AI} and cloud computing. Here's the dilemma, though: to what extent do you believe these models and the data they were trained on? We don't know the feature list of an {LLM}, which presents the first obstacle when discussing trust and the reasons why there should be zero trust. Although it may seem a bit extreme, this is accurate for two reasons. When it comes to {GenAI} models nowadays, the more multimodal and more capabilities they have, the better. This way of thinking is great for exploring and confirming if {GenAI} can address a business problem, but it's a surefire way to run into trouble when attempting to put things into production in an organizational setting. An enterprise cybersecurity architecture known as a zero-trust architecture ({ZTA}) is built on the ideas of zero trust and is intended to stop data breaches, enhance privacy, and restrict internal lateral movement. This article discusses {ZTA}, its logical aspects, probable deployment scenarios, {AI} rules, threats and limitations in order to provide a detailed understanding of why enterprises must adapt a {ZTA} framework in a cloud-based environment for {AI} model deployment.},
	number = {4726625},
	publisher = {Social Science Research Network},
	author = {Dash, Bibhu},
	urldate = {2025-04-27},
	date = {2024-03-12},
	langid = {english},
	keywords = {{AI}-Powered framework, Black Box, {CCPA}, {GDPR}, {IPP}, {LLM}, {PDP}, Zero Trust},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/5ITUH79R/Dash - 2024 - Zero-Trust Architecture (ZTA) Designing an AI-Powered Cloud Security Framework for LLMs' Black Box.pdf:application/pdf},
}

@inproceedings{ismail_big_2025,
	title = {Big Data Architecture for Large Organizations},
	url = {https://www.semanticscholar.org/paper/Big-Data-Architecture-for-Large-Organizations-Ismail-Sengupta/4c954e46ecc91d41e554afba14d3a294b07b7e5e},
	abstract = {The exponential growth of big data has transformed how large organisations leverage information to drive innovation, optimise processes, and maintain competitive advantages. However, managing and extracting insights from vast, heterogeneous data sources requires a scalable, secure, and well-integrated big data architecture. This paper proposes a comprehensive big data framework that aligns with organisational objectives while ensuring flexibility, scalability, and governance. The architecture encompasses multiple layers, including data ingestion, transformation, storage, analytics, machine learning, and security, incorporating emerging technologies such as Generative {AI} ({GenAI}) and low-code machine learning. Cloud-based implementations across Google Cloud, {AWS}, and Microsoft Azure are analysed, highlighting their tools and capabilities. Additionally, this study explores advancements in big data architecture, including {AI}-driven automation, data mesh, and Data Ocean paradigms. By establishing a structured, adaptable framework, this research provides a foundational blueprint for large organisations to harness big data as a strategic asset effectively.},
	author = {Ismail, Fathima Nuzla and Sengupta, Abira and Amarasoma, Shanika},
	urldate = {2025-06-09},
	date = {2025-05-07},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/II2WH5JS/Ismail et al. - 2025 - Big Data Architecture for Large Organizations.pdf:application/pdf},
}

@misc{hayagreevan_security_2024,
	title = {Security of and by Generative {AI} platforms},
	url = {http://arxiv.org/abs/2410.13899},
	doi = {10.48550/arXiv.2410.13899},
	abstract = {This whitepaper highlights the dual importance of securing generative {AI} ({genAI}) platforms and leveraging {genAI} for cybersecurity. As {genAI} technologies proliferate, their misuse poses significant risks, including data breaches, model tampering, and malicious content generation. Securing these platforms is critical to protect sensitive data, ensure model integrity, and prevent adversarial attacks. Simultaneously, {genAI} presents opportunities for enhancing security by automating threat detection, vulnerability analysis, and incident response. The whitepaper explores strategies for robust security frameworks around {genAI} systems, while also showcasing how {genAI} can empower organizations to anticipate, detect, and mitigate sophisticated cyber threats.},
	number = {{arXiv}:2410.13899},
	publisher = {{arXiv}},
	author = {Hayagreevan, Hari and Khamaru, Souvik},
	urldate = {2025-06-09},
	date = {2024-10-15},
	eprinttype = {arxiv},
	eprint = {2410.13899 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/FUB78C6M/Hayagreevan and Khamaru - 2024 - Security of and by Generative AI platforms.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/Q2RG8AVP/2410.html:text/html},
}

@misc{noseevich_towards_2015,
	title = {Towards automated web application logic reconstruction for application level security},
	url = {http://arxiv.org/abs/1511.02564},
	doi = {10.48550/arXiv.1511.02564},
	abstract = {Modern overlay security mechanisms like Web Application Firewalls ({WAF}) suffer from inability to recognize custom high-level application logic and data objects, which results in low accuracy, high false positives rates, and overhelming manual effort for fine tuning. In this paper we propose an approach to web application modeling for security purposes that could help next-generation {WAFs} to adapt to specific web applications, and do it automatically whenever possible. We aim at creating multi-layer models that adequately simulate various aspects of web application functionality that are significant for intrusion detection and prevention, including request parsing and routing, reconstruction of actions and data objects, and action interdependencies.},
	number = {{arXiv}:1511.02564},
	publisher = {{arXiv}},
	author = {Noseevich, George and Gamayunov, Dennis},
	urldate = {2025-06-09},
	date = {2015-11-09},
	eprinttype = {arxiv},
	eprint = {1511.02564 [cs]},
	keywords = {Computer Science - Cryptography and Security},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/C54WINRY/Noseevich and Gamayunov - 2015 - Towards automated web application logic reconstruction for application level security.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/F76YUPCQ/1511.html:text/html},
}

@inproceedings{desai_gen-ai_2024,
	title = {Gen-{AI} for User Safety: A Survey},
	url = {http://arxiv.org/abs/2411.06606},
	doi = {10.1109/BigData62323.2024.10825656},
	shorttitle = {Gen-{AI} for User Safety},
	abstract = {Machine Learning and data mining techniques (i.e. supervised and unsupervised techniques) are used across domains to detect user safety violations. Examples include classifiers used to detect whether an email is spam or a web-page is requesting bank login information. However, existing {ML}/{DM} classifiers are limited in their ability to understand natural languages w.r.t the context and nuances. The aforementioned challenges are overcome with the arrival of Gen-{AI} techniques, along with their inherent ability w.r.t translation between languages, fine-tuning between various tasks and domains. In this manuscript, we provide a comprehensive overview of the various work done while using Gen-{AI} techniques w.r.t user safety. In particular, we first provide the various domains (e.g. phishing, malware, content moderation, counterfeit, physical safety) across which Gen-{AI} techniques have been applied. Next, we provide how Gen-{AI} techniques can be used in conjunction with various data modalities i.e. text, images, videos, audio, executable binaries to detect violations of user-safety. Further, also provide an overview of how Gen-{AI} techniques can be used in an adversarial setting. We believe that this work represents the first summarization of Gen-{AI} techniques for user-safety.},
	pages = {5315--5324},
	booktitle = {2024 {IEEE} International Conference on Big Data ({BigData})},
	author = {Desai, Akshar Prabhu and Ravi, Tejasvi and Luqman, Mohammad and Sharma, Mohit and Kota, Nithya and Yadav, Pranjul},
	urldate = {2025-06-09},
	date = {2024-12-15},
	eprinttype = {arxiv},
	eprint = {2411.06606 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/CDXZPFDL/Desai et al. - 2024 - Gen-AI for User Safety A Survey.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/UZGFQ34D/2411.html:text/html},
}

@misc{ling_enhancing_2024,
	title = {Enhancing Security Control Production With Generative {AI}},
	url = {http://arxiv.org/abs/2411.04284},
	doi = {10.48550/arXiv.2411.04284},
	abstract = {Security controls are mechanisms or policies designed for cloud based services to reduce risk, protect information, and ensure compliance with security regulations. The development of security controls is traditionally a labor-intensive and time-consuming process. This paper explores the use of Generative {AI} to accelerate the generation of security controls. We specifically focus on generating Gherkin codes which are the domain-specific language used to define the behavior of security controls in a structured and understandable format. By leveraging large language models and in-context learning, we propose a structured framework that reduces the time required for developing security controls from 2-3 days to less than one minute. Our approach integrates detailed task descriptions, step-by-step instructions, and retrieval-augmented generation to enhance the accuracy and efficiency of the generated Gherkin code. Initial evaluations on {AWS} cloud services demonstrate promising results, indicating that {GenAI} can effectively streamline the security control development process, thus providing a robust and dynamic safeguard for cloud-based infrastructures.},
	number = {{arXiv}:2411.04284},
	publisher = {{arXiv}},
	author = {Ling, Chen and Ghashami, Mina and Gao, Vianne and Torkamani, Ali and Vaulin, Ruslan and Mangam, Nivedita and Jain, Bhavya and Diwan, Farhan and {SS}, Malini and Cheng, Mingrui and Kumar, Shreya Tarur and Candelario, Felix},
	urldate = {2025-06-09},
	date = {2024-11-06},
	eprinttype = {arxiv},
	eprint = {2411.04284 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/63MHB3Y2/Ling et al. - 2024 - Enhancing Security Control Production With Generative AI.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/D5NYMBMI/2411.html:text/html},
}

@inproceedings{chen_platform-specific_2025,
	title = {Platform-specific code generation method for the Tyche embedded operating system based on {AADL} models},
	volume = {13545},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13545/1354517/Platform-specific-code-generation-method-for-the-Tyche-embedded-operating/10.1117/12.3061113.full},
	doi = {10.1117/12.3061113},
	abstract = {The Tyche Embedded Operating System is a highly customized real-time embedded operating system, widely applied in fields such as aerospace, medical devices, and industrial automation. Renowned for its robust support for real-time tasks and efficient resource management, this system has become a core technology in embedded system development. The Architecture Analysis and Design Language ({AADL}), as a stringent standardized modeling language, possesses powerful expressiveness and scalability. This paper proposes a method for generating platform-specific code for the Tyche Embedded Operating System based on {AADL} models, which involves describing complex systems through {AADL} modeling and generating safety-critical software suitable for the Tyche Embedded Operating System. Firstly, the paper elaborates on the key aspects of the {AADL} standard and adheres to these aspects for modeling safety-critical systems. Secondly, an intermediate layer is introduced, outlining the mapping rules from the {AADL} common subset to the intermediate code, generating intermediate code for each component within the system architecture, and ultimately compiling it into C code applicable to the Tyche platform. Finally, a prototype tool for code generation is provided, and the effectiveness of the proposed method is validated through a case study of a temperature control system.},
	eventtitle = {Third International Conference on Algorithms, Network, and Communication Technology ({ICANCT} 2024)},
	pages = {328--340},
	booktitle = {Third International Conference on Algorithms, Network, and Communication Technology ({ICANCT} 2024)},
	publisher = {{SPIE}},
	author = {Chen, Li and Jia, Zhangtao and An, Heng and Li, Haoyu},
	urldate = {2025-06-10},
	date = {2025-03-03},
}

@article{kumar_generative_nodate,
	title = {Generative {AI} in Software Architecture: Transforming Design and Development Processes},
	volume = {16},
	rights = {Creative Commons Attribution-{ShareAlike} 4.0 International License},
	issn = {2229-7677},
	url = {https://www.ijsat.org/research-paper.php?id=3718},
	doi = {10.71097/IJSAT.v16.i1.3718},
	shorttitle = {Generative {AI} in Software Architecture},
	number = {1},
	journaltitle = {{IJSAT} - International Journal on Science and Technology},
	author = {Kumar, Ritesh},
	urldate = {2025-06-10},
	note = {Publisher: {IJSAT}},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/L7W95BUV/Kumar - Generative AI in Software Architecture Transforming Design and Development Processes.pdf:application/pdf},
}

@inproceedings{ismail_big_2025-1,
	title = {Big Data Architecture for Large Organizations},
	url = {https://www.semanticscholar.org/paper/Big-Data-Architecture-for-Large-Organizations-Ismail-Sengupta/4c954e46ecc91d41e554afba14d3a294b07b7e5e},
	abstract = {The exponential growth of big data has transformed how large organisations leverage information to drive innovation, optimise processes, and maintain competitive advantages. However, managing and extracting insights from vast, heterogeneous data sources requires a scalable, secure, and well-integrated big data architecture. This paper proposes a comprehensive big data framework that aligns with organisational objectives while ensuring flexibility, scalability, and governance. The architecture encompasses multiple layers, including data ingestion, transformation, storage, analytics, machine learning, and security, incorporating emerging technologies such as Generative {AI} ({GenAI}) and low-code machine learning. Cloud-based implementations across Google Cloud, {AWS}, and Microsoft Azure are analysed, highlighting their tools and capabilities. Additionally, this study explores advancements in big data architecture, including {AI}-driven automation, data mesh, and Data Ocean paradigms. By establishing a structured, adaptable framework, this research provides a foundational blueprint for large organisations to harness big data as a strategic asset effectively.},
	author = {Ismail, Fathima Nuzla and Sengupta, Abira and Amarasoma, Shanika},
	urldate = {2025-06-10},
	date = {2025-05-07},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/EBP9KYNF/Ismail et al. - 2025 - Big Data Architecture for Large Organizations.pdf:application/pdf},
}

@inproceedings{chavan_automation_2024,
	title = {Automation of {AD}-{OHC} Dashbord and Monitoring of Cloud Resources using Genrative {AI} to Reduce Costing and Enhance Performance},
	url = {https://ieeexplore.ieee.org/document/10616299},
	doi = {10.1109/ICICET59348.2024.10616299},
	abstract = {In this extensive review, the incorporation of Generative Artificial Intelligence ({AI}) into ad-hoc dashboards and cloud resource monitoring is investigated in depth. A purpose of this work is to investigate a current research and highlight the transformational potential of generative artificial intelligence for optimising costs, automating tasks, and improving overall cost efficiency. This article includes a comprehensive analysis of a development of ad-hoc cloud computing, a relevance of cloud resource monitoring, and the role that generative artificial intelligence plays in reducing costs. Notable advantages include better user satisfaction, resource optimisation, adaptive learning, and efficient automation. Additionally, precise decision-making and resource optimisation are highlighted. By presenting actual evidence, the study highlights the association between the quality of generative artificial intelligence and the influence it has on society. It finishes with an analysis of generative artificial intelligence applications in ad-hoc dashboards, with a focus on increased resource utilisation, scalability, and timely consistency of cloud resources. In addition, the article addresses constraints and makes suggestions for future paths. These include models that protect users’ privacy, efficient resource utilisation, explainable artificial intelligence, dynamic autonomy, and security-driven generative models. The paper’s goal is to provide the groundwork for further study and improvement.},
	eventtitle = {2024 International Conference on Innovations and Challenges in Emerging Technologies ({ICICET})},
	pages = {1--9},
	booktitle = {2024 International Conference on Innovations and Challenges in Emerging Technologies ({ICICET})},
	author = {Chavan, Parikshit and Chavan, Peeyusha},
	urldate = {2025-06-10},
	date = {2024-06},
	keywords = {{AD}-{OHC} Dashbord, Automation, Cloud computing, Cloud Computing, Cloud Monitoring., Cloud Resources, Cost Reductions, Costs, Generative {AI}, Resource management, Scalability, Technological innovation},
}

@article{lo_increased_2024,
	title = {Increased Productivity and Reduced Waste with Robotic Process Automation and Generative {AI}-powered {IoE} Services},
	rights = {Copyright (c) 2024 Journal of Web Engineering},
	issn = {1544-5976},
	url = {https://journals.riverpublishers.com/index.php/JWE/},
	doi = {10.13052/jwe1540-9589.2313},
	abstract = {The convergence of robotic process automation ({RPA}) and generative {AI} ({GAI}) within the context of Internet of Everything ({IoE}) services represents a profound paradigm shift. This fusion of technologies not only streamlines routine tasks but also catalyzes innovation while harnessing the potential of interconnected devices. Such integration empowers organizations to achieve remarkable gains in efficiency and sustainability. This paper embarks on an exploration of these transformative services, designed to elevate productivity, and curtail wasteful practices in contemporary industries. By closely examining intricate case studies, we illuminate the multifaceted advantages of this integrated approach. Our investigation demonstrates how {RPA} accelerates the execution of repetitive processes, substantially diminishing the margin for human error and amplifying operational efficiency. In contrast, generative {AI} introduces a disruptive force, generating fresh ideas, designs, and solutions, thereby elevating the quality of products and services. The infusion of these cutting-edge technologies into the fabric of {IoE} services paves the way for organizations to attain unprecedented levels of automation, intelligence, and connectivity. Furthermore, this paper comprehensively addresses the intricate challenges and considerations associated with the proposed implementation. We delve into ethical concerns, security implications, and the necessary workforce adaptation to offer a balanced perspective on the adoption of these technologies. Additionally, we navigate through potential limitations and constraints, underscoring the imperative need for strategic planning and robust governance.},
	pages = {53--88},
	journaltitle = {Journal of Web Engineering},
	author = {Lo, Wei and Yang, Chun-Ming and Zhang, Qiansha and Li, Mingyuan},
	urldate = {2025-06-10},
	date = {2024-03-27},
	langid = {english},
	keywords = {waste management},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/LM6B6ER4/Lo et al. - 2024 - Increased Productivity and Reduced Waste with Robotic Process Automation and Generative AI-powered I.pdf:application/pdf},
}

@misc{barrett_actionable_2023,
	title = {Actionable Guidance for High-Consequence {AI} Risk Management: Towards Standards Addressing {AI} Catastrophic Risks},
	url = {http://arxiv.org/abs/2206.08966},
	doi = {10.48550/arXiv.2206.08966},
	shorttitle = {Actionable Guidance for High-Consequence {AI} Risk Management},
	abstract = {Artificial intelligence ({AI}) systems can provide many beneficial capabilities but also risks of adverse events. Some {AI} systems could present risks of events with very high or catastrophic consequences at societal scale. The {US} National Institute of Standards and Technology ({NIST}) has been developing the {NIST} Artificial Intelligence Risk Management Framework ({AI} {RMF}) as voluntary guidance on {AI} risk assessment and management for {AI} developers and others. For addressing risks of events with catastrophic consequences, {NIST} indicated a need to translate from high level principles to actionable risk management guidance. In this document, we provide detailed actionable-guidance recommendations focused on identifying and managing risks of events with very high or catastrophic consequences, intended as a risk management practices resource for {NIST} for {AI} {RMF} version 1.0 (released in January 2023), or for {AI} {RMF} users, or for other {AI} risk management guidance and standards as appropriate. We also provide our methodology for our recommendations. We provide actionable-guidance recommendations for {AI} {RMF} 1.0 on: identifying risks from potential unintended uses and misuses of {AI} systems; including catastrophic-risk factors within the scope of risk assessments and impact assessments; identifying and mitigating human rights harms; and reporting information on {AI} risk factors including catastrophic-risk factors. In addition, we provide recommendations on additional issues for a roadmap for later versions of the {AI} {RMF} or supplementary publications. These include: providing an {AI} {RMF} Profile with supplementary guidance for cutting-edge increasingly multi-purpose or general-purpose {AI}. We aim for this work to be a concrete risk-management practices contribution, and to stimulate constructive dialogue on how to address catastrophic risks and associated issues in {AI} standards.},
	number = {{arXiv}:2206.08966},
	publisher = {{arXiv}},
	author = {Barrett, Anthony M. and Hendrycks, Dan and Newman, Jessica and Nonnecke, Brandie},
	urldate = {2025-06-17},
	date = {2023-02-23},
	eprinttype = {arxiv},
	eprint = {2206.08966 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/TRQMFW6W/Barrett et al. - 2023 - Actionable Guidance for High-Consequence AI Risk Management Towards Standards Addressing AI Catastr.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/RYELLFI2/2206.html:text/html},
}

@article{zanzotto_human---loop_2019,
	title = {Human-in-the-loop Artificial Intelligence},
	volume = {64},
	issn = {1076-9757},
	url = {http://arxiv.org/abs/1710.08191},
	doi = {10.1613/jair.1.11345},
	abstract = {Little by little, newspapers are revealing the bright future that Artificial Intelligence ({AI}) is building. Intelligent machines will help everywhere. However, this bright future has a dark side: a dramatic job market contraction before its unpredictable transformation. Hence, in a near future, large numbers of job seekers will need financial support while catching up with these novel unpredictable jobs. This possible job market crisis has an antidote inside. In fact, the rise of {AI} is sustained by the biggest knowledge theft of the recent years. Learning {AI} machines are extracting knowledge from unaware skilled or unskilled workers by analyzing their interactions. By passionately doing their jobs, these workers are digging their own graves. In this paper, we propose Human-in-the-loop Artificial Intelligence ({HIT}-{AI}) as a fairer paradigm for Artificial Intelligence systems. {HIT}-{AI} will reward aware and unaware knowledge producers with a different scheme: decisions of {AI} systems generating revenues will repay the legitimate owners of the knowledge used for taking those decisions. As modern Robin Hoods, {HIT}-{AI} researchers should fight for a fairer Artificial Intelligence that gives back what it steals.},
	pages = {243--252},
	journaltitle = {jair},
	author = {Zanzotto, Fabio Massimo},
	urldate = {2025-06-17},
	date = {2019-02-10},
	eprinttype = {arxiv},
	eprint = {1710.08191 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/QP7ISIZ4/Zanzotto - 2019 - Human-in-the-loop Artificial Intelligence.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/4WXXLBSJ/1710.html:text/html},
}

@article{wu_survey_2022,
	title = {A Survey of Human-in-the-loop for Machine Learning},
	volume = {135},
	issn = {0167739X},
	url = {http://arxiv.org/abs/2108.00941},
	doi = {10.1016/j.future.2022.05.014},
	abstract = {Human-in-the-loop aims to train an accurate prediction model with minimum cost by integrating human knowledge and experience. Humans can provide training data for machine learning applications and directly accomplish tasks that are hard for computers in the pipeline with the help of machine-based approaches. In this paper, we survey existing works on human-in-the-loop from a data perspective and classify them into three categories with a progressive relationship: (1) the work of improving model performance from data processing, (2) the work of improving model performance through interventional model training, and (3) the design of the system independent human-in-the-loop. Using the above categorization, we summarize major approaches in the field; along with their technical strengths/ weaknesses, we have simple classification and discussion in natural language processing, computer vision, and others. Besides, we provide some open challenges and opportunities. This survey intends to provide a high-level summarization for human-in-the-loop and motivates interested readers to consider approaches for designing effective human-in-the-loop solutions.},
	pages = {364--381},
	journaltitle = {Future Generation Computer Systems},
	author = {Wu, Xingjiao and Xiao, Luwei and Sun, Yixuan and Zhang, Junhang and Ma, Tianlong and He, Liang},
	urldate = {2025-06-17},
	date = {2022-10},
	eprinttype = {arxiv},
	eprint = {2108.00941 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/YPAFM2DT/Wu et al. - 2022 - A Survey of Human-in-the-loop for Machine Learning.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/IWVQMSDD/2108.html:text/html},
}

@article{andrade_enhancing_2025,
	title = {Enhancing Security in Software Design Patterns and Antipatterns: A Framework for {LLM}-Based Detection},
	volume = {14},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/14/3/586},
	doi = {10.3390/electronics14030586},
	shorttitle = {Enhancing Security in Software Design Patterns and Antipatterns},
	abstract = {The detection of security vulnerabilities in software design patterns and antipatterns is crucial for maintaining robust and maintainable systems, particularly in dynamic Continuous Integration/Continuous Deployment ({CI}/{CD}) environments. Traditional static analysis tools, while effective for identifying isolated issues, often lack contextual awareness, leading to missed vulnerabilities and high rates of false positives. This paper introduces a novel framework leveraging Large Language Models ({LLMs}) to detect and mitigate security risks in design patterns and antipatterns. By analyzing relationships and behavioral dynamics in code, {LLMs} provide a nuanced, context-aware approach to identifying issues such as unauthorized state changes, insecure communication, and improper data handling. The proposed framework integrates key security heuristics—such as the principles of least privilege and input validation—to enhance {LLM} performance. An evaluation of the framework demonstrates its potential to outperform traditional tools in terms of accuracy and efficiency, enabling the proactive detection and remediation of vulnerabilities in real time. This study contributes to the field of software engineering by offering an innovative methodology for securing software systems using {LLMs}, promoting both academic research and practical application in industry settings.},
	pages = {586},
	number = {3},
	journaltitle = {Electronics},
	author = {Andrade, Roberto and Torres, Jenny and Ortiz-Garcés, Iván},
	urldate = {2025-06-18},
	date = {2025-01},
	langid = {english},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {antipatterns, {LLM}, software security},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/7LELERKQ/Andrade et al. - 2025 - Enhancing Security in Software Design Patterns and Antipatterns A Framework for LLM-Based Detection.pdf:application/pdf},
}

@article{andrade_enhancing_2025-1,
	title = {Enhancing Security in Software Design Patterns and Antipatterns: A Framework for {LLM}-Based Detection},
	volume = {14},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/14/3/586},
	doi = {10.3390/electronics14030586},
	shorttitle = {Enhancing Security in Software Design Patterns and Antipatterns},
	abstract = {The detection of security vulnerabilities in software design patterns and antipatterns is crucial for maintaining robust and maintainable systems, particularly in dynamic Continuous Integration/Continuous Deployment ({CI}/{CD}) environments. Traditional static analysis tools, while effective for identifying isolated issues, often lack contextual awareness, leading to missed vulnerabilities and high rates of false positives. This paper introduces a novel framework leveraging Large Language Models ({LLMs}) to detect and mitigate security risks in design patterns and antipatterns. By analyzing relationships and behavioral dynamics in code, {LLMs} provide a nuanced, context-aware approach to identifying issues such as unauthorized state changes, insecure communication, and improper data handling. The proposed framework integrates key security heuristics—such as the principles of least privilege and input validation—to enhance {LLM} performance. An evaluation of the framework demonstrates its potential to outperform traditional tools in terms of accuracy and efficiency, enabling the proactive detection and remediation of vulnerabilities in real time. This study contributes to the field of software engineering by offering an innovative methodology for securing software systems using {LLMs}, promoting both academic research and practical application in industry settings.},
	pages = {586},
	number = {3},
	journaltitle = {Electronics},
	author = {Andrade, Roberto and Torres, Jenny and Ortiz-Garcés, Iván},
	urldate = {2025-06-18},
	date = {2025-01},
	langid = {english},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {antipatterns, {LLM}, software security},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/XMRADTJW/Andrade et al. - 2025 - Enhancing Security in Software Design Patterns and Antipatterns A Framework for LLM-Based Detection.pdf:application/pdf},
}

@misc{li_iris_2025,
	title = {{IRIS}: {LLM}-Assisted Static Analysis for Detecting Security Vulnerabilities},
	url = {http://arxiv.org/abs/2405.17238},
	doi = {10.48550/arXiv.2405.17238},
	shorttitle = {{IRIS}},
	abstract = {Software is prone to security vulnerabilities. Program analysis tools to detect them have limited effectiveness in practice due to their reliance on human labeled specifications. Large language models (or {LLMs}) have shown impressive code generation capabilities but they cannot do complex reasoning over code to detect such vulnerabilities especially since this task requires whole-repository analysis. We propose {IRIS}, a neuro-symbolic approach that systematically combines {LLMs} with static analysis to perform whole-repository reasoning for security vulnerability detection. Specifically, {IRIS} leverages {LLMs} to infer taint specifications and perform contextual analysis, alleviating needs for human specifications and inspection. For evaluation, we curate a new dataset, {CWE}-Bench-Java, comprising 120 manually validated security vulnerabilities in real-world Java projects. A state-of-the-art static analysis tool {CodeQL} detects only 27 of these vulnerabilities whereas {IRIS} with {GPT}-4 detects 55 (+28) and improves upon {CodeQL}'s average false discovery rate by 5\% points. Furthermore, {IRIS} identifies 4 previously unknown vulnerabilities which cannot be found by existing tools. {IRIS} is available publicly at https://github.com/iris-sast/iris.},
	number = {{arXiv}:2405.17238},
	publisher = {{arXiv}},
	author = {Li, Ziyang and Dutta, Saikat and Naik, Mayur},
	urldate = {2025-06-18},
	date = {2025-04-06},
	eprinttype = {arxiv},
	eprint = {2405.17238 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Programming Languages, Computer Science - Software Engineering},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/8GY7RFXK/Li et al. - 2025 - IRIS LLM-Assisted Static Analysis for Detecting Security Vulnerabilities.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/AR9WSYRE/2405.html:text/html},
}
