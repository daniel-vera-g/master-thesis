
@article{weedon_generative_2023,
	title = {Generative {AI}: security implications for business automation},
	volume = {2023},
	issn = {1353-4858, 1872-9371},
	url = {http://www.magonlinelibrary.com/doi/10.12968/S1353-4858%2823%2970045-7},
	doi = {10.12968/S1353-4858(23)70045-7},
	shorttitle = {Generative {AI}},
	abstract = {{AI} tools such as {ChatGPT} certainly appear to offer significant benefits to organisations looking to save costs and improve efficiency. But the technology is being adopted with an enthusiasm that leaves little room for the careful consideration of potential security vulnerabilities. So how do you embrace this revolution without putting yourself at risk?},
	pages = {S1353--4858(23)70045--7},
	number = {9},
	journaltitle = {Network Security},
	author = {Weedon, Scott},
	urldate = {2024-09-07},
	date = {2023-09},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/3ICS935N/ba42b88132000be4ea8cf6b9a119f6b71d0b07f1.html:text/html},
}

@misc{haryanto_secgenai_2024,
	title = {{SecGenAI}: Enhancing Security of Cloud-based Generative {AI} Applications within Australian Critical Technologies of National Interest},
	url = {http://arxiv.org/abs/2407.01110},
	doi = {10.48550/arXiv.2407.01110},
	shorttitle = {{SecGenAI}},
	abstract = {The rapid advancement of Generative {AI} ({GenAI}) technologies offers transformative opportunities within Australia's critical technologies of national interest while introducing unique security challenges. This paper presents {SecGenAI}, a comprehensive security framework for cloud-based {GenAI} applications, with a focus on Retrieval-Augmented Generation ({RAG}) systems. {SecGenAI} addresses functional, infrastructure, and governance requirements, integrating end-to-end security analysis to generate specifications emphasizing data privacy, secure deployment, and shared responsibility models. Aligned with Australian Privacy Principles, {AI} Ethics Principles, and guidelines from the Australian Cyber Security Centre and Digital Transformation Agency, {SecGenAI} mitigates threats such as data leakage, adversarial attacks, and model inversion. The framework's novel approach combines advanced machine learning techniques with robust security measures, ensuring compliance with Australian regulations while enhancing the reliability and trustworthiness of {GenAI} systems. This research contributes to the field of intelligent systems by providing actionable strategies for secure {GenAI} implementation in industry, fostering innovation in {AI} applications, and safeguarding national interests.},
	number = {{arXiv}:2407.01110},
	publisher = {{arXiv}},
	author = {Haryanto, Christoforus Yoga and Vu, Minh Hieu and Nguyen, Trung Duc and Lomempow, Emily and Nurliana, Yulia and Taheri, Sona},
	urldate = {2024-08-26},
	date = {2024-07-01},
	eprinttype = {arxiv},
	eprint = {2407.01110 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Cryptography and Security, Computer Science - Computers and Society},
	file = {arXiv Fulltext PDF:/Users/d.veragilliard/Zotero/storage/Y87CT6NW/Haryanto et al. - 2024 - SecGenAI Enhancing Security of Cloud-based Genera.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/7S4ZGDKG/2407.html:text/html},
}

@article{zscaler_inc_bloomington_in_usa_ai_2023,
	title = {{AI} in Cybersecurity and User Interface Design beyond Chatbots},
	issn = {27546659},
	url = {https://www.onlinescientificresearch.com/articles/ai-in-cybersecurity-and-user-interface-design-beyond-chatbots.pdf},
	doi = {10.47363/JAICC/2023(2)164},
	abstract = {This paper examines the integration of Artificial Intelligence ({AI}) in cybersecurity, highlighting how {AI} is revolutionizing cloud security for enterprises amidst increasing cyber threats. It defines key concepts including {AI}, Machine Learning, Large Language Models, Natural Language Processing, and Generative {AI}, and explores their applications in cybersecurity. Focused on enhancing the efficiency and efficacy of cybersecurity solutions, the paper delves into {AI}-driven technologies like Text-to-Visualization, Breach Analytics, and Multi-modal Data Protection. It also discusses the impact of {AI} on user experience ({UX}) design, advocating for user-centric, intuitive interfaces in cybersecurity tools. The paper concludes by emphasizing the importance of ethical considerations in {AI} deployment and the crucial role of {UX} designers in shaping the future of {AI}-enhanced cybersecurity solutions.delves into {AI}-driven technologies like Text-to-Visualization, Breach Analytics, and Multi-modal Data Protection. It also discusses the impact of {AI} on user experience ({UX}) design, advocating for user-centric, intuitive interfaces in cybersecurity tools. The paper concludes by emphasizing the importance of ethical considerations in {AI} deployment and the crucial role of {UX} designers in shaping the future of {AI}-enhanced cybersecurity solutions.},
	pages = {1--4},
	journaltitle = {J Arti Inte \& Cloud Comp},
	author = {{Zscaler, Inc. Bloomington, IN, USA} and Shete, Shriyash},
	urldate = {2025-03-31},
	date = {2023-12-31},
	file = {Full Text:/Users/d.veragilliard/Zotero/storage/3PYU6B2J/Zscaler, Inc. Bloomington, IN, USA and Shete - 2023 - AI in Cybersecurity and User Interface Design beyond Chatbots.pdf:application/pdf},
}

@article{senior_software_engineer_cisco_systems_inc_usa_next-gen_2024,
	title = {Next-Gen Firewalls: Enhancing Cloud Security with Generative {AI}},
	volume = {3},
	url = {https://www.onlinescientificresearch.com/articles/nextgen-firewalls-enhancing-cloud-security-with-generative-ai.pdf},
	doi = {10.47363/JAICC/2024(3)404},
	shorttitle = {Next-Gen Firewalls},
	abstract = {Next-generation firewalls are available and use machine learning and generative modeling to enhance the detection of hard-to-detect cyber threats. These systems incorporate advanced security controls, policies, and protocols with Layer 7 of the {OSI} model. This chapter updates these steep {AI}-based protection systems and applications.},
	pages = {1--9},
	number = {4},
	journaltitle = {J Arti Inte \& Cloud Comp},
	author = {{Senior Software Engineer, Cisco Systems Inc, USA} and Lekkala, Seshagirirao},
	urldate = {2025-03-31},
	date = {2024-08-30},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/D9LSZDNH/4373239ca9de9d5ab0dbf0b2e60bf1885beca545.html:text/html},
}

@article{patel_generative_2025,
	title = {Generative {AI} for Automated Security Operations in Cloud Computing},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10849302/},
	doi = {10.1109/ICAIC63015.2025.10849302},
	abstract = {New opportunities in cloud computing have brought many new risks that require effective protection of dynamic distributed environments. Introducing a new formative technology, generative {AI}, to cloud security has far-reaching benefits for automating threat detection, real-time incident addressing, and vulnerability management. This paper focuses on extending generative {AI} with cloud security tools like {AWS} {GuardDuty} and Google Cloud Security Command Center; the contemplation of accuracy enhancement and response efficiency highlights its aim. Concerning actual applications such as {SOAR} systems, the study demonstrates how media industry giants, such as Netflix and {JPMorgan} Chase, have used {AI} to minimize risk factors while increasing operational efficiency. The paper also discusses the significant increase in response time, enhanced detection accuracy, and the shift to proactive security strategies brought by generative {AI}. Drawing attention to {AI} systems’ opportunities, the study examines the subsequent issues connected with {AI} applications, including over-dependence on {AI} tools, adversarial risk to models, and the complex nature of decisionmaking in the context of {AI} systems. The present study also highlights the importance of generative {AI} in strengthening the defense of the cloud environment, but, at the same time, it recognizes the significance of preventive efforts and planned action plans to manage these technologies efficiently.},
	pages = {1--7},
	journaltitle = {2025 {IEEE} 4th International Conference on {AI} in Cybersecurity ({ICAIC})},
	author = {Patel, Advait and Pandey, Pravin and Ragothaman, Hariharan and Molleti, Ramasankar and Peddinti, Diwakar Reddy},
	urldate = {2025-03-31},
	date = {2025-02-05},
	note = {Conference Name: 2025 {IEEE} 4th International Conference on {AI} in Cybersecurity ({ICAIC})
{ISBN}: 9798331518882
Place: Houston, {TX}, {USA}
Publisher: {IEEE}},
}

@inproceedings{tunc_cloud_2017,
  author    = {Tunc, Cihan and Hariri, Salim and Merzouki, Mheni and Mahmoudi, Charif and De Vaulx, Frederic J. and Chbili, Jaafar and Bohn, Robert and Battou, Abdella},
  title     = {{Cloud Security Automation Framework}},
  booktitle = {Proc. IEEE 2nd Int. Workshops Foundations Appl. Self* Syst. (FAS*W)},
  year      = {2017},
  month     = {Sep.},
  pages     = {307--312},
  location  = {Tucson, AZ, USA},
  publisher = {IEEE},
  doi       = {10.1109/FAS-W.2017.164}
}

@online{noauthor_generative_nodate,
	title = {Generative {AI} Security {\textbar} springerprofessional.de},
	url = {https://www.springerprofessional.de/en/generative-ai-security/26951270},
	urldate = {2025-03-31},
	file = {26951270:/Users/d.veragilliard/Zotero/storage/S6EBVVUG/26951270.html:text/html},
}

@online{noauthor_pdf_nodate,
	title = {({PDF}) {ENHANCING} {CLOUD} {SECURITY} {WITH} {GENERATIVE} {AI}: {EMERGING} {STRATEGIES} {AND} {APPLICATIONS}},
	url = {https://www.researchgate.net/publication/382297663_ENHANCING_CLOUD_SECURITY_WITH_GENERATIVE_AI_EMERGING_STRATEGIES_AND_APPLICATIONS},
	shorttitle = {({PDF}) {ENHANCING} {CLOUD} {SECURITY} {WITH} {GENERATIVE} {AI}},
	abstract = {{PDF} {\textbar} This article explores the potential of generative {AI} for enhancing cloud security. With the rapid adoption of cloud technologies and the... {\textbar} Find, read and cite all the research you need on {ResearchGate}},
	titleaddon = {{ResearchGate}},
	urldate = {2025-03-31},
	langid = {english},
	doi = {10.17605/OSF.IO/SDZCX},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/BQ5YRE6K/382297663_ENHANCING_CLOUD_SECURITY_WITH_GENERATIVE_AI_EMERGING_STRATEGIES_AND_APPLICATIONS.html:text/html},
}

@article{mercer_generative_nodate,
	title = {Generative {AI} in Cybersecurity},
	author = {Mercer, Sarah and Watson, Tim},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/UPI8RFNP/Mercer and Watson - Generative AI in Cybersecurity.pdf:application/pdf},
}

@online{noauthor_pdf_nodate-1,
	title = {({PDF}) The role of generative {AI} in cyber security},
	url = {https://www.researchgate.net/publication/385790015_The_role_of_generative_AI_in_cyber_security},
	urldate = {2025-03-31},
	file = {(PDF) The role of generative AI in cyber security:/Users/d.veragilliard/Zotero/storage/S57D3LEN/385790015_The_role_of_generative_AI_in_cyber_security.html:text/html},
}

@article{yang_survey_2023,
	title = {Survey on Explainable {AI}: From Approaches, Limitations and Applications Aspects},
	volume = {3},
	issn = {2667-1336},
	url = {https://link.springer.com/10.1007/s44230-023-00038-y},
	doi = {10.1007/s44230-023-00038-y},
	shorttitle = {Survey on Explainable {AI}},
	abstract = {Abstract
            In recent years, artificial intelligence ({AI}) technology has been used in most if not all domains and has greatly benefited our lives. While {AI} can accurately extract critical features and valuable information from large amounts of data to help people complete tasks faster, there are growing concerns about the non-transparency of {AI} in the decision-making process. The emergence of explainable {AI} ({XAI}) has allowed humans to better understand and control {AI} systems, which is motivated to provide transparent explanations for the decisions made by {AI}. This article aims to present a comprehensive overview of recent research on {XAI} approaches from three well-defined taxonomies. We offer an in-depth analysis and summary of the status and prospects of {XAI} applications in several key areas where reliable explanations are urgently needed to avoid mistakes in decision-making. We conclude by discussing {XAI}’s limitations and future research directions.},
	pages = {161--188},
	number = {3},
	journaltitle = {Hum-Cent Intell Syst},
	author = {Yang, Wenli and Wei, Yuchen and Wei, Hanyu and Chen, Yanyu and Huang, Guan and Li, Xiang and Li, Renjie and Yao, Naimeng and Wang, Xinyi and Gu, Xiaotong and Amin, Muhammad Bilal and Kang, Byeong},
	urldate = {2025-03-31},
	date = {2023-08-10},
	langid = {english},
	file = {Full Text:/Users/d.veragilliard/Zotero/storage/XBGJG3HA/Yang et al. - 2023 - Survey on Explainable AI From Approaches, Limitations and Applications Aspects.pdf:application/pdf},
}

@misc{wang_overview_2023,
	title = {An Overview on Generative {AI} at Scale with Edge-Cloud Computing},
	url = {http://arxiv.org/abs/2306.17170},
	doi = {10.36227/techrxiv.23272271},
	abstract = {As a specific category of artificial intelligence ({AI}), generative artificial intelligence ({GenAI}) generates new content that resembles what is created by humans. The rapid development of {GenAI} systems has created a huge amount of new data on the Internet, posing new challenges to current computing and communication frameworks. Currently, {GenAI} services rely on the traditional cloud computing framework due to the need for large computation resources. However, such services will encounter high latency because of data transmission and a high volume of requests. On the other hand, edge-cloud computing can provide adequate computation power and low latency at the same time through the collaboration between edges and the cloud. Thus, it is attractive to build {GenAI} systems at scale by leveraging the edge-cloud computing paradigm. In this overview paper, we review recent developments in {GenAI} and edge-cloud computing, respectively. Then, we use two exemplary {GenAI} applications to discuss technical challenges in scaling up their solutions using edge-cloud collaborative systems. Finally, we list design considerations for training and deploying {GenAI} systems at scale and point out future research directions.},
	author = {Wang, Yun-Cheng and Xue, Jintang and Wei, Chengwei and Kuo, C.-C. Jay},
	urldate = {2025-03-31},
	date = {2023-10-31},
	eprinttype = {arxiv},
	eprint = {2306.17170 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Systems and Control, Electrical Engineering and Systems Science - Systems and Control},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/V9XV5TQT/Wang et al. - 2023 - An Overview on Generative AI at Scale with Edge-Cloud Computing.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/WL84ITKW/2306.html:text/html},
}

@article{bright_ojo_ai-driven_2024,
	title = {{AI}-driven cybersecurity solutions for real-time threat detection in critical infrastructure},
	volume = {12},
	issn = {25828185},
	url = {https://ijsra.net/node/5148},
	doi = {10.30574/ijsra.2024.12.2.1401},
	abstract = {Cyber-security as a concept relates to the protection of critical infrastructures that are significant to the security of a nation. Because many security threats have targeted computer-based critical infrastructures, nations have considered it necessary to enhance their security to detect and predict cyber threats accurately. This paper aimed to discuss the role of artificial intelligence ({AI}) in increasing real-time threat detection to critical infrastructures such as water facilities and transport systems. Through the implementation and application of {AI}, it is easier to not only detect the threat but also counter it promptly. Thus, the paper discussed the latest {AI} technologies, the approaches for their use and the cases, for example, the Colonial Pipeline ransomware attack, to demonstrate {AI}’s capabilities and limitations in this area. Other strategies such as measures and formulation of policies were also considered to ensure sound protection and improvement policies and regulations framework for cybersecurity.},
	pages = {1716--1726},
	number = {2},
	journaltitle = {Int. J. Sci. Res. Arch.},
	author = {{Bright Ojo} and {Chukwudi Tabitha Aghaunor}},
	urldate = {2025-04-07},
	date = {2024-08-30},
}

@article{thapaliya_leveraging_2024,
	title = {Leveraging artificial intelligence for enhanced cybersecurity: insights and innovations},
	volume = {1},
	issn = {3021-9566},
	url = {https://www.nepjol.info/index.php/sadgamaya/article/view/66888},
	doi = {10.3126/sadgamaya.v1i1.66888},
	shorttitle = {Leveraging artificial intelligence for enhanced cybersecurity},
	abstract = {In the digital age, cyber threats have become increasingly sophisticated, necessitating innovative approaches to bolster security measures. Artificial Intelligence ({AI}) has emerged as a formidable tool in the realm of cyber security, offering advanced capabilities in threat detection, anomaly detection, and response automation. This article provides an overview of {AI} applications in cyber security, highlighting its role in mitigating risks and fortifying defense mechanisms. {AI} techniques such as machine learning, deep learning, and natural language processing empower security systems to analyze vast amounts of data in real-time, identifying patterns indicative of malicious activities. Through the utilization of {AI}-driven algorithms, cyber security platforms can proactively detect and neutralize cyber threats before they inflict substantial damage. Moreover, {AI} enables the automation of incident response processes, reducing response times and minimizing the impact of security breaches. Case studies from leading cyber security firms from the integral part of the studies and demonstrate the practical implementation of {AI}-driven solutions in safeguarding critical infrastructures against cyber threats. Resilience towards cyber-attacks and safeguarding sensitive data assets through leveraging {AI} technologies has been focused in the study.},
	pages = {46--52},
	number = {1},
	journaltitle = {Sadgamaya},
	author = {Thapaliya, Suman and Bokani, Ayub},
	urldate = {2025-04-07},
	date = {2024-06-17},
	file = {Full Text:/Users/d.veragilliard/Zotero/storage/77WHQXKX/Thapaliya and Bokani - 2024 - Leveraging artificial intelligence for enhanced cybersecurity insights and innovations.pdf:application/pdf},
}

@article{sharko_artificial_2024,
	title = {Artificial Intelligence In Cybersecurity Applications},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10629129/},
	doi = {10.1109/INES63318.2024.10629129},
	abstract = {People cannot handle the volume of data and the complexity of processes needed to secure cyberspace without significant automation. However, it is challenging to develop technologies and software with conventional fixed implementations (hardwired decision-making logic) that successfully defend against security risks. {AI} learning techniques and machine simplicity can be used to treat this issue. Artificial intelligence ({AI}) approaches have been attempted to be used in a variety of cyber security applications recently. This paper gives an overview to the algorithms that might be used to have a better protection for our systems. This paper examines the crucial role that artificial intelligence plays in cybersecurity, as well as its benefits, drawbacks, and practical applications from the largest global corporations, such as {PayPal} and {AWS}. Also gives the benefits of using {AI} technology for Security.},
	pages = {000175--000180},
	journaltitle = {2024 {IEEE} 28th International Conference on Intelligent Engineering Systems ({INES})},
	author = {Sharko, Anni Dasho and Sharko, Genci and Qose, Silvana},
	urldate = {2025-04-07},
	date = {2024-07-17},
	note = {Conference Name: 2024 {IEEE} 28th International Conference on Intelligent Engineering Systems ({INES})
{ISBN}: 9798350367591
Place: Gammarth, Tunisia
Publisher: {IEEE}},
}

@article{kodete_determining_2024,
	title = {Determining the Efficacy of Machine Learning Strategies in Quelling Cyber Security Threats: Evidence from Selected Literatures},
	volume = {17},
	issn = {2581-8260},
	url = {https://journalajrcos.com/index.php/AJRCOS/article/view/487},
	doi = {10.9734/ajrcos/2024/v17i7487},
	shorttitle = {Determining the Efficacy of Machine Learning Strategies in Quelling Cyber Security Threats},
	abstract = {The alarming security threats in the internet world continually raise critical concerns among individuals, organizations and governments alike. The sophistication of cyber-attacks makes it imperative for a paradigm shift from traditional approaches and measures for quelling the attacks to modern sophisticated, digital and strategic ones, such as those involving machine learning and other technologies of artificial intelligence ({AI}). This study is aimed at examining machine learning ({ML}) strategies for effective cyber security. {ML} involves using algorithms and statistical models to enable computers learn from and make decisions or predictions based on data. The study relied on secondary data, which were subjected to a systematic review. The results of its thematic and qualitative analyses prove that majority of the literatures allude to the fact that the maximal performance abilities and tactics of the {ML} constitute its strategies for quelling cyber security. These include its: early detection of threats that are tackled before they cause damages; ability to analyze huge quantity of data quickly and accurately; and processing of datasets in real-time. The study argues that the noted abilities and tactics constitute {ML} strategies for quelling cyber security, regardless of its challenges like data quality, security vulnerabilities and possible incidences of bias. The study concludes that {ML} can indeed be used to detect and respond to threats in real-time, ascertain patterns of malicious behavior, and improve on internet security, which thereby prove it to be a viable tool for quelling cyber security.},
	pages = {24--33},
	number = {8},
	journaltitle = {Asian J. Res. Com. Sci.},
	author = {Kodete, Chandra Shikhi and Thuraka, Bharadwaj and Pasupuleti, Vikram and Malisetty, Saiteja},
	urldate = {2025-04-07},
	date = {2024-07-13},
	file = {Full Text:/Users/d.veragilliard/Zotero/storage/8HJQ73L4/Kodete et al. - 2024 - Determining the Efficacy of Machine Learning Strategies in Quelling Cyber Security Threats Evidence.pdf:application/pdf},
}

@article{siam_artificial_2025,
	title = {Artificial Intelligence for Cybersecurity: A State of the Art},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10848980/},
	doi = {10.1109/ICAIC63015.2025.10848980},
	shorttitle = {Artificial Intelligence for Cybersecurity},
	abstract = {The goal of this study is to analyze the role of artificial intelligence ({AI}) in cybersecurity by analyzing the strengths of many key {AI} techniques, including machine learning ({ML}), deep learning ({DL}), natural language processing ({NLP}), and anomaly detection algorithms. We conducted a detailed literature assessment on current research to assess the applicability of {AI} approaches in cybersecurity. Principal methodologies examined include machine learning for behavioral analytics, deep learning for malware detection, natural language processing for phishing identification, and anomaly detection for intrusion detection. Artificial intelligence approaches significantly enhance cybersecurity, with each strategy providing distinct functionalities. This study’s distinctive contributions are its comparative assessment of approaches, emphasizing their strengths and practical applications in cybersecurity while addressing present issues and future avenues for improvement. The research suggests that a combination of {AI} in cybersecurity that merges these strategies could provide a significant increase in digital security. These findings bring substantial value by identifying the best scenarios for using each {AI} approach in cybersecurity.},
	pages = {1--7},
	journaltitle = {2025 {IEEE} 4th International Conference on {AI} in Cybersecurity ({ICAIC})},
	author = {Siam, Abdullah Al and Hassan, Md Maruf and Bhuiyan, Touhid},
	urldate = {2025-04-07},
	date = {2025-02-05},
	note = {Conference Name: 2025 {IEEE} 4th International Conference on {AI} in Cybersecurity ({ICAIC})
{ISBN}: 9798331518882
Place: Houston, {TX}, {USA}
Publisher: {IEEE}},
}

@article{sarker_ai-driven_2021,
	title = {{AI}-Driven Cybersecurity: An Overview, Security Intelligence Modeling and Research Directions},
	volume = {2},
	issn = {2662-995X, 2661-8907},
	url = {https://link.springer.com/10.1007/s42979-021-00557-0},
	doi = {10.1007/s42979-021-00557-0},
	shorttitle = {{AI}-Driven Cybersecurity},
	abstract = {Artificial intelligence ({AI}) is one of the key technologies of the Fourth Industrial Revolution (or Industry 4.0), which can be used for the protection of Internet-connected systems from cyber threats, attacks, damage, or unauthorized access. To intelligently solve today’s various cybersecurity issues, popular {AI} techniques involving machine learning and deep learning methods, the concept of natural language processing, knowledge representation and reasoning, as well as the concept of knowledge or rule-based expert systems modeling can be used. Based on these {AI} methods, in this paper, we present a comprehensive view on “{AI}-driven Cybersecurity” that can play an important role for intelligent cybersecurity services and management. The security intelligence modeling based on such {AI} methods can make the cybersecurity computing process automated and intelligent than the conventional security systems. We also highlight several research directions within the scope of our study, which can help researchers do future research in the area. Overall, this paper’s ultimate objective is to serve as a reference point and guidelines for cybersecurity researchers as well as industry professionals in the area, especially from an intelligent computing or {AI}-based technical point of view.},
	pages = {173},
	number = {3},
	journaltitle = {{SN} {COMPUT}. {SCI}.},
	author = {Sarker, Iqbal H. and Furhad, Md Hasan and Nowrozy, Raza},
	urldate = {2025-04-07},
	date = {2021-05},
	langid = {english},
	file = {Submitted Version:/Users/d.veragilliard/Zotero/storage/THBZZSGZ/Sarker et al. - 2021 - AI-Driven Cybersecurity An Overview, Security Intelligence Modeling and Research Directions.pdf:application/pdf},
}

@article{naveen_kumar_thawait_machine_2024,
	title = {Machine Learning in Cybersecurity : Applications, Challenges and Future Directions},
	volume = {10},
	rights = {https://creativecommons.org/licenses/by/4.0},
	issn = {2456-3307},
	url = {https://ijsrcseit.com/index.php/home/article/view/CSEIT24102125},
	doi = {10.32628/CSEIT24102125},
	shorttitle = {Machine Learning in Cybersecurity},
	abstract = {Machine learning ({ML}) is transforming cybersecurity by enabling advanced detection, prevention and response mechanisms. This paper provides a comprehensive review of {ML}'s role in cybersecurity, examining both theoretical frameworks and practical implementations. It outlines the emerging threats targeting {ML} models, such as adversarial attacks, data poisoning and model inversion attacks and discusses state-of-the-art defense strategies, including adversarial training, robust architectures and differential privacy. Additionally, the paper explores various {ML} applications in cybersecurity from intrusion detection to malware classification, highlighting their impact on enhancing security measures. An anomaly inference algorithm is proposed for the early detection of cyber-intrusions at the substations. Cybersecurity has become a vital research area. The paper concludes with a discussion on the key research directions and best practices for creating secure and resilient {ML} systems in a data-driven world. This paper delves into how Machine Learning ({ML}) revolutionizes cybersecurity, empowering advanced detection, prevention, and response mechanisms. It offers a thorough exploration of {ML}'s pivotal role in cybersecurity, encompassing theoretical frameworks and practical applications. It addresses emerging threats like adversarial attacks and data poisoning, alongside cutting-edge defense strategies such as adversarial training and robust architectures.},
	pages = {16--27},
	number = {3},
	journaltitle = {Int. J. Sci. Res. Comput. Sci. Eng. Inf. Technol},
	author = {{Naveen Kumar Thawait}},
	urldate = {2025-04-07},
	date = {2024-05-03},
	file = {Full Text:/Users/d.veragilliard/Zotero/storage/8TQJGP7L/Naveen Kumar Thawait - 2024 - Machine Learning in Cybersecurity  Applications, Challenges and Future Directions.pdf:application/pdf},
}

@article{olatunji_systematic_2024,
	title = {A Systematic Review of the Role of Artificial Intelligence in Cybersecurity},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10926941/},
	doi = {10.1109/NIGERCON62786.2024.10926941},
	abstract = {Artificial Intelligence ({AI}) has become a cornerstone in advancing cybersecurity, offering innovative solutions to detect and mitigate cyber threats. Over the past decade, numerous studies have explored the application of {AI}, particularly machine learning ({ML}) and deep learning ({DL}), in enhancing cybersecurity across various domains such as intrusion detection, malware identification, and phishing prevention. This paper presents a systematic review of {AI} applications in cybersecurity, covering the period from 2014 to August 2024. The review analyzed literature from five major academic databases—Google Scholar, {MDPI}, Science Direct, Springer, and {IEEE}—with a focus on only review papers to gain comprehensive insights into the field. The findings reveal significant progress in deploying {AI} to counter cyber threats, with notable advances in {AI}-driven threat intelligence, incident response, and the identification of adversarial {ML} challenges. However, the review also highlights persistent challenges, including the need for high-quality training datasets, the complexities of emerging threats, and the ethical considerations surrounding {AI} deployment in cybersecurity.},
	pages = {1--6},
	journaltitle = {2024 {IEEE} 5th International Conference on Electro-Computing Technologies for Humanity ({NIGERCON})},
	author = {Olatunji, Ayobami Peter and Alozie, Emmanuel and Olagunju, Hawau and Udensi, Ferguson},
	urldate = {2025-04-07},
	date = {2024-11-26},
	note = {Conference Name: 2024 {IEEE} 5th International Conference on Electro-Computing Technologies for Humanity ({NIGERCON})
{ISBN}: 9798331542559
Place: Ado Ekiti, Nigeria
Publisher: {IEEE}},
}

@article{attila_machine_2024,
	title = {Machine Learning Used in Cyber Security},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10619896/},
	doi = {10.1109/SACI60582.2024.10619896},
	abstract = {In this analysis, we discuss the critical role of machine learning ({ML}) in cyber security, in the context of the cyber threats highlighted by the {ENISA} “Threat Landscape 2023” report. We focus on ransomware, malware, social engineering attacks, data protection and infrastructure threats, showing how {ML} and deep learning contribute to their more effective detection and management. The analysis emphasizes the importance of cybersecurity awareness, education, and best practices for digital security, highlighting the importance of up-to-date technological approaches to modern cyber threats.},
	pages = {000297--000302},
	journaltitle = {2024 {IEEE} 18th International Symposium on Applied Computational Intelligence and Informatics ({SACI})},
	author = {Attila, Nagy and Szilvia, Ács and Anikó, Horváth-Kiss and Beatrix, Fregan and Zoltán, Rajnai},
	urldate = {2025-04-07},
	date = {2024-05-23},
	note = {Conference Name: 2024 {IEEE} 18th International Symposium on Applied Computational Intelligence and Informatics ({SACI})
{ISBN}: 9798350329520
Place: Timisoara, Romania
Publisher: {IEEE}},
}

@article{nawaf_optimization_2025,
	title = {Optimization of cyber security through the implementation of {AI} technologies},
	volume = {34},
	rights = {http://creativecommons.org/licenses/by/4.0},
	issn = {2191-026X},
	url = {https://www.degruyter.com/document/doi/10.1515/jisys-2024-0226/html},
	doi = {10.1515/jisys-2024-0226},
	abstract = {Abstract
            Identification of cyber threats is crucial and significant for determining substantial security techniques and approaches. This research illustrates a brief discussion of cyberspace challenges and threats in a disruptive era alongside comprehensive approaches in mitigating the risk of cyber threats. Additionally, the aim of this research is to provide beneficial approaches on how to handle cyber threats in detail. For example, threats and attacks may be caused in the absence of legislation, ethical standardization, support system, and lack of access control. The governance system, therefore, will put a lot of effort into communicating, identifying, and enforcing the principles of security to moderate risk. The Metaheuristic algorithms are stimulated by the human brain, so implementing Artificial Intelligence ({AI}) that assists the Neural Network to mimic the behaviour of the human brain is important to predict significant outcomes. In this study, the author investigates and analyses the rapid growth of cyber threats to outline the solutions. The aim of this study is to contribute to cyber security optimization through implementing {AI} methodologies.},
	pages = {20240226},
	number = {1},
	journaltitle = {Journal of Intelligent Systems},
	author = {Nawaf, Liqaa and Bentotahewa, Vibhushinie},
	urldate = {2025-04-07},
	date = {2025-02-06},
	langid = {english},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/LEPH7SC4/Nawaf and Bentotahewa - 2025 - Optimization of cyber security through the implementation of AI technologies.pdf:application/pdf},
}

@article{department_of_computer_science_washington_university_of_science_and_technology_vienna_virginia_va_22182_usa_artificial_2023,
	title = {Artificial Intelligence with Respect to Cyber Security},
	volume = {1},
	issn = {29724503},
	url = {http://www.jaai.net/content-173-18-1.html},
	doi = {10.18178/JAAI.2023.1.2.96-102},
	abstract = {Artificial Intelligence has transformed the cyber security industry by enabling organizations to systematize and enlarge outdated safety procedures. {AI} can provide more effective threat detection and response capabilities, enhance vulnerability management, and improve compliance and governance. {AI} technologies such as machine learning, natural language processing, behavioral analytics, and deep learning can enhance cyber security defenses and protect against a wide range of cyber threats, including malware, phishing attacks, and insider threats. Theoretical underpinnings of {AI} in cyber security, such as machine learning, natural language processing, behavioral analytics, and deep learning, are discussed. The advantages of using {AI} in cyber security are discussed including speed and accuracy, continuous learning and adaptation, and efficiency and scalability. It's important to note that {AI} is not a silver bullet for cyber security and should be used in conjunction with other security measures to provide a comprehensive defense strategy. {AI} has transformed the way cyber security operates in today's digital age. By analyzing vast amounts of data quickly and accurately it has become a valuable tool for organizations looking to protect their assets from cyber threats.},
	pages = {96--102},
	number = {2},
	journaltitle = {{JAAI}},
	author = {{Department of Computer Science, Washington University of Science and Technology, Vienna, Virginia. VA 22182 USA.} and Jawaid, Syed Adnan},
	urldate = {2025-04-07},
	date = {2023},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/F5LB4CKK/Department of Computer Science, Washington University of Science and Technology, Vienna, Virginia. VA 22182 USA. and Jawaid - 2023 - Artificial Intelligence with Respect to Cyber Security.pdf:application/pdf},
}

@article{tlachenska_approaches_2024,
	title = {Approaches for Implementing Artificial Intelligence in Cyber-security to Improve, Speed up and Optimize Processes},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10590694/},
	doi = {10.1109/Lighting62260.2024.10590694},
	abstract = {This paper provides an examination of how Artificial intelligence applies in cyber security's difficult job of preventing and guarding information. Dealing with broad attack surface, big number of applications and large number of users makes the defended territory too vast to deal with [1]. All of this creates challenges for cyber security with the large amounts of data to be analyzed and understood. Traditional security methods are not enough to stop cybercriminals from breaching data and inflicting damage. Artificial Intelligence, with machine learning algorithms, continuous learning mechanisms and real-time data processing, offers fundamental tools to cybersecurity to use and enhance approaches to recognize network intrusions, data breaches, phishing and spam emails, malware attacks, and to alert security vulnerability when appears.},
	pages = {1--3},
	journaltitle = {2024 Ninth Junior Conference on Lighting (Lighting)},
	author = {Tlachenska, Elina and Ivanov, Kiril and Nenova, Maria and Valkova-Jarvis, Zlatka and Kassev, Kiril},
	urldate = {2025-04-07},
	date = {2024-06-04},
	note = {Conference Name: 2024 Ninth Junior Conference on Lighting (Lighting)
{ISBN}: 9798350352757
Place: Sozopol, Bulgaria
Publisher: {IEEE}},
}

@online{noauthor_ai_nodate,
	title = {{AI} and Security - What Changes with Generative {AI} {\textbar} Semantic Scholar},
	url = {https://www.semanticscholar.org/paper/AI-and-Security-What-Changes-with-Generative-AI-Sasaki/47e364772899924a140ba56c7299c708f36d9ff0},
	urldate = {2025-04-07},
}

@article{tsareva_information_2022,
	title = {Information Security Systems Based on the {AI} and Machine Learning},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/9755581/},
	doi = {10.1109/ElConRus54750.2022.9755581},
	abstract = {In this article we are observing what impact {AI} and machine learning have in the development of security systems. With this approach some problems are solved such as human errors, overwhelming notifications about possible threats, long time required for reaction. Among the advantages there is also possibility to adapt to different requirements, to find and to predict future security problems. Still there are some restrictions should be followed, for example, systems based on machine learning can violate data privacy laws. For the industry development qualified specialists who can customize systems are highly needed. On the current level of the technical process people can’t be removed completely because they are more capable in making decisions. While there is too much to finalize this idea, these types of systems are gradually starting to be applied by Google, Amazon, {IBM}.},
	pages = {469--473},
	journaltitle = {2022 Conference of Russian Young Researchers in Electrical and Electronic Engineering ({ElConRus})},
	author = {Tsareva, Polina E. and Voronova, Anna V.},
	urldate = {2025-04-07},
	date = {2022-01-25},
	note = {Conference Name: 2022 Conference of Russian Young Researchers in Electrical and Electronic Engineering ({ElConRus})
{ISBN}: 9781665409933
Place: Saint Petersburg, Russian Federation
Publisher: {IEEE}},
}

@article{seth_ai_2025,
	title = {{AI} and Generative {AI}-Driven Automation for Multi-Cloud and Hybrid Cloud Architectures: Enhancing Security, Performance, and Operational Efficiency},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10903928/},
	doi = {10.1109/CCWC62904.2025.10903928},
	shorttitle = {{AI} and Generative {AI}-Driven Automation for Multi-Cloud and Hybrid Cloud Architectures},
	abstract = {The emergence of cloud and hybrid cloud structures presents {eCommerce} firms with the adaptability and robustness needed to manage expansion and varying user requirements effectively. However, this also brings about challenges concerning security enhancements, distribution of workloads, and cost-effectiveness optimization. Traditional cloud management models often need help to meet these evolving demands efficiently. This research presents a system that leverages Artificial Intelligence ({AI}) and Generative {AI} (Gen {AI}) to effectively automate and enhance cloud and hybrid infrastructures for ecommerce websites. The system adapts infrastructure to traffic times like holidays or sales events by utilizing {AI} to scale resources as needed. It conserves resources during low user activity periods such as overnight. Ensuring optimal system performance and availability during peak traffic times while cutting costs during traffic periods is essential for cost-effectiveness and efficient resource management. In addition, {AI}-powered security automation safeguards against changing cyber dangers, and compliance automation guarantees conformity with rules like {PCI} {DSS} for payment handling. This report also delves into merging Gen {AI} into cloud coordination systems, facilitating workflows, and enhancing {eCommerce} processes. The outcome is a significant drop in operational expenses, a quicker service rollout, and decreased security breaches. Through real-world {eCommerce} case studies, this paper provides actionable insights for cloud engineers and architects on leveraging {AI}-driven cloud management to enhance performance, security, and cost-efficiency in multi-cloud and hybrid environments, ensuring seamless user experiences and business continuity.},
	pages = {00784--00793},
	journaltitle = {2025 {IEEE} 15th Annual Computing and Communication Workshop and Conference ({CCWC})},
	author = {Seth, Dhruv Kumar and Ratra, Karan Kumar and Sundareswaran, Aneeshkumar P},
	urldate = {2025-04-08},
	date = {2025-01-06},
	note = {Conference Name: 2025 {IEEE} 15th Annual Computing and Communication Workshop and Conference ({CCWC})
{ISBN}: 9798331507695
Place: Las Vegas, {NV}, {USA}
Publisher: {IEEE}},
}

@article{khanna_enhancing_2024,
  author  = {Khanna, Karan},
  title   = {{Enhancing Cloud Security with Generative AI: Emerging Strategies and Applications}},
  journal = {JARET},
  year    = {2024},
  volume  = {3},
  number  = {1},
  pages   = {234--244},
  month   = {Jun.}
}

@online{noauthor_securing_2023,
	title = {Securing generative {AI}: An introduction to the Generative {AI} Security Scoping Matrix {\textbar} {AWS} Security Blog},
	url = {https://aws.amazon.com/blogs/security/securing-generative-ai-an-introduction-to-the-generative-ai-security-scoping-matrix/},
	shorttitle = {Securing generative {AI}},
	urldate = {2025-04-08},
	date = {2023-10-19},
	langid = {american},
	note = {Section: Amazon Bedrock},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/748SVXTA/securing-generative-ai-an-introduction-to-the-generative-ai-security-scoping-matrix.html:text/html},
}

@report{tabassi_artificial_2023,
	location = {Gaithersburg, {MD}},
	title = {Artificial Intelligence Risk Management Framework ({AI} {RMF} 1.0)},
	url = {http://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf},
	abstract = {As directed by the National Artificial Intelligence Initiative Act of 2020 (P.L. 116-283), the goal of the {AI} {RMF} is to offer a resource to the organizations designing, developing, deploying, or using {AI} systems to help manage the many risks of {AI} and promote trustworthy and responsible development and use of {AI} systems. The Framework is intended to be voluntary, rights-preserving, non-sector specific, and use-case agnostic, providing flexibility to organizations of all sizes and in all sectors and throughout society to implement the approaches in the Framework.   The {AI} {RMF} is intended to be practical, to adapt to the {AI} landscape as {AI} technologies continue to develop, and to be operationalized by organizations in varying degrees and capacities so society can benefit from {AI} while also being protected from its potential harms.},
	pages = {NIST AI 100--1},
	number = {{NIST} {AI} 100-1},
	institution = {National Institute of Standards and Technology (U.S.)},
	author = {Tabassi, Elham},
	urldate = {2025-04-08},
	date = {2023-01-26},
	langid = {english},
	doi = {10.6028/NIST.AI.100-1},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/IFJQD782/Tabassi - 2023 - Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf:application/pdf;PDF:/Users/d.veragilliard/Zotero/storage/5EPR3V9L/Tabassi - 2023 - Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf:application/pdf},
}

@article{nyoto_cyber_2024,
  author  = {Nyoto, Rebecca La Volla and Devega, Mariza and Nyoto, Nyoto},
  title   = {{Cyber Security Risks in the Rapid Development of Generative Artificial Intelligence: A Systematic Literature Review}},
  journal = {ComniTech: J. Comput. Intell. Informatics},
  year    = {2024},
  volume  = {1},
  number  = {2},
  pages   = {57--66},
  month   = {Dec.}
}

@misc{yigit_review_2024,
	title = {Review of Generative {AI} Methods in Cybersecurity},
	url = {http://arxiv.org/abs/2403.08701},
	doi = {10.48550/arXiv.2403.08701},
	abstract = {Over the last decade, Artificial Intelligence ({AI}) has become increasingly popular, especially with the use of chatbots such as {ChatGPT}, Gemini, and {DALL}-E. With this rise, large language models ({LLMs}) and Generative {AI} ({GenAI}) have also become more prevalent in everyday use. These advancements strengthen cybersecurity's defensive posture and open up new attack avenues for adversaries as well. This paper provides a comprehensive overview of the current state-of-the-art deployments of {GenAI}, covering assaults, jailbreaking, and applications of prompt injection and reverse psychology. This paper also provides the various applications of {GenAI} in cybercrimes, such as automated hacking, phishing emails, social engineering, reverse cryptography, creating attack payloads, and creating malware. {GenAI} can significantly improve the automation of defensive cyber security processes through strategies such as dataset construction, safe code development, threat intelligence, defensive measures, reporting, and cyberattack detection. In this study, we suggest that future research should focus on developing robust ethical norms and innovative defense mechanisms to address the current issues that {GenAI} creates and to also further encourage an impartial approach to its future application in cybersecurity. Moreover, we underscore the importance of interdisciplinary approaches further to bridge the gap between scientific developments and ethical considerations.},
	number = {{arXiv}:2403.08701},
	publisher = {{arXiv}},
	author = {Yigit, Yagmur and Buchanan, William J. and Tehrani, Madjid G. and Maglaras, Leandros},
	urldate = {2025-04-08},
	date = {2024-03-19},
	eprinttype = {arxiv},
	eprint = {2403.08701 [cs]},
	keywords = {Computer Science - Cryptography and Security},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/93NDWF8C/Yigit et al. - 2024 - Review of Generative AI Methods in Cybersecurity.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/P2VFTJVJ/2403.html:text/html},
}

@incollection{feffer_red-teaming_2025,
	title = {Red-Teaming for Generative {AI}: Silver Bullet or Security Theater?},
	shorttitle = {Red-Teaming for Generative {AI}},
	abstract = {In response to rising concerns surrounding the safety, security, and trustworthiness of Generative {AI} ({GenAI}) models, practitioners and regulators alike have pointed to {AI} red-teaming as a key component of their strategies for identifying and mitigating these risks. However, despite {AI} red-teaming's central role in policy discussions and corporate messaging, significant questions remain about what precisely it means, what role it can play in regulation, and how it relates to conventional red-teaming practices as originally conceived in the field of cybersecurity. In this work, we identify recent cases of red-teaming activities in the {AI} industry and conduct an extensive survey of relevant research literature to characterize the scope, structure, and criteria for {AI} red-teaming practices. Our analysis reveals that prior methods and practices of {AI} red-teaming diverge along several axes, including the purpose of the activity (which is often vague), the artifact under evaluation, the setting in which the activity is conducted (e.g., actors, resources, and methods), and the resulting decisions it informs (e.g., reporting, disclosure, and mitigation). In light of our findings, we argue that while red-teaming may be a valuable big-tent idea for characterizing {GenAI} harm mitigations, and that industry may effectively apply red-teaming and other strategies behind closed doors to safeguard {AI}, gestures towards red-teaming (based on public definitions) as a panacea for every possible risk verge on security theater. To move toward a more robust toolbox of evaluations for generative {AI}, we synthesize our recommendations into a question bank meant to guide and scaffold future {AI} red-teaming practices.},
	pages = {421--437},
	booktitle = {Proceedings of the 2024 {AAAI}/{ACM} Conference on {AI}, Ethics, and Society},
	publisher = {{AAAI} Press},
	author = {Feffer, Michael and Sinha, Anusha and Deng, Wesley H. and Lipton, Zachary C. and Heidari, Hoda},
	urldate = {2025-04-08},
	date = {2025-02-07},
}

@article{vootkuri_multi-cloud_2024,
	title = {Multi-Cloud Data Strategy \& Security for Generative {AI}},
	volume = {12},
	abstract = {The rapid growth of generative artificial intelligence has fundamentally changed the requirements for cloud computing infrastructure, including requisites such as innovative approaches to resource management and development strategies. A multi-cloud strategy involves leveraging multiple cloud providers to execute an application to optimize data management, storage, and processing capabilities for training and inference. This comprehensive research paper aims to study the evolving paradigm of multi-cloud strategies tailored for Generative Artificial intelligence (Gen-{AI}) using the multi-cloud platforms to enhance their infrastructure, reliability, and security and how the costs are optimized by effectively reducing vendor lock-ins and provide a chance to strategically leverage a variety of providers and their skills to meet specific company demands. The paper demonstrates multi cloud data strategy and security frameworks for Gen {AI} applications. The research discusses how to protect {GenAI} using different strategies in enterprise ecosystems.},
	number = {1},
	author = {Vootkuri, Chaitanya},
	date = {2024},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/UWZHX4FU/Vootkuri - 2024 - Multi-Cloud Data Strategy & Security for Generative AI.pdf:application/pdf},
}

@article{sushil_prabhu_prabhakaran_integration_2024,
	title = {Integration Patterns in Unified {AI} and Cloud Platforms: A Systematic Review of Process Automation Technologies},
	volume = {10},
	rights = {https://creativecommons.org/licenses/by/4.0},
	issn = {2456-3307},
	url = {https://ijsrcseit.com/index.php/home/article/view/CSEIT241061229},
	doi = {10.32628/CSEIT241061229},
	shorttitle = {Integration Patterns in Unified {AI} and Cloud Platforms},
	abstract = {This article comprehensively analyzes unified {AI} and cloud platforms, examining their role in transforming process automation and decision systems across industries. The article investigates the architectural frameworks and integration patterns that enable the convergence of {AI} tools, machine learning operations, and workflow orchestration within cloud-native environments. The article explores key innovations, including federated {AI} implementations, real-time data processing architectures, and multi-cloud integration patterns. It provides insights into their practical applications across finance, healthcare, retail, and manufacturing sectors. The article identifies critical success factors in platform implementation, including integrating {MLOps} frameworks, automated decision engines, and compliance tools for {AI} governance. Through case study analysis and architectural evaluation, we demonstrate how unified platforms address traditional challenges in {AI} deployment while enabling scalable, cost-efficient solutions. The findings reveal emerging patterns in platform architecture that facilitate seamless integration of edge computing, real-time analytics, and distributed {AI} systems, contributing to the broader understanding of enterprise {AI} implementation strategies. This article provides valuable insights for researchers and practitioners in cloud engineering, artificial intelligence, and systems integration while highlighting future directions for platform evolution and standardization.},
	pages = {1932--1940},
	number = {6},
	journaltitle = {Int. J. Sci. Res. Comput. Sci. Eng. Inf. Technol},
	author = {{Sushil Prabhu Prabhakaran}},
	urldate = {2025-04-08},
	date = {2024-12-15},
}

@article{bringhenti_security_2023,
	title = {Security automation for multi-cluster orchestration in Kubernetes},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10175419/},
	doi = {10.1109/NetSoft57336.2023.10175419},
	abstract = {In the latest years, multi-domain Kubernetes architectures composed of multiple clusters have been getting more frequent, so as to provide higher workload isolation, resource availability flexibility and scalability for application deployment. However, manually configuring their security may lead to inconsistencies among policies defined in different clusters, or it may require knowledge that the administrator of each domain cannot have. Therefore, this paper proposes an automatic approach for the automatic generation of the network security policies to be deployed in each cluster of a multi-domain Kubernetes deployment. The objectives of this approach are to reduce of configuration errors that human administrators commonly make, and to create transparent cross-cluster communications. This approach has been implemented as a framework named Multi-Cluster Orchestrator, which has been validated in realistic use cases to assess its benefits to Kubernetes orchestration.},
	pages = {480--485},
	journaltitle = {2023 {IEEE} 9th International Conference on Network Softwarization ({NetSoft})},
	author = {Bringhenti, Daniele and Sisto, Riccardo and Valenza, Fulvio},
	urldate = {2025-04-08},
	date = {2023-06-19},
	note = {Conference Name: 2023 {IEEE} 9th International Conference on Network Softwarization ({NetSoft})
{ISBN}: 9798350399806
Place: Madrid, Spain
Publisher: {IEEE}},
}

@article{hammar_digital_2023,
	title = {Digital Twins for Security Automation},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10154288/},
	doi = {10.1109/NOMS56928.2023.10154288},
	abstract = {We present a novel emulation system for creating high-fidelity digital twins of {IT} infrastructures. The digital twins replicate key functionality of the corresponding infrastructures and allow to play out security scenarios in a safe environment. We show that this capability can be used to automate the process of finding effective security policies for a target infrastructure. In our approach, a digital twin of the target infrastructure is used to run security scenarios and collect data. The collected data is then used to instantiate simulations of Markov decision processes and learn effective policies through reinforcement learning, whose performances are validated in the digital twin. This closed-loop learning process executes iteratively and provides continuously evolving and improving security policies. We apply our approach to an intrusion response scenario. Our results show that the digital twin provides the necessary evaluative feedback to learn near-optimal intrusion response policies.},
	pages = {1--6},
	journaltitle = {{NOMS} 2023-2023 {IEEE}/{IFIP} Network Operations and Management Symposium},
	author = {Hammar, Kim and Stadler, Rolf},
	urldate = {2025-04-08},
	date = {2023-05-08},
	note = {Conference Name: {NOMS} 2023-2023 {IEEE}/{IFIP} Network Operations and Management Symposium
{ISBN}: 9781665477161
Place: Miami, {FL}, {USA}
Publisher: {IEEE}},
}

@article{surathunmanun_exploring_2024,
	title = {Exploring the Role of Generative Artificial Intelligence in the Energy Sector: A Comprehensive Literature Review},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10795598/},
	doi = {10.1109/ICUE63019.2024.10795598},
	shorttitle = {Exploring the Role of Generative Artificial Intelligence in the Energy Sector},
	abstract = {Generative Artificial Intelligence ({GenAI}) enhances productivity by creating data, forecasting, optimizing, and understanding human language. In the energy sector, it is projected to have a \$240 billion global economic impact, though research remains limited. This paper reviews {GenAI}'s benefits, challenges, and research gaps in the energy sector, also focusing on climate change efforts. A {PRISMA}-{SCR}-based literature review from January 2022 to May 2024 was conducted using {IEEE} Xplore, {ScienceDirect}, {ACM} Digital Library, and Google Scholar. {GenAI} tools extracted data, verified by researchers. Analysis of 33 papers shows {GenAI} excels in knowledge integration and prediction. It generates synthetic electricity demand data, manages grids, forecasts energy demand, and optimizes renewable energy systems. Key challenges include hallucinations, data biases, privacy concerns, misuse, and system errors. Solutions involve improving training data, system fine-tuning, human oversight, and security measures. Research gaps include synthetic data realism, model evaluation standards, and integrating {GenAI} with blockchain and {IoT}.},
	pages = {1--11},
	journaltitle = {2024 International Conference on Sustainable Energy: Energy Transition and Net-Zero Climate Future ({ICUE})},
	author = {Surathunmanun, Surasak and Ongsakul, Weerakorn and Singh, Jai Govind},
	urldate = {2025-04-08},
	date = {2024-10-21},
	note = {Conference Name: 2024 International Conference on Sustainable Energy: Energy Transition and Net-Zero Climate Future ({ICUE})
{ISBN}: 9798331517076
Place: Pattaya City, Thailand
Publisher: {IEEE}},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/T6QIN8FX/69dd137c561619884ee4aecd95f81a351b7ce328.html:text/html},
}

@online{noauthor_securing_nodate,
	title = {Securing Generative {AI}: Introduction to the Generative {AI} Security Scoping Matrix},
	url = {https://aws.amazon.com/ai/generative-ai/security/scoping-matrix/},
	shorttitle = {Securing Generative {AI}},
	abstract = {Explore how to secure generative {AI} applications with {AWS}. This webpage introduces the Generative {AI} Security Scoping Matrix, providing essential guidelines for securing {AI} infrastructure, models, and applications. Learn best practices for implementing effective security measures to protect your {AI} investments.},
	titleaddon = {Amazon Web Services, Inc.},
	urldate = {2025-04-09},
	langid = {american},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/PPEMLSLJ/scoping-matrix.html:text/html},
}

@online{resources_australias_2024,
	title = {Australia’s {AI} Ethics Principles {\textbar} Australia’s Artificial Intelligence Ethics Principles {\textbar} Department of Industry Science and Resources},
	url = {https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-principles/australias-ai-ethics-principles},
	abstract = {Consider these voluntary principles to ensure {AI} is safe, secure and reliable.},
	titleaddon = {https://www.industry.gov.au/node/91877},
	author = {Resources, Department of Industry Science and},
	urldate = {2025-04-09},
	date = {2024-10-11},
	langid = {australian},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/EYMMH8PS/australias-ai-ethics-principles.html:text/html},
}

@online{noauthor_isoiec_nodate,
	title = {{ISO}/{IEC} 38500:2024},
	url = {https://www.iso.org/standard/81684.html},
	shorttitle = {{ISO}/{IEC} 38500},
	abstract = {Information technology — Governance of {IT} for the organization},
	titleaddon = {{ISO}},
	urldate = {2025-04-09},
	langid = {english},
	file = {d11300:/Users/d.veragilliard/Zotero/storage/HBJ39RQS/d11300.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/UU4JNT3B/81684.html:text/html},
}

@inproceedings{zhou_study_2010,
  author    = {Zhou, Zhimin and Zhongwen, Chen and Tiecheng, Zhou and Xiaohui, Guan},
  title     = {{The Study on Network Intrusion Detection System of Snort}},
  booktitle = {Proc. 2nd Int. Conf. Networking Digit. Soc. (ICNDS)},
  year      = {2010},
  month     = {May},
  pages     = {156--159},
  volume    = {2},
  doi       = {10.1109/ICNDS.2010.5479341}
}

@article{page_prisma_2021,
	title = {The {PRISMA} 2020 statement: an updated guideline for reporting systematic reviews},
	issn = {1756-1833},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.n71},
	doi = {10.1136/bmj.n71},
	shorttitle = {The {PRISMA} 2020 statement},
	abstract = {{POINTS} To ensure a systematic review is valuable to users, authors should prepare a transparent, complete, and accurate account of why the review was done, what they did, and what they found The {PRISMA} 2020 statement provides updated reporting guidance for systematic reviews that reflects advances in methods to identify, select, appraise, and synthesise studies The {PRISMA} 2020 statement consists of a 27-item checklist, an expanded checklist that details reporting recommendations for each item, the {PRISMA} 2020 abstract checklist, and revised flow diagrams for original and updated reviews We anticipate that the {PRISMA} 2020 statement will benefit authors, editors, and peer reviewers of systematic reviews, and different users of reviews, including guideline developers, policy makers, healthcare providers, patients, and other stakeholders {BMJ}: {firPsrtopteucbtliesdhbeyd} caosp1y0r.i1g1h3t,6/ibncmlju.ndi7n1gofnor2u9sMesarrcehla2te02d1t.{oDtoexwtnalonadddeadtafromimnihnttg},{psA}:I//twrawinwi.nbgm, ja.cnodms/imoinla1r2teAcphrinlo2l0o2gi5ebs.y guest.},
	pages = {n71},
	journaltitle = {{BMJ}},
	author = {Page, Matthew J and {McKenzie}, Joanne E and Bossuyt, Patrick M and Boutron, Isabelle and Hoffmann, Tammy C and Mulrow, Cynthia D and Shamseer, Larissa and Tetzlaff, Jennifer M and Akl, Elie A and Brennan, Sue E and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M and Hróbjartsson, Asbjørn and Lalu, Manoj M and Li, Tianjing and Loder, Elizabeth W and Mayo-Wilson, Evan and {McDonald}, Steve and {McGuinness}, Luke A and Stewart, Lesley A and Thomas, James and Tricco, Andrea C and Welch, Vivian A and Whiting, Penny and Moher, David},
	urldate = {2025-04-12},
	date = {2021-03-29},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/29PKSQ2J/Page et al. - 2021 - The PRISMA 2020 statement an updated guideline for reporting systematic reviews.pdf:application/pdf},
}

@article{mell_nist_nodate,
	title = {The {NIST} Definition of Cloud Computing},
	author = {Mell, Peter and Grance, Timothy},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/63CCNWW2/Mell and Grance - The NIST Definition of Cloud Computing.pdf:application/pdf},
}

@misc{abimbola_cloud_2021,
	title = {Cloud Computing Concept and Roots},
	url = {http://arxiv.org/abs/2102.00981},
	doi = {10.48550/arXiv.2102.00981},
	abstract = {Cloud computing is a particular implementation of distributed computing. It inherited many properties of distributed computing such as scalability, reliability and distribution transparency. The transparency middle layer abstracts the underlying platform away from the end user. Virtualization technology is the foundation of Cloud computing. Virtual machine provides abstraction of the physical server resources and securely isolates different users in multi-tenant environment. To the Cloud services consumer, all the computing power and resources are accessed through high speed internet access by client platforms. This eliminates the cost to build and maintain local data center. Resource pooling and rapid elasticity are the main characters of Cloud computing. The scalability of Cloud computing comes from resources which can span multiple data centers and geographic regions. There is virtually no limitation on the amount of resources available from Cloud. New processing and storage resources can be added into the Cloud resource pool seamlessly.},
	number = {{arXiv}:2102.00981},
	publisher = {{arXiv}},
	author = {Abimbola, Bola},
	urldate = {2025-04-15},
	date = {2021-02-09},
	eprinttype = {arxiv},
	eprint = {2102.00981 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/9ITFYC7G/Abimbola - 2021 - Cloud Computing Concept and Roots.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/6NP6GTQI/2102.html:text/html},
}

@inproceedings{nikita_enterprise_2023,
	title = {Enterprise Security Architecture For Cloud Computing: A Review},
	url = {https://ieeexplore.ieee.org/document/10307676},
	doi = {10.1109/ICCCNT56998.2023.10307676},
	shorttitle = {Enterprise Security Architecture For Cloud Computing},
	abstract = {Cloud computing has transformed {IT} in recent years by isolating application and data resources from foundational structures. Providing high-quality service, however, necessitates guaranteeing cloud computing security. Security risks develop when apps run outside of the defined firewall and into the public domain. Any security compromise in a cloud component might be catastrophic for both the organization (the client) and the supplier. As a result, we present in this study a framework and technique for cloud security that can detect cloud computing security concerns.},
	eventtitle = {2023 14th International Conference on Computing Communication and Networking Technologies ({ICCCNT})},
	pages = {1--7},
	booktitle = {2023 14th International Conference on Computing Communication and Networking Technologies ({ICCCNT})},
	author = {Nikita, Nikita and Parashar, Gaurav},
	urldate = {2025-04-15},
	date = {2023-07},
	note = {{ISSN}: 2473-7674},
	keywords = {Cloud computing, Cloud computing security, Computer architecture, Data protection, Firewalls (computing), Network security, Organizations, Security Architecture, Security Frameworks, Stars},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/WADIF3DE/10307676.html:text/html},
}

@article{moura_review_nodate,
	title = {Review and Analysis of Networking Challenges in Cloud Computing},
	author = {Moura, Jose},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/JRK8RUIK/Moura - Review and Analysis of Networking Challenges in Cloud Computing.pdf:application/pdf},
}

@online{blog_blueprint_2024,
	title = {Blueprint for {AI} Agents in Cybersecurity},
	url = {https://www.cybersec-automation.com/p/blueprint-for-ai-agents-in-cybersecurity},
	abstract = {Leveraging {AI} Agents to Evolve Cybersecurity Practices},
	titleaddon = {Cyber Security Automation and Orchestration},
	author = {Blog, Cyber Automation \{and\} Autonomous {SOC}},
	urldate = {2025-04-18},
	date = {2024-07-11},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/Q8TCUBKF/blueprint-for-ai-agents-in-cybersecurity.html:text/html},
}

@online{noauthor_agentic_nodate,
	title = {Agentic {AI} Threat Modeling Framework: {MAESTRO} {\textbar} {CSA}},
	url = {https://cloudsecurityalliance.org/blog/2025/02/06/agentic-ai-threat-modeling-framework-maestro},
	shorttitle = {Agentic {AI} Threat Modeling Framework},
	abstract = {{MAESTRO} (Multi-Agent Environment, Security, Threat, Risk, \& Outcome) is a novel threat modeling framework for Agentic {AI}. Assess risks across the {AI} lifecycle.},
	urldate = {2025-04-18},
}

@online{noauthor_cyber_nodate,
	title = {Cyber Swarm: the rise of the machines Potential application of {AI} agents in offensive and defensive cybersecurity},
	url = {https://eviden.com/publications/digital-security-magazine/ai-and-cybersecurity/ai-agents-system-2-thinking/},
	shorttitle = {Cyber Swarm},
	abstract = {Explore the concept of System 2 thinking, its application through multi-agent systems, and their roles in strengthening offensive and defensive cybersecurity},
	titleaddon = {Eviden},
	urldate = {2025-04-18},
	langid = {american},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/D5NY9QWF/ai-agents-system-2-thinking.html:text/html},
}

@article{ramasankar_molleti_automated_2024,
	title = {Automated threat detection and response using {LLM} agents},
	volume = {24},
	issn = {25819615},
	url = {https://wjarr.com/node/15847},
	doi = {10.30574/wjarr.2024.24.2.3329},
	abstract = {The increase of cyber threats from individual cases to a worldwide problem is the reason why people have shifted their cybersecurity perspectives. Basic defense processes, originally well understood and effective, fail to match modern attacks’ complexity and velocity. Taking into consideration {LLMs} as a recent addition to {AI}, this paper aims at discussing their application in integrating threat detection and response automation systems. As a result, {LLMs}, which have higher capabilities for natural language processing, deliver a revolutionary perspective regarding cybersecurity. Since {LLM} agents can review massive amounts of security data, distinguish patterns, and create contextually appropriate responses, they can bridge the gap between emerging threats and stable security systems. The paper examines the tools used by {LLM} agents, such as natural language processing to analyse the logs, contextual anomaly detection, pattern identification in network traffic, and the analysis of the user’s behaviour. Also, it describes how {LLM} agents can support automated threat handling in the context of threat identification, alert prioritization, context-driven response generation, security policy enforcement, and threat handling. The integration of {LLM} agents into already known systems, including {SIEM} systems and {AI}-Ops platforms, is also considered, which allows for further conclusions on the opportunities to create proactive cybersecurity systems. However, open dilemmas such as adversarial attacks and interpretability are still present, the future for {LLM} agents in cybersecurity is still bright, and there are more possibilities in multi-modal threat analysis and quantum-safe {LLM}-based cryptography.},
	pages = {079--090},
	number = {2},
	journaltitle = {World J. Adv. Res. Rev.},
	author = {{Ramasankar Molleti} and {Vinod Goje} and {Puneet Luthra} and {Prathap Raghavan}},
	urldate = {2025-04-18},
	date = {2024-11-30},
}

@inproceedings{kaswan_generative_2023,
  author    = {Kaswan, Kuldeep Singh and Dhatterwal, Jagjit Singh and Malik, Kiran and Baliyan, Anupam},
  title     = {{Generative AI: A Review on Models and Applications}},
  booktitle = {Proc. Int. Conf. Commun., Security Artif. Intell. (ICCSAI)},
  year      = {2023},
  month     = {Nov.},
  pages     = {699--704},
  location  = {Greater Noida, India},
  publisher = {IEEE},
  doi       = {10.1109/ICCSAI59793.2023.10421601}
}

@article{gatla_advancements_2024,
	title = {Advancements in Generative {AI}: Exploring Fundamentals and Evolution},
	rights = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10594003/},
	doi = {10.1109/ICECCC61767.2024.10594003},
	shorttitle = {Advancements in Generative {AI}},
	abstract = {Generative Artificial Intelligence ({AI}) has emerged as a transformative field with far-reaching implications across various domains. This review manuscript provides a advancements in generative {AI}, focusing on its fundamental concepts, methodologies, and evolutionary trends. We begin by elucidating the foundational principles underlying generative {AI} techniques, including autoregressive models, Variational Autoencoders ({VAEs}), and Generative Adversarial Networks ({GANs}). Subsequently, we delve into the evolution of generative {AI}, discussing recent advancements, challenges, and potential future directions. Through an in-depth analysis of research literature and real-world applications, this manuscript aims to offer insights into the current landscape of generative {AI} and its profound impact on diverse sectors.},
	pages = {1--5},
	journaltitle = {2024 International Conference on Electronics, Computing, Communication and Control Technology ({ICECCC})},
	author = {Gatla, Ranjith Kumar and Gatla, Anitha and Sridhar, Patti and Kumar, Devineni Gireesh and Rao, D S Naga Malleswara},
	urldate = {2025-04-18},
	date = {2024-05-02},
	note = {Conference Name: 2024 International Conference on Electronics, Computing, Communication and Control Technology ({ICECCC})
{ISBN}: 9798350371802
Place: Bengaluru, India
Publisher: {IEEE}},
}

@online{noauthor_generative_nodate-1,
	title = {Generative Artificial Intelligence: A Systematic Review and Applications},
	url = {https://arxiv.org/html/2405.11029v1},
	urldate = {2025-04-18},
	file = {Generative Artificial Intelligence\: A Systematic Review and Applications:/Users/d.veragilliard/Zotero/storage/FEFNVU47/2405.html:text/html},
}

@misc{vaswani_attention_2023,
	title = {Attention Is All You Need},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 {BLEU} on the {WMT} 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 {BLEU}. On the {WMT} 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art {BLEU} score of 41.8 after training for 3.5 days on eight {GPUs}, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	number = {{arXiv}:1706.03762},
	publisher = {{arXiv}},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	urldate = {2025-04-18},
	date = {2023-08-02},
	eprinttype = {arxiv},
	eprint = {1706.03762 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/UE4FQBLZ/Vaswani et al. - 2023 - Attention Is All You Need.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/4Y7WG8PL/1706.html:text/html},
}

@misc{goodfellow_generative_2014,
  author     = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  title      = {{Generative Adversarial Networks}},
  year       = {2014},
  eprinttype = {arXiv},
  eprint     = {1406.2661},
  doi        = {10.48550/arXiv.1406.2661}
}

@article{vijay_ramamoorthi_review_2024,
	title = {A Review of {AI} and Multi-Agent Systems for Cloud Performance and Security},
	volume = {10},
	rights = {https://creativecommons.org/licenses/by/4.0},
	issn = {2456-3307},
	url = {https://ijsrcseit.com/index.php/home/article/view/CSEIT24105112},
	doi = {10.32628/CSEIT24105112},
	abstract = {Cloud computing has become a critical backbone for distributed systems, offering scalability and flexibility across diverse industries. However, ensuring optimal performance and robust security in such dynamic environments presents significant challenges, including inefficient task scheduling, suboptimal resource utilization, and persistent security threats such as data breaches and Distributed Denial of Service ({DDoS}) attacks. This paper examines the transformative potential of Artificial Intelligence ({AI}) and Multi-Agent Systems ({MAS}) in addressing these complexities. {AI}-driven solutions, including real-time anomaly detection, predictive analytics, and resource optimization, are combined with {MAS} frameworks that leverage decentralized, autonomous agents for distributed decision-making and proactive threat mitigation. The integration of {AI} and {MAS} enables dynamic adaptation to workload fluctuations, enhances resource efficiency, and provides robust security measures in multi-cloud and large-scale systems. The paper further explores key challenges in implementing these technologies, such as scalability and integration across heterogeneous environments, and identifies promising research directions to advance their adoption. By synthesizing empirical evidence and recent advancements, this study highlights the critical role of {AI} and {MAS} in shaping the future of cloud performance and security.},
	pages = {326--337},
	number = {4},
	journaltitle = {Int. J. Sci. Res. Comput. Sci. Eng. Inf. Technol},
	author = {{Vijay Ramamoorthi}},
	urldate = {2025-04-18},
	date = {2024-07-15},
}

@article{kalava_best_2024,
	title = {Best {AI} Framework Guide: Build Production-Ready Agents That Work},
	volume = {03},
	issn = {25836129},
	url = {https://isjem.com/download/best-ai-framework-guide-build-production-ready-agents-that-work/},
	doi = {10.55041/ISJEM02191},
	shorttitle = {Best {AI} Framework Guide},
	abstract = {Artificial Intelligence ({AI}) frameworks serve as the foundation for building scalable, production-ready {AI} agents
that enable automation, decision-making, and intelligent interactions. This paper explores the architecture, core
components, and best practices for selecting, deploying, and optimizing {AI} agent frameworks. Additionally, it
addresses security considerations, compliance standards, performance enhancements, and real-world integration
strategies for enterprise adoption.
Keywords
Artificial Intelligence, {AI} Agents, Automation, Scalability, Security, Optimization, Enterprise {AI}},
	pages = {1--9},
	number = {12},
	journaltitle = {{ISJEM}},
	author = {Kalava, Sudheer Peddineni},
	urldate = {2025-04-18},
	date = {2024-12-17},
}

@online{hansen_introducing_2023,
	title = {Introducing Google’s Secure {AI} Framework},
	url = {https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/},
	abstract = {Today Google released released the Secure {AI} Framework to help collaboratively secure {AI} technology.},
	titleaddon = {Google},
	author = {Hansen, Royal and Venables, Phil},
	urldate = {2025-04-25},
	date = {2023-06-08},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/TC3VRHGX/introducing-googles-secure-ai-framework.html:text/html},
}

@online{noauthor_owasp_nodate,
	title = {{OWASP} {AI} Security and Privacy Guide {\textbar} {OWASP} Foundation},
	url = {https://owasp.org/www-project-ai-security-and-privacy-guide/},
	abstract = {Guidance on designing, creating, testing, and procuring secure and privacy-preserving {AI} systems},
	urldate = {2025-04-26},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/WL5IP4Y6/www-project-ai-security-and-privacy-guide.html:text/html},
}

@online{noauthor_owasp_nodate-1,
	title = {{OWASP} Top 10 for Large Language Model Applications {\textbar} {OWASP} Foundation},
	url = {https://owasp.org/www-project-top-10-for-large-language-model-applications/},
	abstract = {Aims to educate developers, designers, architects, managers, and organizations about the potential security risks when deploying and managing Large Language Models ({LLMs})},
	urldate = {2025-04-26},
	langid = {english},
}

@online{editor_llm_nodate,
	title = {{LLM} Applications Cybersecurity and Governance Checklist v1.1 - English},
	url = {https://genai.owasp.org/resource/llm-applications-cybersecurity-and-governance-checklist-english/},
	abstract = {The {OWASP} Top 10 for {LLM} Applications Cybersecurity and Governance Checklist is for leaders across executive, tech, cybersecurity, privacy, compliance, and legal areas, {DevSecOps}, {MLSecOps}, and Cybersecurity teams and defenders. It is intended for people who are striving to stay ahead in the fast-moving {AI} world, aiming not just to leverage {AI} for corporate success […]},
	titleaddon = {{OWASP} Top 10 for {LLM} \& Generative {AI} Security},
	author = {Editor, {OWASPGenAIProject}},
	urldate = {2025-04-27},
	langid = {american},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/YDXV4DIE/llm-applications-cybersecurity-and-governance-checklist-english.html:text/html},
}

@online{editor_llm_nodate-1,
	title = {{LLM} and Generative {AI} Security Center of Excellence Guide},
	url = {https://genai.owasp.org/resource/llm-and-generative-ai-security-center-of-excellence-guide/},
	abstract = {As generative {AI} technologies evolve and integrate into various aspects of business and society, the need for robust governance, security, and policy management becomes paramount. Establishing a Center of Excellence ({COE}) for Generative {AI} Security aims to bring together diverse groups such as security, legal, data science, operations, and end-users to foster collaboration, develop best […]},
	titleaddon = {{OWASP} Top 10 for {LLM} \& Generative {AI} Security},
	author = {Editor, {OWASPGenAIProject}},
	urldate = {2025-04-27},
	langid = {american},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/9UE7J798/llm-and-generative-ai-security-center-of-excellence-guide.html:text/html},
}

@article{pillala_devsecops_2024,
	title = {{DevSecOps} Sentinel: {GenAI}-Driven Agentic Workflows for Comprehensive Supply Chain Security},
	volume = {18},
	rights = {Copyright (c) 2024 Gyani Pillala,Damoon Azarpazhooh,Scott Baxter},
	issn = {1913-8989},
	url = {https://ccsenet.org/journal/index.php/cis/article/view/0/51118},
	doi = {10.5539/cis.v18n1p39},
	shorttitle = {{DevSecOps} Sentinel},
	abstract = {A growing number of security challenges are born out of the complexity of modern software supply chains that span microservices, containerization, and cloud-native architectures. The increasing rate of new cyber-threats, and the need to quickly deploy software updates after a security incident, typically outpaces traditional {DevSecOps} security practices. In this paper, we propose a novel {DevSecOps} Sentinel system, which employs Generative {AI} ({GenAI}) driven agentic workflows to improve software supply chain security holistically.

In this paper, we elaborate on the architecture of {DevSecOps} Sentinel: by integrating cutting-edge {GenAI} models, and by deploying intelligent agentic workflows. Then we dive into how the system impacts our software development life cycle from code writing to production and beyond. Our results indicate that agentic workflows powered by {GenAI} are a viable method to tackle the intricate security issues of modern software supply chains. Integrating the analysis capability of {AI} and marrying this with the strengths that come from agentic systems, {DevSecOps} Sentinel reveals a way forward for organizations seeking to strengthen their security profile in an ever more hostile digital world - to build better software — faster, safer, and reliable.},
	pages = {p39},
	number = {1},
	journaltitle = {Computer and Information Science},
	author = {Pillala, Gyani and Azarpazhooh, Damoon and Baxter, Scott},
	urldate = {2025-04-27},
	date = {2024-12-20},
	langid = {english},
	note = {Number: 1},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/BPBW7V3V/Pillala et al. - 2024 - DevSecOps Sentinel GenAI-Driven Agentic Workflows for Comprehensive Supply Chain Security.pdf:application/pdf},
}

@misc{dash_zero-trust_2024,
	location = {Rochester, {NY}},
	title = {Zero-Trust Architecture ({ZTA}): Designing an {AI}-Powered Cloud Security Framework for {LLMs}' Black Box Problems},
	url = {https://papers.ssrn.com/abstract=4726625},
	doi = {10.2139/ssrn.4726625},
	shorttitle = {Zero-Trust Architecture ({ZTA})},
	abstract = {Businesses are becoming more interested in developing and testing Large Language Models ({LLMs}) in their own settings to support decision-making and growth as a result of the rapid emergence of {AI} and cloud computing. Here's the dilemma, though: to what extent do you believe these models and the data they were trained on? We don't know the feature list of an {LLM}, which presents the first obstacle when discussing trust and the reasons why there should be zero trust. Although it may seem a bit extreme, this is accurate for two reasons. When it comes to {GenAI} models nowadays, the more multimodal and more capabilities they have, the better. This way of thinking is great for exploring and confirming if {GenAI} can address a business problem, but it's a surefire way to run into trouble when attempting to put things into production in an organizational setting. An enterprise cybersecurity architecture known as a zero-trust architecture ({ZTA}) is built on the ideas of zero trust and is intended to stop data breaches, enhance privacy, and restrict internal lateral movement. This article discusses {ZTA}, its logical aspects, probable deployment scenarios, {AI} rules, threats and limitations in order to provide a detailed understanding of why enterprises must adapt a {ZTA} framework in a cloud-based environment for {AI} model deployment.},
	number = {4726625},
	publisher = {Social Science Research Network},
	author = {Dash, Bibhu},
	urldate = {2025-04-27},
	date = {2024-03-12},
	langid = {english},
	keywords = {{AI}-Powered framework, Black Box, {CCPA}, {GDPR}, {IPP}, {LLM}, {PDP}, Zero Trust},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/5ITUH79R/Dash - 2024 - Zero-Trust Architecture (ZTA) Designing an AI-Powered Cloud Security Framework for LLMs' Black Box.pdf:application/pdf},
}

@inproceedings{ismail_big_2025,
	title = {Big Data Architecture for Large Organizations},
	url = {https://www.semanticscholar.org/paper/Big-Data-Architecture-for-Large-Organizations-Ismail-Sengupta/4c954e46ecc91d41e554afba14d3a294b07b7e5e},
	abstract = {The exponential growth of big data has transformed how large organisations leverage information to drive innovation, optimise processes, and maintain competitive advantages. However, managing and extracting insights from vast, heterogeneous data sources requires a scalable, secure, and well-integrated big data architecture. This paper proposes a comprehensive big data framework that aligns with organisational objectives while ensuring flexibility, scalability, and governance. The architecture encompasses multiple layers, including data ingestion, transformation, storage, analytics, machine learning, and security, incorporating emerging technologies such as Generative {AI} ({GenAI}) and low-code machine learning. Cloud-based implementations across Google Cloud, {AWS}, and Microsoft Azure are analysed, highlighting their tools and capabilities. Additionally, this study explores advancements in big data architecture, including {AI}-driven automation, data mesh, and Data Ocean paradigms. By establishing a structured, adaptable framework, this research provides a foundational blueprint for large organisations to harness big data as a strategic asset effectively.},
	author = {Ismail, Fathima Nuzla and Sengupta, Abira and Amarasoma, Shanika},
	urldate = {2025-06-09},
	date = {2025-05-07},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/II2WH5JS/Ismail et al. - 2025 - Big Data Architecture for Large Organizations.pdf:application/pdf},
}

@misc{hayagreevan_security_2024,
	title = {Security of and by Generative {AI} platforms},
	url = {http://arxiv.org/abs/2410.13899},
	doi = {10.48550/arXiv.2410.13899},
	abstract = {This whitepaper highlights the dual importance of securing generative {AI} ({genAI}) platforms and leveraging {genAI} for cybersecurity. As {genAI} technologies proliferate, their misuse poses significant risks, including data breaches, model tampering, and malicious content generation. Securing these platforms is critical to protect sensitive data, ensure model integrity, and prevent adversarial attacks. Simultaneously, {genAI} presents opportunities for enhancing security by automating threat detection, vulnerability analysis, and incident response. The whitepaper explores strategies for robust security frameworks around {genAI} systems, while also showcasing how {genAI} can empower organizations to anticipate, detect, and mitigate sophisticated cyber threats.},
	number = {{arXiv}:2410.13899},
	publisher = {{arXiv}},
	author = {Hayagreevan, Hari and Khamaru, Souvik},
	urldate = {2025-06-09},
	date = {2024-10-15},
	eprinttype = {arxiv},
	eprint = {2410.13899 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/FUB78C6M/Hayagreevan and Khamaru - 2024 - Security of and by Generative AI platforms.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/Q2RG8AVP/2410.html:text/html},
}

@misc{noseevich_towards_2015,
	title = {Towards automated web application logic reconstruction for application level security},
	url = {http://arxiv.org/abs/1511.02564},
	doi = {10.48550/arXiv.1511.02564},
	abstract = {Modern overlay security mechanisms like Web Application Firewalls ({WAF}) suffer from inability to recognize custom high-level application logic and data objects, which results in low accuracy, high false positives rates, and overhelming manual effort for fine tuning. In this paper we propose an approach to web application modeling for security purposes that could help next-generation {WAFs} to adapt to specific web applications, and do it automatically whenever possible. We aim at creating multi-layer models that adequately simulate various aspects of web application functionality that are significant for intrusion detection and prevention, including request parsing and routing, reconstruction of actions and data objects, and action interdependencies.},
	number = {{arXiv}:1511.02564},
	publisher = {{arXiv}},
	author = {Noseevich, George and Gamayunov, Dennis},
	urldate = {2025-06-09},
	date = {2015-11-09},
	eprinttype = {arxiv},
	eprint = {1511.02564 [cs]},
	keywords = {Computer Science - Cryptography and Security},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/C54WINRY/Noseevich and Gamayunov - 2015 - Towards automated web application logic reconstruction for application level security.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/F76YUPCQ/1511.html:text/html},
}

@inproceedings{desai_gen-ai_2024,
	title = {Gen-{AI} for User Safety: A Survey},
	url = {http://arxiv.org/abs/2411.06606},
	doi = {10.1109/BigData62323.2024.10825656},
	shorttitle = {Gen-{AI} for User Safety},
	abstract = {Machine Learning and data mining techniques (i.e. supervised and unsupervised techniques) are used across domains to detect user safety violations. Examples include classifiers used to detect whether an email is spam or a web-page is requesting bank login information. However, existing {ML}/{DM} classifiers are limited in their ability to understand natural languages w.r.t the context and nuances. The aforementioned challenges are overcome with the arrival of Gen-{AI} techniques, along with their inherent ability w.r.t translation between languages, fine-tuning between various tasks and domains. In this manuscript, we provide a comprehensive overview of the various work done while using Gen-{AI} techniques w.r.t user safety. In particular, we first provide the various domains (e.g. phishing, malware, content moderation, counterfeit, physical safety) across which Gen-{AI} techniques have been applied. Next, we provide how Gen-{AI} techniques can be used in conjunction with various data modalities i.e. text, images, videos, audio, executable binaries to detect violations of user-safety. Further, also provide an overview of how Gen-{AI} techniques can be used in an adversarial setting. We believe that this work represents the first summarization of Gen-{AI} techniques for user-safety.},
	pages = {5315--5324},
	booktitle = {2024 {IEEE} International Conference on Big Data ({BigData})},
	author = {Desai, Akshar Prabhu and Ravi, Tejasvi and Luqman, Mohammad and Sharma, Mohit and Kota, Nithya and Yadav, Pranjul},
	urldate = {2025-06-09},
	date = {2024-12-15},
	eprinttype = {arxiv},
	eprint = {2411.06606 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/CDXZPFDL/Desai et al. - 2024 - Gen-AI for User Safety A Survey.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/UZGFQ34D/2411.html:text/html},
}

@misc{ling_enhancing_2024,
	title = {Enhancing Security Control Production With Generative {AI}},
	url = {http://arxiv.org/abs/2411.04284},
	doi = {10.48550/arXiv.2411.04284},
	abstract = {Security controls are mechanisms or policies designed for cloud based services to reduce risk, protect information, and ensure compliance with security regulations. The development of security controls is traditionally a labor-intensive and time-consuming process. This paper explores the use of Generative {AI} to accelerate the generation of security controls. We specifically focus on generating Gherkin codes which are the domain-specific language used to define the behavior of security controls in a structured and understandable format. By leveraging large language models and in-context learning, we propose a structured framework that reduces the time required for developing security controls from 2-3 days to less than one minute. Our approach integrates detailed task descriptions, step-by-step instructions, and retrieval-augmented generation to enhance the accuracy and efficiency of the generated Gherkin code. Initial evaluations on {AWS} cloud services demonstrate promising results, indicating that {GenAI} can effectively streamline the security control development process, thus providing a robust and dynamic safeguard for cloud-based infrastructures.},
	number = {{arXiv}:2411.04284},
	publisher = {{arXiv}},
	author = {Ling, Chen and Ghashami, Mina and Gao, Vianne and Torkamani, Ali and Vaulin, Ruslan and Mangam, Nivedita and Jain, Bhavya and Diwan, Farhan and {SS}, Malini and Cheng, Mingrui and Kumar, Shreya Tarur and Candelario, Felix},
	urldate = {2025-06-09},
	date = {2024-11-06},
	eprinttype = {arxiv},
	eprint = {2411.04284 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Cryptography and Security},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/63MHB3Y2/Ling et al. - 2024 - Enhancing Security Control Production With Generative AI.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/D5NYMBMI/2411.html:text/html},
}

@inproceedings{chen_platform-specific_2025,
	title = {Platform-specific code generation method for the Tyche embedded operating system based on {AADL} models},
	volume = {13545},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13545/1354517/Platform-specific-code-generation-method-for-the-Tyche-embedded-operating/10.1117/12.3061113.full},
	doi = {10.1117/12.3061113},
	abstract = {The Tyche Embedded Operating System is a highly customized real-time embedded operating system, widely applied in fields such as aerospace, medical devices, and industrial automation. Renowned for its robust support for real-time tasks and efficient resource management, this system has become a core technology in embedded system development. The Architecture Analysis and Design Language ({AADL}), as a stringent standardized modeling language, possesses powerful expressiveness and scalability. This paper proposes a method for generating platform-specific code for the Tyche Embedded Operating System based on {AADL} models, which involves describing complex systems through {AADL} modeling and generating safety-critical software suitable for the Tyche Embedded Operating System. Firstly, the paper elaborates on the key aspects of the {AADL} standard and adheres to these aspects for modeling safety-critical systems. Secondly, an intermediate layer is introduced, outlining the mapping rules from the {AADL} common subset to the intermediate code, generating intermediate code for each component within the system architecture, and ultimately compiling it into C code applicable to the Tyche platform. Finally, a prototype tool for code generation is provided, and the effectiveness of the proposed method is validated through a case study of a temperature control system.},
	eventtitle = {Third International Conference on Algorithms, Network, and Communication Technology ({ICANCT} 2024)},
	pages = {328--340},
	booktitle = {Third International Conference on Algorithms, Network, and Communication Technology ({ICANCT} 2024)},
	publisher = {{SPIE}},
	author = {Chen, Li and Jia, Zhangtao and An, Heng and Li, Haoyu},
	urldate = {2025-06-10},
	date = {2025-03-03},
}

@article{kumar_generative_nodate,
	title = {Generative {AI} in Software Architecture: Transforming Design and Development Processes},
	volume = {16},
	rights = {Creative Commons Attribution-{ShareAlike} 4.0 International License},
	issn = {2229-7677},
	url = {https://www.ijsat.org/research-paper.php?id=3718},
	doi = {10.71097/IJSAT.v16.i1.3718},
	shorttitle = {Generative {AI} in Software Architecture},
	number = {1},
	journaltitle = {{IJSAT} - International Journal on Science and Technology},
	author = {Kumar, Ritesh},
	urldate = {2025-06-10},
	note = {Publisher: {IJSAT}},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/L7W95BUV/Kumar - Generative AI in Software Architecture Transforming Design and Development Processes.pdf:application/pdf},
}

@inproceedings{ismail_big_2025-1,
	title = {Big Data Architecture for Large Organizations},
	url = {https://www.semanticscholar.org/paper/Big-Data-Architecture-for-Large-Organizations-Ismail-Sengupta/4c954e46ecc91d41e554afba14d3a294b07b7e5e},
	abstract = {The exponential growth of big data has transformed how large organisations leverage information to drive innovation, optimise processes, and maintain competitive advantages. However, managing and extracting insights from vast, heterogeneous data sources requires a scalable, secure, and well-integrated big data architecture. This paper proposes a comprehensive big data framework that aligns with organisational objectives while ensuring flexibility, scalability, and governance. The architecture encompasses multiple layers, including data ingestion, transformation, storage, analytics, machine learning, and security, incorporating emerging technologies such as Generative {AI} ({GenAI}) and low-code machine learning. Cloud-based implementations across Google Cloud, {AWS}, and Microsoft Azure are analysed, highlighting their tools and capabilities. Additionally, this study explores advancements in big data architecture, including {AI}-driven automation, data mesh, and Data Ocean paradigms. By establishing a structured, adaptable framework, this research provides a foundational blueprint for large organisations to harness big data as a strategic asset effectively.},
	author = {Ismail, Fathima Nuzla and Sengupta, Abira and Amarasoma, Shanika},
	urldate = {2025-06-10},
	date = {2025-05-07},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/EBP9KYNF/Ismail et al. - 2025 - Big Data Architecture for Large Organizations.pdf:application/pdf},
}

@inproceedings{chavan_automation_2024,
	title = {Automation of {AD}-{OHC} Dashbord and Monitoring of Cloud Resources using Genrative {AI} to Reduce Costing and Enhance Performance},
	url = {https://ieeexplore.ieee.org/document/10616299},
	doi = {10.1109/ICICET59348.2024.10616299},
	abstract = {In this extensive review, the incorporation of Generative Artificial Intelligence ({AI}) into ad-hoc dashboards and cloud resource monitoring is investigated in depth. A purpose of this work is to investigate a current research and highlight the transformational potential of generative artificial intelligence for optimising costs, automating tasks, and improving overall cost efficiency. This article includes a comprehensive analysis of a development of ad-hoc cloud computing, a relevance of cloud resource monitoring, and the role that generative artificial intelligence plays in reducing costs. Notable advantages include better user satisfaction, resource optimisation, adaptive learning, and efficient automation. Additionally, precise decision-making and resource optimisation are highlighted. By presenting actual evidence, the study highlights the association between the quality of generative artificial intelligence and the influence it has on society. It finishes with an analysis of generative artificial intelligence applications in ad-hoc dashboards, with a focus on increased resource utilisation, scalability, and timely consistency of cloud resources. In addition, the article addresses constraints and makes suggestions for future paths. These include models that protect users’ privacy, efficient resource utilisation, explainable artificial intelligence, dynamic autonomy, and security-driven generative models. The paper’s goal is to provide the groundwork for further study and improvement.},
	eventtitle = {2024 International Conference on Innovations and Challenges in Emerging Technologies ({ICICET})},
	pages = {1--9},
	booktitle = {2024 International Conference on Innovations and Challenges in Emerging Technologies ({ICICET})},
	author = {Chavan, Parikshit and Chavan, Peeyusha},
	urldate = {2025-06-10},
	date = {2024-06},
	keywords = {Cloud computing, Generative {AI}, Scalability, Resource management, Technological innovation, {AD}-{OHC} Dashbord, Automation, Cloud Computing, Cloud Monitoring., Cloud Resources, Cost Reductions, Costs},
}

@article{lo_increased_2024,
	title = {Increased Productivity and Reduced Waste with Robotic Process Automation and Generative {AI}-powered {IoE} Services},
	rights = {Copyright (c) 2024 Journal of Web Engineering},
	issn = {1544-5976},
	url = {https://journals.riverpublishers.com/index.php/JWE/},
	doi = {10.13052/jwe1540-9589.2313},
	abstract = {The convergence of robotic process automation ({RPA}) and generative {AI} ({GAI}) within the context of Internet of Everything ({IoE}) services represents a profound paradigm shift. This fusion of technologies not only streamlines routine tasks but also catalyzes innovation while harnessing the potential of interconnected devices. Such integration empowers organizations to achieve remarkable gains in efficiency and sustainability. This paper embarks on an exploration of these transformative services, designed to elevate productivity, and curtail wasteful practices in contemporary industries. By closely examining intricate case studies, we illuminate the multifaceted advantages of this integrated approach. Our investigation demonstrates how {RPA} accelerates the execution of repetitive processes, substantially diminishing the margin for human error and amplifying operational efficiency. In contrast, generative {AI} introduces a disruptive force, generating fresh ideas, designs, and solutions, thereby elevating the quality of products and services. The infusion of these cutting-edge technologies into the fabric of {IoE} services paves the way for organizations to attain unprecedented levels of automation, intelligence, and connectivity. Furthermore, this paper comprehensively addresses the intricate challenges and considerations associated with the proposed implementation. We delve into ethical concerns, security implications, and the necessary workforce adaptation to offer a balanced perspective on the adoption of these technologies. Additionally, we navigate through potential limitations and constraints, underscoring the imperative need for strategic planning and robust governance.},
	pages = {53--88},
	journaltitle = {Journal of Web Engineering},
	author = {Lo, Wei and Yang, Chun-Ming and Zhang, Qiansha and Li, Mingyuan},
	urldate = {2025-06-10},
	date = {2024-03-27},
	langid = {english},
	keywords = {waste management},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/LM6B6ER4/Lo et al. - 2024 - Increased Productivity and Reduced Waste with Robotic Process Automation and Generative AI-powered I.pdf:application/pdf},
}

@misc{barrett_actionable_2023,
	title = {Actionable Guidance for High-Consequence {AI} Risk Management: Towards Standards Addressing {AI} Catastrophic Risks},
	url = {http://arxiv.org/abs/2206.08966},
	doi = {10.48550/arXiv.2206.08966},
	shorttitle = {Actionable Guidance for High-Consequence {AI} Risk Management},
	abstract = {Artificial intelligence ({AI}) systems can provide many beneficial capabilities but also risks of adverse events. Some {AI} systems could present risks of events with very high or catastrophic consequences at societal scale. The {US} National Institute of Standards and Technology ({NIST}) has been developing the {NIST} Artificial Intelligence Risk Management Framework ({AI} {RMF}) as voluntary guidance on {AI} risk assessment and management for {AI} developers and others. For addressing risks of events with catastrophic consequences, {NIST} indicated a need to translate from high level principles to actionable risk management guidance. In this document, we provide detailed actionable-guidance recommendations focused on identifying and managing risks of events with very high or catastrophic consequences, intended as a risk management practices resource for {NIST} for {AI} {RMF} version 1.0 (released in January 2023), or for {AI} {RMF} users, or for other {AI} risk management guidance and standards as appropriate. We also provide our methodology for our recommendations. We provide actionable-guidance recommendations for {AI} {RMF} 1.0 on: identifying risks from potential unintended uses and misuses of {AI} systems; including catastrophic-risk factors within the scope of risk assessments and impact assessments; identifying and mitigating human rights harms; and reporting information on {AI} risk factors including catastrophic-risk factors. In addition, we provide recommendations on additional issues for a roadmap for later versions of the {AI} {RMF} or supplementary publications. These include: providing an {AI} {RMF} Profile with supplementary guidance for cutting-edge increasingly multi-purpose or general-purpose {AI}. We aim for this work to be a concrete risk-management practices contribution, and to stimulate constructive dialogue on how to address catastrophic risks and associated issues in {AI} standards.},
	number = {{arXiv}:2206.08966},
	publisher = {{arXiv}},
	author = {Barrett, Anthony M. and Hendrycks, Dan and Newman, Jessica and Nonnecke, Brandie},
	urldate = {2025-06-17},
	date = {2023-02-23},
	eprinttype = {arxiv},
	eprint = {2206.08966 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computers and Society},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/TRQMFW6W/Barrett et al. - 2023 - Actionable Guidance for High-Consequence AI Risk Management Towards Standards Addressing AI Catastr.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/RYELLFI2/2206.html:text/html},
}

@article{zanzotto_human---loop_2019,
	title = {Human-in-the-loop Artificial Intelligence},
	volume = {64},
	issn = {1076-9757},
	url = {http://arxiv.org/abs/1710.08191},
	doi = {10.1613/jair.1.11345},
	abstract = {Little by little, newspapers are revealing the bright future that Artificial Intelligence ({AI}) is building. Intelligent machines will help everywhere. However, this bright future has a dark side: a dramatic job market contraction before its unpredictable transformation. Hence, in a near future, large numbers of job seekers will need financial support while catching up with these novel unpredictable jobs. This possible job market crisis has an antidote inside. In fact, the rise of {AI} is sustained by the biggest knowledge theft of the recent years. Learning {AI} machines are extracting knowledge from unaware skilled or unskilled workers by analyzing their interactions. By passionately doing their jobs, these workers are digging their own graves. In this paper, we propose Human-in-the-loop Artificial Intelligence ({HIT}-{AI}) as a fairer paradigm for Artificial Intelligence systems. {HIT}-{AI} will reward aware and unaware knowledge producers with a different scheme: decisions of {AI} systems generating revenues will repay the legitimate owners of the knowledge used for taking those decisions. As modern Robin Hoods, {HIT}-{AI} researchers should fight for a fairer Artificial Intelligence that gives back what it steals.},
	pages = {243--252},
	journaltitle = {jair},
	author = {Zanzotto, Fabio Massimo},
	urldate = {2025-06-17},
	date = {2019-02-10},
	eprinttype = {arxiv},
	eprint = {1710.08191 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/QP7ISIZ4/Zanzotto - 2019 - Human-in-the-loop Artificial Intelligence.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/4WXXLBSJ/1710.html:text/html},
}

@article{wu_survey_2022,
	title = {A Survey of Human-in-the-loop for Machine Learning},
	volume = {135},
	issn = {0167739X},
	url = {http://arxiv.org/abs/2108.00941},
	doi = {10.1016/j.future.2022.05.014},
	abstract = {Human-in-the-loop aims to train an accurate prediction model with minimum cost by integrating human knowledge and experience. Humans can provide training data for machine learning applications and directly accomplish tasks that are hard for computers in the pipeline with the help of machine-based approaches. In this paper, we survey existing works on human-in-the-loop from a data perspective and classify them into three categories with a progressive relationship: (1) the work of improving model performance from data processing, (2) the work of improving model performance through interventional model training, and (3) the design of the system independent human-in-the-loop. Using the above categorization, we summarize major approaches in the field; along with their technical strengths/ weaknesses, we have simple classification and discussion in natural language processing, computer vision, and others. Besides, we provide some open challenges and opportunities. This survey intends to provide a high-level summarization for human-in-the-loop and motivates interested readers to consider approaches for designing effective human-in-the-loop solutions.},
	pages = {364--381},
	journaltitle = {Future Generation Computer Systems},
	author = {Wu, Xingjiao and Xiao, Luwei and Sun, Yixuan and Zhang, Junhang and Ma, Tianlong and He, Liang},
	urldate = {2025-06-17},
	date = {2022-10},
	eprinttype = {arxiv},
	eprint = {2108.00941 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/YPAFM2DT/Wu et al. - 2022 - A Survey of Human-in-the-loop for Machine Learning.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/IWVQMSDD/2108.html:text/html},
}

@article{andrade_enhancing_2025,
	title = {Enhancing Security in Software Design Patterns and Antipatterns: A Framework for {LLM}-Based Detection},
	volume = {14},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/14/3/586},
	doi = {10.3390/electronics14030586},
	shorttitle = {Enhancing Security in Software Design Patterns and Antipatterns},
	abstract = {The detection of security vulnerabilities in software design patterns and antipatterns is crucial for maintaining robust and maintainable systems, particularly in dynamic Continuous Integration/Continuous Deployment ({CI}/{CD}) environments. Traditional static analysis tools, while effective for identifying isolated issues, often lack contextual awareness, leading to missed vulnerabilities and high rates of false positives. This paper introduces a novel framework leveraging Large Language Models ({LLMs}) to detect and mitigate security risks in design patterns and antipatterns. By analyzing relationships and behavioral dynamics in code, {LLMs} provide a nuanced, context-aware approach to identifying issues such as unauthorized state changes, insecure communication, and improper data handling. The proposed framework integrates key security heuristics—such as the principles of least privilege and input validation—to enhance {LLM} performance. An evaluation of the framework demonstrates its potential to outperform traditional tools in terms of accuracy and efficiency, enabling the proactive detection and remediation of vulnerabilities in real time. This study contributes to the field of software engineering by offering an innovative methodology for securing software systems using {LLMs}, promoting both academic research and practical application in industry settings.},
	pages = {586},
	number = {3},
	journaltitle = {Electronics},
	author = {Andrade, Roberto and Torres, Jenny and Ortiz-Garcés, Iván},
	urldate = {2025-06-18},
	date = {2025-01},
	langid = {english},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {{LLM}, antipatterns, software security},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/7LELERKQ/Andrade et al. - 2025 - Enhancing Security in Software Design Patterns and Antipatterns A Framework for LLM-Based Detection.pdf:application/pdf},
}

@article{andrade_enhancing_2025-1,
	title = {Enhancing Security in Software Design Patterns and Antipatterns: A Framework for {LLM}-Based Detection},
	volume = {14},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/14/3/586},
	doi = {10.3390/electronics14030586},
	shorttitle = {Enhancing Security in Software Design Patterns and Antipatterns},
	abstract = {The detection of security vulnerabilities in software design patterns and antipatterns is crucial for maintaining robust and maintainable systems, particularly in dynamic Continuous Integration/Continuous Deployment ({CI}/{CD}) environments. Traditional static analysis tools, while effective for identifying isolated issues, often lack contextual awareness, leading to missed vulnerabilities and high rates of false positives. This paper introduces a novel framework leveraging Large Language Models ({LLMs}) to detect and mitigate security risks in design patterns and antipatterns. By analyzing relationships and behavioral dynamics in code, {LLMs} provide a nuanced, context-aware approach to identifying issues such as unauthorized state changes, insecure communication, and improper data handling. The proposed framework integrates key security heuristics—such as the principles of least privilege and input validation—to enhance {LLM} performance. An evaluation of the framework demonstrates its potential to outperform traditional tools in terms of accuracy and efficiency, enabling the proactive detection and remediation of vulnerabilities in real time. This study contributes to the field of software engineering by offering an innovative methodology for securing software systems using {LLMs}, promoting both academic research and practical application in industry settings.},
	pages = {586},
	number = {3},
	journaltitle = {Electronics},
	author = {Andrade, Roberto and Torres, Jenny and Ortiz-Garcés, Iván},
	urldate = {2025-06-18},
	date = {2025-01},
	langid = {english},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {{LLM}, antipatterns, software security},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/XMRADTJW/Andrade et al. - 2025 - Enhancing Security in Software Design Patterns and Antipatterns A Framework for LLM-Based Detection.pdf:application/pdf},
}

@misc{li_iris_2025,
	title = {{IRIS}: {LLM}-Assisted Static Analysis for Detecting Security Vulnerabilities},
	url = {http://arxiv.org/abs/2405.17238},
	doi = {10.48550/arXiv.2405.17238},
	shorttitle = {{IRIS}},
	abstract = {Software is prone to security vulnerabilities. Program analysis tools to detect them have limited effectiveness in practice due to their reliance on human labeled specifications. Large language models (or {LLMs}) have shown impressive code generation capabilities but they cannot do complex reasoning over code to detect such vulnerabilities especially since this task requires whole-repository analysis. We propose {IRIS}, a neuro-symbolic approach that systematically combines {LLMs} with static analysis to perform whole-repository reasoning for security vulnerability detection. Specifically, {IRIS} leverages {LLMs} to infer taint specifications and perform contextual analysis, alleviating needs for human specifications and inspection. For evaluation, we curate a new dataset, {CWE}-Bench-Java, comprising 120 manually validated security vulnerabilities in real-world Java projects. A state-of-the-art static analysis tool {CodeQL} detects only 27 of these vulnerabilities whereas {IRIS} with {GPT}-4 detects 55 (+28) and improves upon {CodeQL}'s average false discovery rate by 5\% points. Furthermore, {IRIS} identifies 4 previously unknown vulnerabilities which cannot be found by existing tools. {IRIS} is available publicly at https://github.com/iris-sast/iris.},
	number = {{arXiv}:2405.17238},
	publisher = {{arXiv}},
	author = {Li, Ziyang and Dutta, Saikat and Naik, Mayur},
	urldate = {2025-06-18},
	date = {2025-04-06},
	eprinttype = {arxiv},
	eprint = {2405.17238 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Programming Languages, Computer Science - Software Engineering},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/8GY7RFXK/Li et al. - 2025 - IRIS LLM-Assisted Static Analysis for Detecting Security Vulnerabilities.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/AR9WSYRE/2405.html:text/html},
}

@online{noauthor_streamlining_nodate,
	title = {Streamlining {CI}/{CD} Pipelines with Automated Policy Checks},
	url = {https://cloudsmith.com/blog/streamlining-ci-cd-pipelines-with-automated-policy-checks},
	abstract = {Continuous Integration and Continuous Deployment ({CI}/{CD}) pipelines power modern {DevOps}. They enable teams to deliver software faster, with greater reliability and confidence. However, as development a…},
	titleaddon = {Cloudsmith},
	urldate = {2025-06-26},
	langid = {british},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/4KN6HH5D/streamlining-ci-cd-pipelines-with-automated-policy-checks.html:text/html},
}

@article{preeta_pillai_python-driven_2025,
	title = {Python-driven security automation pipeline for enterprise financial reporting},
	volume = {15},
	issn = {25828266},
	url = {https://journalwjaets.com/node/593},
	doi = {10.30574/wjaets.2025.15.1.0473},
	abstract = {This article examines the implementation of Python-driven security automation within enterprise financial reporting systems. The article highlights critical vulnerabilities in financial applications and demonstrates how Python-based automation frameworks address these challenges through modular architectures, technology integration, and advanced sanitization techniques. The article involving 70,000+ financial reports illustrate significant improvements in vulnerability detection, remediation time, and compliance achievement through {CI}/{CD} pipeline integration, task orchestration with Airflow, and comprehensive monitoring systems. The article reveals that automated security controls substantially reduce error rates, improve operational efficiency, and enhance data integrity while decreasing resource requirements. The article concludes by exploring future trends in security automation, including the growing adoption of machine learning and advanced analytics to further improve threat detection capabilities, with broad implications for the financial services industry's approach to cybersecurity.},
	pages = {2233--2239},
	number = {1},
	journaltitle = {World J. Adv. Eng. Technol. Sci.},
	author = {{Preeta Pillai}},
	urldate = {2025-06-26},
	date = {2025-04-30},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/QS4A8RSN/Preeta Pillai - 2025 - Python-driven security automation pipeline for enterprise financial reporting.pdf:application/pdf},
}

@online{noauthor_human---loop_nodate,
	title = {Human-in-the-loop in {SOC} Automation},
	url = {https://www.xenonstack.com/blog/human-loop-soc-automation},
	abstract = {Explore the role of human-in-the-loop in {SOC} automation, enhancing decision-making, efficiency, and responsiveness in cybersecurity operations.},
	urldate = {2025-06-26},
	langid = {english},
}

@misc{haque_sok_2025,
  author     = {Haque, Ariful and Siddique, Sunzida and Rahman, Md Mahfuzur and Hasan, Ahmed Rafi and Das, Laxmi Rani and Kamal, Marufa and Masura, Tasnim and Gupta, Kishor Datta},
  title      = {{SOK: Exploring Hallucinations and Security Risks in AI-Assisted Software Development with Insights for LLM Deployment}},
  year       = {2025},
  eprinttype = {arXiv},
  eprint     = {2502.18468},
  doi        = {10.48550/arXiv.2502.18468}
}

@online{noauthor_evaluating_2024,
	title = {Evaluating Static Analysis Alerts with {LLMs}},
	url = {https://insights.sei.cmu.edu/blog/evaluating-static-analysis-alerts-with-llms/},
	abstract = {{LLMs} show promising initial results in adjudicating static analysis alerts, offering possibilities for better vulnerability detection. This post discusses initial experiments using {GPT}-4 to evaluate static analysis alerts.},
	urldate = {2025-06-26},
	date = {2024-10-07},
	langid = {english},
}

@misc{ozgur_simple_2024,
	title = {A Simple Architecture for Enterprise Large Language Model Applications based on Role based security and Clearance Levels using Retrieval-Augmented Generation or Mixture of Experts},
	url = {http://arxiv.org/abs/2407.06718},
	doi = {10.48550/arXiv.2407.06718},
	abstract = {This study proposes a simple architecture for Enterprise application for Large Language Models ({LLMs}) for role based security and {NATO} clearance levels. Our proposal aims to address the limitations of current {LLMs} in handling security and information access. The proposed architecture could be used while utilizing Retrieval-Augmented Generation ({RAG}) and fine tuning of Mixture of experts models ({MoE}). It could be used only with {RAG}, or only with {MoE} or with both of them. Using roles and security clearance level of the user, documents in {RAG} and experts in {MoE} are filtered. This way information leakage is prevented.},
	number = {{arXiv}:2407.06718},
	publisher = {{arXiv}},
	author = {Özgür, Atilla and Uygun, Yılmaz},
	urldate = {2025-06-26},
	date = {2024-07-09},
	eprinttype = {arxiv},
	eprint = {2407.06718 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/LVD39QTQ/Özgür and Uygun - 2024 - A Simple Architecture for Enterprise Large Language Model Applications based on Role based security.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/TVHQJZXR/2407.html:text/html},
}

@online{noauthor_ground_nodate,
	title = {Ground responses using {RAG} {\textbar} Generative {AI} on Vertex {AI}},
	url = {https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/ground-responses-using-rag},
	titleaddon = {Google Cloud},
	urldate = {2025-06-26},
	langid = {english},
}

@inproceedings{noauthor_testbed_2025,
	title = {A Testbed for Operations in the Information Environment {\textbar} Request {PDF}},
	url = {https://www.researchgate.net/publication/383085784_A_Testbed_for_Operations_in_the_Information_Environment},
	doi = {10.1145/3675741.3675751},
	abstract = {Request {PDF} {\textbar} On Aug 13, 2024, Adam Tse and others published A Testbed for Operations in the Information Environment {\textbar} Find, read and cite all the research you need on {ResearchGate}},
	booktitle = {{ResearchGate}},
	urldate = {2025-06-26},
	date = {2025-02-12},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/DETPWEVX/383085784_A_Testbed_for_Operations_in_the_Information_Environment.html:text/html},
}

@misc{lim_explicate_2025,
	title = {{EXPLICATE}: Enhancing Phishing Detection through Explainable {AI} and {LLM}-Powered Interpretability},
	url = {http://arxiv.org/abs/2503.20796},
	doi = {10.48550/arXiv.2503.20796},
	shorttitle = {{EXPLICATE}},
	abstract = {Sophisticated phishing attacks have emerged as a major cybersecurity threat, becoming more common and difficult to prevent. Though machine learning techniques have shown promise in detecting phishing attacks, they function mainly as "black boxes" without revealing their decision-making rationale. This lack of transparency erodes the trust of users and diminishes their effective threat response. We present {EXPLICATE}: a framework that enhances phishing detection through a three-component architecture: an {ML}-based classifier using domain-specific features, a dual-explanation layer combining {LIME} and {SHAP} for complementary feature-level insights, and an {LLM} enhancement using {DeepSeek} v3 to translate technical explanations into accessible natural language. Our experiments show that {EXPLICATE} attains 98.4 \% accuracy on all metrics, which is on par with existing deep learning techniques but has better explainability. High-quality explanations are generated by the framework with an accuracy of 94.2 \% as well as a consistency of 96.8{\textbackslash}\% between the {LLM} output and model prediction. We create {EXPLICATE} as a fully usable {GUI} application and a light Chrome extension, showing its applicability in many deployment situations. The research shows that high detection performance can go hand-in-hand with meaningful explainability in security applications. Most important, it addresses the critical divide between automated {AI} and user trust in phishing detection systems.},
	number = {{arXiv}:2503.20796},
	publisher = {{arXiv}},
	author = {Lim, Bryan and Huerta, Roman and Sotelo, Alejandro and Quintela, Anthonie and Kumar, Priyanka},
	urldate = {2025-06-26},
	date = {2025-03-22},
	eprinttype = {arxiv},
	eprint = {2503.20796 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/79YGBKVK/Lim et al. - 2025 - EXPLICATE Enhancing Phishing Detection through Explainable AI and LLM-Powered Interpretability.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/2FFKWE76/2503.html:text/html},
}

@misc{fakih_llm4cve_2025,
	title = {{LLM}4CVE: Enabling Iterative Automated Vulnerability Repair with Large Language Models},
	url = {http://arxiv.org/abs/2501.03446},
	doi = {10.48550/arXiv.2501.03446},
	shorttitle = {{LLM}4CVE},
	abstract = {Software vulnerabilities continue to be ubiquitous, even in the era of {AI}-powered code assistants, advanced static analysis tools, and the adoption of extensive testing frameworks. It has become apparent that we must not simply prevent these bugs, but also eliminate them in a quick, efficient manner. Yet, human code intervention is slow, costly, and can often lead to further security vulnerabilities, especially in legacy codebases. The advent of highly advanced Large Language Models ({LLM}) has opened up the possibility for many software defects to be patched automatically. We propose {LLM}4CVE an {LLM}-based iterative pipeline that robustly fixes vulnerable functions in real-world code with high accuracy. We examine our pipeline with State-of-the-Art {LLMs}, such as {GPT}-3.5, {GPT}-4o, Llama 38B, and Llama 3 70B. We achieve a human-verified quality score of 8.51/10 and an increase in groundtruth code similarity of 20\% with Llama 3 70B. To promote further research in the area of {LLM}-based vulnerability repair, we publish our testing apparatus, fine-tuned weights, and experimental data on our website},
	number = {{arXiv}:2501.03446},
	publisher = {{arXiv}},
	author = {Fakih, Mohamad and Dharmaji, Rahul and Bouzidi, Halima and Araya, Gustavo Quiros and Ogundare, Oluwatosin and Faruque, Mohammad Abdullah Al},
	urldate = {2025-06-26},
	date = {2025-01-07},
	eprinttype = {arxiv},
	eprint = {2501.03446 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Software Engineering},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/9SJ98W5G/Fakih et al. - 2025 - LLM4CVE Enabling Iterative Automated Vulnerability Repair with Large Language Models.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/56ZU5RN9/2501.html:text/html},
}

@inproceedings{noauthor_artificial_2025,
	title = {Artificial Intelligence for Cybersecurity: A State of the Art {\textbar} Request {PDF}},
	url = {https://www.researchgate.net/publication/388722398_Artificial_Intelligence_for_Cybersecurity_A_State_of_the_Art},
	doi = {10.1109/ICAIC63015.2025.10848980},
	shorttitle = {Artificial Intelligence for Cybersecurity},
	abstract = {Request {PDF} {\textbar} On Feb 5, 2025, Abdullah Al Siam and others published Artificial Intelligence for Cybersecurity: A State of the Art {\textbar} Find, read and cite all the research you need on {ResearchGate}},
	booktitle = {{ResearchGate}},
	urldate = {2025-06-26},
	date = {2025-03-22},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/IDACMA4X/388722398_Artificial_Intelligence_for_Cybersecurity_A_State_of_the_Art.html:text/html},
}

@misc{zhang_empirical_2024,
	title = {An Empirical Study of Automated Vulnerability Localization with Large Language Models},
	url = {http://arxiv.org/abs/2404.00287},
	doi = {10.48550/arXiv.2404.00287},
	abstract = {Recently, Automated Vulnerability Localization ({AVL}) has attracted much attention, aiming to facilitate diagnosis by pinpointing the lines of code responsible for discovered vulnerabilities. Large Language Models ({LLMs}) have shown potential in various domains, yet their effectiveness in vulnerability localization remains underexplored. In this work, we perform the first comprehensive study of {LLMs} for {AVL}. Our investigation encompasses 10+ leading {LLMs} suitable for code analysis, including {ChatGPT} and various open-source models, across three architectural types: encoder-only, encoder-decoder, and decoder-only, with model sizes ranging from 60M to 16B parameters. We explore the efficacy of these {LLMs} using 4 distinct paradigms: zero-shot learning, one-shot learning, discriminative fine-tuning, and generative fine-tuning. Our evaluation framework is applied to the {BigVul}-based dataset for C/C++, and an additional dataset comprising smart contract vulnerabilities. The results demonstrate that discriminative fine-tuning of {LLMs} can significantly outperform existing learning-based methods for {AVL}, while other paradigms prove less effective or unexpectedly ineffective for the task. We also identify challenges related to input length and unidirectional context in fine-tuning processes for encoders and decoders. We then introduce two remedial strategies: the sliding window and the right-forward embedding, both of which substantially enhance performance. Furthermore, our findings highlight certain generalization capabilities of {LLMs} across Common Weakness Enumerations ({CWEs}) and different projects, indicating a promising pathway toward their practical application in vulnerability localization.},
	number = {{arXiv}:2404.00287},
	publisher = {{arXiv}},
	author = {Zhang, Jian and Wang, Chong and Li, Anran and Sun, Weisong and Zhang, Cen and Ma, Wei and Liu, Yang},
	urldate = {2025-06-26},
	date = {2024-03-30},
	eprinttype = {arxiv},
	eprint = {2404.00287 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Software Engineering},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/6AGRZFFX/Zhang et al. - 2024 - An Empirical Study of Automated Vulnerability Localization with Large Language Models.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/GQVKV35W/2404.html:text/html},
}

@inproceedings{gunathilaka_context-aware_2025,
  author    = {Gunathilaka, Pawara and Senadheera, Dinal and Perara, Shenan and Gunawardana, Chamithu and Thelijjagoda, Samantha and Krishara, Jenny},
  title     = {{Context-Aware Behavior-Driven Pipeline Generation}},
  booktitle = {Proc. 13th Int. Symp. Digit. Forensics Security (ISDFS)},
  year      = {2025},
  month     = {Apr.},
  pages     = {1--6},
  doi       = {10.1109/ISDFS65363.2025.11011952}
}


@article{alevizos_towards_2024,
	title = {Towards an {AI}-Enhanced Cyber Threat Intelligence Processing Pipeline},
	volume = {13},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/13/11/2021},
	doi = {10.3390/electronics13112021},
	abstract = {Cyber threats continue to evolve in complexity, thereby traditional cyber threat intelligence ({CTI}) methods struggle to keep pace. {AI} offers a potential solution, automating and enhancing various tasks, from data ingestion to resilience verification. This paper explores the potential of integrating artificial intelligence ({AI}) into {CTI}. We provide a blueprint of an {AI}-enhanced {CTI} processing pipeline and detail its components and functionalities. The pipeline highlights the collaboration between {AI} and human expertise, which is necessary to produce timely and high-fidelity cyber threat intelligence. We also explore the automated generation of mitigation recommendations, harnessing {AI}’s capabilities to provide real-time, contextual, and predictive insights. However, the integration of {AI} into {CTI} is not without its challenges. Thereby, we discuss the ethical dilemmas, potential biases, and the imperative for transparency in {AI}-driven decisions. We address the need for data privacy, consent mechanisms, and the potential misuse of technology. Moreover, we highlight the importance of addressing biases both during {CTI} analysis and within {AI} models, warranting their transparency and interpretability. Lastly, our work points out future research directions, such as the exploration of advanced {AI} models to augment cyber defenses, and human–{AI} collaboration optimization. Ultimately, the fusion of {AI} with {CTI} appears to hold significant potential in the cybersecurity domain.},
	pages = {2021},
	number = {11},
	journaltitle = {Electronics},
	author = {Alevizos, Lampis and Dekker, Martijn},
	urldate = {2025-06-26},
	date = {2024-01},
	langid = {english},
	note = {Number: 11
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {artificial intelligence, cyber threat intelligence, {CTI} and {AI} biases, cyber resilience, ethical considerations},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/WF54MVFY/Alevizos and Dekker - 2024 - Towards an AI-Enhanced Cyber Threat Intelligence Processing Pipeline.pdf:application/pdf},
}

@inproceedings{akiri_generative_2025,
	title = {Generative {AI} for Real-Time Cloud Security: Advanced Anomaly Detection Using {GPT} Models},
	url = {https://ieeexplore.ieee.org/document/11011269},
	doi = {10.1109/ICCA65395.2025.11011269},
	shorttitle = {Generative {AI} for Real-Time Cloud Security},
	abstract = {As cloud infrastructures become increasingly complex and integral to modern enterprises, the demand for advanced, real-time security solutions has grown significantly. Traditional anomaly detection systems often struggle to keep pace with the rapid evolution of cyber threats in these dynamic environments, particularly when faced with novel or sophisticated attacks. Such systems typically rely on predefined rules or signature-based detection, which limits their effectiveness in identifying emerging security risks. This paper explores the potential of generative {AI} models, specifically {LLaMA} and {OpenAI}’s {GPT} architectures, to enhance real-time cloud security. By leveraging the advanced pattern recognition and adaptive capabilities of these models, we propose a framework that can analyze vast amounts of cloud data, including logs, network traffic, user behavior, and system activities, to detect abnormal patterns indicative of security threats. The real-time anomaly detection offered by generative {AI} provides a significant advantage over traditional methods, as it continuously learns from new data, thereby improving its ability to identify novel threats in complex cloud environments.This research addresses key gaps in current cloud security practices, highlighting the limitations of existing systems in detecting previously unknown threats. The proposed approach introduces generative {AI} as a highly adaptive and scalable solution for cloud anomaly detection, capable of responding to evolving threats in real-time. By using models such as {GPT}, which are known for their ability to generate coherent predictions based on diverse inputs, the framework offers a novel means of safe-guarding cloud infrastructure. This study not only underscores the benefits of employing generative {AI} for security purposes but also provides a robust methodology for integrating these models into cloud security systems. The paper concludes with an assessment of the practical deployment of these {AI} models in large-scale cloud environments, demonstrating their potential to significantly enhance the resilience and adaptability of modern cloud security frameworks.},
	eventtitle = {2025 {IEEE} Conference on Computer Applications ({ICCA})},
	pages = {1--6},
	booktitle = {2025 {IEEE} Conference on Computer Applications ({ICCA})},
	author = {Akiri, Charan Kumar and Jayabalan, Kathiresan and Lopes, Joel and Kareem, Shaik Abdul and Tabbassum, Ayisha},
	urldate = {2025-06-26},
	date = {2025-03},
	keywords = {Cloud computing security, Organizations, Generative {AI}, Security, Adaptation models, Anomaly detection, Cloud Security, Data models, {GPT} and {LLaMA} Models, Real-time Anomaly Detection, Real-time systems, Scalability, Telecommunication traffic, Zero-Day Attack Detection},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/6I4SWV5E/11011269.html:text/html},
}

@article{noauthor_pdf_2025,
	title = {({PDF}) {AI}-driven cybersecurity framework for software development based on the {ANN}-{ISM} paradigm},
	url = {https://www.researchgate.net/publication/390922505_AI-driven_cybersecurity_framework_for_software_development_based_on_the_ANN-ISM_paradigm},
	doi = {10.1038/s41598-025-97204-y},
	abstract = {{PDF} {\textbar} With the increasing reliance on software applications, cybersecurity threats have become a critical concern for developers and organizations. The... {\textbar} Find, read and cite all the research you need on {ResearchGate}},
	journaltitle = {{ResearchGate}},
	urldate = {2025-06-26},
	date = {2025-04-23},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/QE8HQFLA/390922505_AI-driven_cybersecurity_framework_for_software_development_based_on_the_ANN-ISM_parad.html:text/html},
}

@inproceedings{nicosia_risk_nodate,
	title = {Risk management in human-in-the-loop {AI}-assisted attention aware systems},
	url = {https://www.semanticscholar.org/paper/Risk-management-in-human-in-the-loop-AI-assisted-Nicosia-Kristensson/49d3e97575ba5e53fba8d772750a4fa93c7c2cb6},
	abstract = {Semantic Scholar extracted view of "Risk management in human-in-the-loop {AI}-assisted attention aware systems" by Max Nicosia et al.},
	author = {Nicosia, Max and Kristensson, Ola},
	urldate = {2025-06-26},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/HGPPAGNJ/Nicosia and Kristensson - Risk management in human-in-the-loop AI-assisted attention aware systems.pdf:application/pdf},
}

@article{sarathe_krisshnan_jutoo_vijayaraghavan_policy_2025,
	title = {Policy as Code: A paradigm shifts in infrastructure security and governance},
	volume = {26},
	issn = {25819615},
	url = {https://journalwjarr.com/node/1380},
	doi = {10.30574/wjarr.2025.26.1.1441},
	shorttitle = {Policy as Code},
	abstract = {Policy as Code represents a transformative approach to infrastructure security and governance in modern cloud environments. By codifying security and compliance policies as machine-readable code, organizations can automate enforcement throughout the development lifecycle. This paradigm shift addresses the velocity gap between rapid development cycles and traditionally slower security processes, enabling consistent policy enforcement without sacrificing agility. The integration with {CI}/{CD} pipelines allows for "shifting left" security considerations, identifying and remediating issues before they reach production. Various implementation approaches have emerged, from open-source tools like Open Policy Agent to cloud-native solutions, each with distinct advantages. While implementation challenges exist, including policy language complexity and organizational alignment, established best practices help organizations navigate these hurdles. As infrastructure continues to evolve, Policy as Code emerges as an essential strategy for maintaining security and compliance in dynamic, cloud-native environments, transforming governance from a perceived roadblock into an enabler of innovation.},
	pages = {3399--3405},
	number = {1},
	journaltitle = {World J. Adv. Res. Rev.},
	author = {{Sarathe Krisshnan Jutoo Vijayaraghavan}},
	urldate = {2025-06-26},
	date = {2025-04-30},
}

@inproceedings{noauthor_towards_2025,
	title = {Towards Transparent Intrusion Detection: A Coherence-Based Framework in Explainable {AI} Integrating Large Language Models},
	url = {https://www.researchgate.net/publication/388090990_Towards_Transparent_Intrusion_Detection_A_Coherence-Based_Framework_in_Explainable_AI_Integrating_Large_Language_Models},
	doi = {10.1109/TPS-ISA62245.2024.00020},
	shorttitle = {Towards Transparent Intrusion Detection},
	abstract = {Download Citation {\textbar} On Oct 28, 2024, Areej Alnahdi and others published Towards Transparent Intrusion Detection: A Coherence-Based Framework in Explainable {AI} Integrating Large Language Models {\textbar} Find, read and cite all the research you need on {ResearchGate}},
	booktitle = {{ResearchGate}},
	urldate = {2025-06-26},
	date = {2025-01-19},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/SR7VHLBW/388090990_Towards_Transparent_Intrusion_Detection_A_Coherence-Based_Framework_in_Explainable_AI.html:text/html},
}

@misc{howard_terraform_2022,
	title = {Terraform -- Automating Infrastructure as a Service},
	url = {http://arxiv.org/abs/2205.10676},
	doi = {10.48550/arXiv.2205.10676},
	abstract = {Developing a software service requires a strict software development life cycle and process. This process demands controlling all application code through source control management as well as a rigorous versioning and branching strategy. However, the platform and infrastructure also benefit from this rigor. Software services must be deployed to a target run time environment and provisioning that environment through manual user actions is tedious and error-prone. Provisioning manually also becomes prohibitive as the number of resources grow and spread globally over multiple regions. The answer is to apply the same rigor to provisioning the infrastructure as applied to developing the application software. Terraform provides a platform allowing infrastructure resources to be defined in code. This code not only allows the automation of the infrastructure provisioning but also allows for a strict development and review life cycle, same as the application software.},
	number = {{arXiv}:2205.10676},
	publisher = {{arXiv}},
	author = {Howard, Michael},
	urldate = {2025-07-16},
	date = {2022-05-21},
	eprinttype = {arxiv},
	eprint = {2205.10676 [cs]},
	note = {version: 1},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Software Engineering},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/LF9VYKNJ/Howard - 2022 - Terraform -- Automating Infrastructure as a Service.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/9LQBL6L4/2205.html:text/html},
}

@online{noauthor_welcome_nodate,
	title = {Welcome to {AWS} Documentation},
	url = {https://docs.aws.amazon.com/},
	urldate = {2025-07-16},
}

@online{noauthor_claude_nodate,
	title = {Claude Code on Amazon Bedrock},
	url = {https://docs.anthropic.com/en/docs/claude-code/amazon-bedrock},
	abstract = {Learn about configuring Claude Code through Amazon Bedrock, including setup, {IAM} configuration, and troubleshooting.},
	titleaddon = {Anthropic},
	urldate = {2025-07-16},
	langid = {english},
}

@online{noauthor_terraform_nodate,
	title = {Terraform {CLI} Documentation {\textbar} Terraform {\textbar} {HashiCorp} Developer},
	url = {https://developer.hashicorp.com/terraform/cli},
	abstract = {Learn Terraform's {CLI}-based workflows. You can use the {CLI} alone or with {HCP} Terraform or Terraform Enterprise.},
	titleaddon = {Terraform {CLI} Documentation {\textbar} Terraform {\textbar} {HashiCorp} Developer},
	urldate = {2025-07-16},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/UXDIWRIF/cli.html:text/html},
}

@online{noauthor_introduction_nodate,
	title = {Introduction {\textbar} Open Policy Agent},
	url = {https://openpolicyagent.org/docs},
	abstract = {The Open Policy Agent ({OPA}, pronounced "oh-pa") is an open source,},
	urldate = {2025-07-16},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/DKYK29AF/docs.html:text/html},
}

@online{noauthor_whats_nodate,
	title = {What’s New In Python 3.12},
	url = {https://docs.python.org/3/whatsnew/3.12.html},
	abstract = {Editor, Adam Turner,. This article explains the new features in Python 3.12, compared to 3.11. Python 3.12 was released on October 2, 2023. For full details, see the changelog. Summary – Release hi...},
	titleaddon = {Python documentation},
	urldate = {2025-07-16},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/HTLJ4T5J/3.12.html:text/html},
}

@online{noauthor_github_2025,
	title = {{GitHub} Actions},
	url = {https://github.com/features/actions},
	abstract = {Easily build, package, release, update, and deploy your project in any language—on {GitHub} or any external system—without having to run code yourself.},
	titleaddon = {{GitHub}},
	urldate = {2025-07-16},
	date = {2025},
	langid = {english},
}

@online{noauthor_aws_nodate,
	title = {{AWS} Well-Architected Framework - {AWS} Well-Architected Framework},
	url = {https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html},
	urldate = {2025-07-20},
	file = {AWS Well-Architected Framework - AWS Well-Architected Framework:/Users/d.veragilliard/Zotero/storage/YZZXJ38U/welcome.html:text/html},
}

@misc{lewis_retrieval-augmented_2021,
	title = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
	url = {http://arxiv.org/abs/2005.11401},
	doi = {10.48550/arXiv.2005.11401},
	abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream {NLP} tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation ({RAG}) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce {RAG} models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two {RAG} formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive {NLP} tasks and set the state-of-the-art on three open domain {QA} tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that {RAG} models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
	number = {{arXiv}:2005.11401},
	publisher = {{arXiv}},
	author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Küttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rocktäschel, Tim and Riedel, Sebastian and Kiela, Douwe},
	urldate = {2025-07-20},
	date = {2021-04-12},
	eprinttype = {arxiv},
	eprint = {2005.11401 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/RCVVSUXU/Lewis et al. - 2021 - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/6J5AR49Q/2005.html:text/html},
}

@online{noauthor_introduction_nodate-1,
	title = {Introduction to Infrastructure as Code {\textbar} springerprofessional.de},
	url = {https://www.springerprofessional.de/introduction-to-infrastructure-as-code/23724222},
	abstract = {Get inspired to explore the depths of the {DevOps} field. In today’s rapidly transforming world, Infrastructure as Code ({IaC}) has emerged as an},
	urldate = {2025-07-20},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/XWJJXAAJ/23724222.html:text/html},
}

@book{martin_clean_2009,
	location = {Upper Saddle River, {NJ}},
	title = {Clean Code: A Handbook of Agile Software Craftsmanship},
	isbn = {978-0-13-235088-4},
	shorttitle = {Clean Code},
	abstract = {Even bad code can function. But if code isn’t clean, it can bring a development organization to its knees. Every year, countless hours and significant resources are lost because of poorly written code. But it doesn’t have to be that way. Noted software expert Robert C. Martin presents a revolutionary paradigm with Clean Code: A Handbook of Agile Software Craftsmanship . Martin has teamed up with his colleagues from Object Mentor to distill their best agile practice of cleaning code “on the fly” into a book that will instill within you the values of a software craftsman and make you a better programmer—but only if you work at it. What kind of work will you be doing? You’ll be reading code—lots of code. And you will be challenged to think about what’s right about that code, and what’s wrong with it. More importantly, you will be challenged to reassess your professional values and your commitment to your craft. Clean Code is divided into three parts. The first describes the principles, patterns, and practices of writing clean code. The second part consists of several case studies of increasing complexity. Each case study is an exercise in cleaning up code—of transforming a code base that has some problems into one that is sound and efficient. The third part is the payoff: a single chapter containing a list of heuristics and “smells” gathered while creating the case studies. The result is a knowledge base that describes the way we think when we write, read, and clean code. Readers will come away from this book understanding How to tell the difference between good and bad code How to write good code and how to transform bad code into good code How to create good names, good functions, good objects, and good classes How to format code for maximum readability How to implement complete error handling without obscuring code logic How to unit test and practice test-driven development This book is a must for any developer, software engineer, project manager, team lead, or systems analyst with an interest in producing better code.},
	pagetotal = {464},
	publisher = {Pearson},
	author = {Martin, Robert},
	date = {2009},
}

@online{noauthor_pytest_nodate,
	title = {pytest documentation},
	url = {https://docs.pytest.org/en/stable/},
	urldate = {2025-07-20},
	file = {pytest documentation:/Users/d.veragilliard/Zotero/storage/CJZ4BIUJ/stable.html:text/html},
}

@article{dasari_infrastructure_2025,
  author  = {Dasari, Hari},
  title   = {{Infrastructure as Code (IaC) Best Practices for Multi-Cloud Deployments in Enterprises}},
  journal = {Int. J. Netw. Secur.},
  year    = {2025},
  month   = {Jun.},
  volume  = {5},
  number  = {1},
  pages   = {174--186},
  doi     = {10.55640/ijns-05-01-10}
}

@book{gitops_nodate,
  author    = {Beetz, Florian and Kammer, Anja and Harrer, Simon and Scheungrab, Sonja},
  title     = {{GitOps: Cloud-Native Continuous Deployment}},
  publisher = {Liquid Reply GmbH},
  year      = {2021},
  isbn      = {978-3982112688}
}

@inproceedings{delicheh_mitigating_2024,
	location = {New York, {NY}, {USA}},
	title = {Mitigating Security Issues in {GitHub} Actions},
	isbn = {979-8-4007-0565-6},
	url = {https://doi.org/10.1145/3643662.3643961},
	doi = {10.1145/3643662.3643961},
	series = {{EnCyCriS}/{SVM} '24},
	abstract = {Collaborative practices have revolutionised the software development process, enabling distributed teams to seamlessly work together. Social coding platforms have integrated {CI}/{CD} automation workflows, with {GitHub} Actions emerging as a prominent automation ecosystem for {GitHub} repositories. While automation brings efficiency, it also introduces security challenges, often related to software supply chain attacks and workflow misconfigurations. We outline the security issues associated with the software supply chain of {GitHub} Actions workflows, most notably their reusable Actions and their dependencies. We also explore the security risks associated with misconfigurations of repositories and workflows, such as poor permission management, command injection, and credential exposure. To mitigate these risks we suggest practical remediations, including dependency and security monitoring, pinning Actions, strict access control, verified creator practices, secret scanning tools, raising awareness, and training. In doing so, we provide valuable insights on the need to integrate security seamlessly into the automated collaborative software development processes. To enhance the security of workflow automation within {GitHub} repositories we encourage a proactive approach and advocate for the adoption of best practices.},
	pages = {6--11},
	booktitle = {Proceedings of the 2024 {ACM}/{IEEE} 4th International Workshop on Engineering and Cybersecurity of Critical Systems ({EnCyCriS}) and 2024 {IEEE}/{ACM} Second International Workshop on Software Vulnerability},
	publisher = {Association for Computing Machinery},
	author = {Delicheh, Hassan Onsori and Mens, Tom},
	urldate = {2025-07-21},
	date = {2024-08-26},
}

@article{noauthor_httpswwwijirmpsorgresearch-paperphpid232448_nodate,
	title = {https://www.ijirmps.org/research-paper.php?id=232448},
	volume = {13},
	rights = {Creative Commons Attribution-{ShareAlike} 4.0 International License},
	issn = {2349-7300},
	url = {https://www.ijirmps.org/research-paper.php?id=232448},
	shorttitle = {https},
	number = {4},
	journaltitle = {{IJIRMPS} - International Journal of Innovative Research in Engineering \& Multidisciplinary Physical Sciences},
	urldate = {2025-08-03},
	note = {Publisher: Advanced Research Publication and Journals},
}

@article{fu_ai_2025,
  author  = {Fu, Michael and Pasuksmit, Jirat and Tantithamthavorn, Chakkrit},
  title   = {{AI for DevSecOps: A Landscape and Future Opportunities}},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  year    = {2025},
  month   = {May},
  volume  = {34},
  number  = {4},
  pages   = {1--61},
  doi     = {10.1145/3712190}
}

@inproceedings{gunathilaka_context-aware_2025-1,
	title = {Context-Aware Behavior-Driven Pipeline Generation},
	url = {https://ieeexplore.ieee.org/document/11011952},
	doi = {10.1109/ISDFS65363.2025.11011952},
	abstract = {An efficient {CI}/{CD} process is crucial for modern software teams, but manual pipeline creation is error-prone and requires high {DevOps} expertise, slowing deployment speed and reducing productivity. This research introduces a context-aware, behavior-driven approach to fully automating {CI}/{CD} pipeline generation by analyzing {GitHub} user activity patterns. The proposed solution utilizes a historical analysis of repository events, developer contributions, and workload distribution to dynamically generate pipelines and assign reviewers to pull requests based on expertise. Unlike previous template-based and generative {AI} solutions that require manual intervention, our approach leverages pattern recognition and adaptive decision-making to continuously refine automation. This paper presents the methodology behind data collection, analysis, and pipeline generation, demonstrating its effectiveness in reducing human effort while improving software delivery efficiency. This research highlights how behavior-driven automation streamlines the complexity of {CI}/{CD} pipeline creation, enabling more adaptive and intelligent systems that effectively respond to the evolving needs of software development teams.},
	eventtitle = {2025 13th International Symposium on Digital Forensics and Security ({ISDFS})},
	pages = {1--6},
	booktitle = {2025 13th International Symposium on Digital Forensics and Security ({ISDFS})},
	author = {Gunathilaka, Pawara and Senadheera, Dinal and Perara, Shenan and Gunawardana, Chamithu and Thelijjagoda, Samantha and Krishara, Jenny},
	urldate = {2025-08-03},
	date = {2025-04},
	note = {{ISSN}: 2768-1831},
	keywords = {Security, Adaptive systems, Automation, Reviews, behavior-driven development, {CI}/{CD}, context-aware, {DevOps}, {GitHub} activity analysis, Intelligent systems, Manuals, Pipelines, reviewer assignment, Software, Testing, workload optimization},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/9CYRQFU7/11011952.html:text/html},
}

@misc{mahboob_future_2024,
	title = {Future of Artificial Intelligence in Agile Software Development},
	url = {http://arxiv.org/abs/2408.00703},
	doi = {10.48550/arXiv.2408.00703},
	abstract = {The advent of Artificial intelligence has promising advantages that can be utilized to transform the landscape of software project development. The Software process framework consists of activities that constantly require routine human interaction, leading to the possibility of errors and uncertainties. {AI} can assist software development managers, software testers, and other team members by leveraging {LLMs}, {GenAI} models, and {AI} agents to perform routine tasks, risk analysis and prediction, strategy recommendations, and support decision making. {AI} has the potential to increase efficiency and reduce the risks encountered by the project management team while increasing the project success rates. Additionally, it can also break down complex notions and development processes for stakeholders to make informed decisions. In this paper, we propose an approach in which {AI} tools and technologies can be utilized to bestow maximum assistance for agile software projects, which have become increasingly favored in the industry in recent years.},
	number = {{arXiv}:2408.00703},
	publisher = {{arXiv}},
	author = {Mahboob, Mariyam and Ahmed, Mohammed Rayyan Uddin and Zia, Zoiba and Ali, Mariam Shakeel and Ahmed, Ayman Khaleel},
	urldate = {2025-08-03},
	date = {2024-08-01},
	eprinttype = {arxiv},
	eprint = {2408.00703 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Software Engineering},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/BZXFLC2A/Mahboob et al. - 2024 - Future of Artificial Intelligence in Agile Software Development.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/ZQ56VVSL/2408.html:text/html},
}

@article{fu_ai_2025-1,
	title = {{AI} for {DevSecOps}: A Landscape and Future Opportunities},
	volume = {34},
	issn = {1049-331X, 1557-7392},
	url = {https://dl.acm.org/doi/10.1145/3712190},
	doi = {10.1145/3712190},
	shorttitle = {{AI} for {DevSecOps}},
	abstract = {{MICHAEL} {FU}, Monash University, Australia {JIRAT} {PASUKSMIT}, Atlassian, Australia {CHAKKRIT} {TANTITHAMTHAVORN}, Monash University, Australia {DevOps} has emerged as one of the most rapidly evolving software development paradigms. With the growing concerns surrounding security in software systems, the {DevSecOps} paradigm has gained prominence, urging practitioners to incorporate security practices seamlessly into the {DevOps} workflow. However, integrating security into the {DevOps} workflow can impact agility and impede delivery speed. Recently, the advancement of artificial intelligence ({AI}) has revolutionized automation in various software domains, including software security. {AI}-driven security approaches, particularly those leveraging machine learning or deep learning, hold promise in automating security workflows. They reduce manual efforts, which can be integrated into {DevOps} to ensure uninterrupted delivery speed and align with the {DevSecOps} paradigm simultaneously. This paper seeks to contribute to the critical intersection of {AI} and {DevSecOps} by presenting a comprehensive landscape of {AI}-driven security techniques applicable to {DevOps} and identifying avenues for enhancing security, trust, and efficiency in software development processes. We analyzed 99 research papers spanning from 2017 to 2023. Specifically, we address two key research questions ({RQs}). In {RQ}1, we identified 12 security tasks associated with the {DevSecOps} process and reviewed existing {AI}-driven security approaches, the problems they addressed, and the 65 benchmarks used to evaluate those approaches. Drawing insights from our findings, in {RQ}2, we discussed state-of-the-art {AI}-driven security approaches, highlighted 15 challenges in existing research, and proposed 15 corresponding avenues for future opportunities. {CCS} Concepts: • Software and its engineering → Software development techniques; • Security and privacy → Software security engineering; • Computing methodologies → Artificial intelligence.},
	pages = {1--61},
	number = {4},
	journaltitle = {{ACM} Trans. Softw. Eng. Methodol.},
	author = {Fu, Michael and Pasuksmit, Jirat and Tantithamthavorn, Chakkrit},
	urldate = {2025-08-03},
	date = {2025-05-31},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/5SJH27Z2/Fu et al. - 2025 - AI for DevSecOps A Landscape and Future Opportunities.pdf:application/pdf},
}

@misc{peng_impact_2023,
	title = {The Impact of {AI} on Developer Productivity: Evidence from {GitHub} Copilot},
	url = {http://arxiv.org/abs/2302.06590},
	doi = {10.48550/arXiv.2302.06590},
	shorttitle = {The Impact of {AI} on Developer Productivity},
	abstract = {Generative {AI} tools hold promise to increase human productivity. This paper presents results from a controlled experiment with {GitHub} Copilot, an {AI} pair programmer. Recruited software developers were asked to implement an {HTTP} server in {JavaScript} as quickly as possible. The treatment group, with access to the {AI} pair programmer, completed the task 55.8\% faster than the control group. Observed heterogenous effects show promise for {AI} pair programmers to help people transition into software development careers.},
	number = {{arXiv}:2302.06590},
	publisher = {{arXiv}},
	author = {Peng, Sida and Kalliamvakou, Eirini and Cihon, Peter and Demirer, Mert},
	urldate = {2025-08-03},
	date = {2023-02-13},
	eprinttype = {arxiv},
	eprint = {2302.06590 [cs]},
	keywords = {Computer Science - Software Engineering},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/4VMJB9UR/Peng et al. - 2023 - The Impact of AI on Developer Productivity Evidence from GitHub Copilot.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/F2TXJWKA/2302.html:text/html},
}

@article{kesireddy_copilot_2025,
	title = {Copilot in the Cloud: Evaluating the Accuracy and Speed of {LLMs} in Data Engineering Tasks},
	volume = {15},
	rights = {Copyrights to World Journal of Advanced Engineering Technology and Sciences},
	issn = {2582-8266},
	url = {https://journalwjaets.com/content/copilot-cloud-evaluating-accuracy-and-speed-llms-data-engineering-tasks},
	doi = {10.30574/wjaets.2025.15.3.1049},
	shorttitle = {Copilot in the Cloud},
	abstract = {The integration of large language models ({LLMs}) into enterprise workflows has opened new frontiers in cloud data engineering. This article presents a comprehensive evaluation of {AI} copilots in the development of scalable data pipelines across regulated environments. The article benchmarks {LLMs} on key engineering tasks including pipeline scaffolding, {SQL} optimization, {IAM} policy generation, and compliance rule encoding, providing insights into their capabilities and limitations in specialized technical contexts. It measures improvements in developer velocity, reduction in syntax errors, and overall impact on quality assurance cycles. Beyond automation, the article assesses how {LLMs} learn and generalize patterns from metadata-driven frameworks—making intelligent suggestions aligned with domain rules and architectural best practices. Special attention is given to the risks of hallucination, governance gaps, and security considerations that organizations must actively manage. It contributes to a deeper understanding of human-{AI} pair programming in high-stakes data systems, offering a framework for safely scaling {AI}-augmented development across data teams while preserving auditability, trust, and compliance.},
	pages = {1434--1441},
	number = {3},
	journaltitle = {World Journal of Advanced Engineering Technology and Sciences},
	author = {Kesireddy, Sunny},
	urldate = {2025-08-03},
	date = {2025},
	langid = {english},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/YY49TZ2L/copilot-cloud-evaluating-accuracy-and-speed-llms-data-engineering-tasks.html:text/html},
}

@misc{rein_hcast_2025,
	title = {{HCAST}: Human-Calibrated Autonomy Software Tasks},
	url = {http://arxiv.org/abs/2503.17354},
	doi = {10.48550/arXiv.2503.17354},
	shorttitle = {{HCAST}},
	abstract = {To understand and predict the societal impacts of highly autonomous {AI} systems, we need benchmarks with grounding, i.e., metrics that directly connect {AI} performance to real-world effects we care about. We present {HCAST} (Human-Calibrated Autonomy Software Tasks), a benchmark of 189 machine learning engineering, cybersecurity, software engineering, and general reasoning tasks. We collect 563 human baselines (totaling over 1500 hours) from people skilled in these domains, working under identical conditions as {AI} agents, which lets us estimate that {HCAST} tasks take humans between one minute and 8+ hours. Measuring the time tasks take for humans provides an intuitive metric for evaluating {AI} capabilities, helping answer the question "can an agent be trusted to complete a task that would take a human X hours?" We evaluate the success rates of {AI} agents built on frontier foundation models, and we find that current agents succeed 70-80\% of the time on tasks that take humans less than one hour, and less than 20\% of the time on tasks that take humans more than 4 hours.},
	number = {{arXiv}:2503.17354},
	publisher = {{arXiv}},
	author = {Rein, David and Becker, Joel and Deng, Amy and Nix, Seraphina and Canal, Chris and O'Connel, Daniel and Arnott, Pip and Bloom, Ryan and Broadley, Thomas and Garcia, Katharyn and Goodrich, Brian and Hasin, Max and Jawhar, Sami and Kinniment, Megan and Kwa, Thomas and Lajko, Aron and Rush, Nate and Sato, Lucas Jun Koba and Arx, Sydney Von and West, Ben and Chan, Lawrence and Barnes, Elizabeth},
	urldate = {2025-08-03},
	date = {2025-03-21},
	eprinttype = {arxiv},
	eprint = {2503.17354 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/ET4T7XFU/Rein et al. - 2025 - HCAST Human-Calibrated Autonomy Software Tasks.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/7JJZL9VW/2503.html:text/html},
}

@misc{tufano_autodev_2024,
	title = {{AutoDev}: Automated {AI}-Driven Development},
	url = {http://arxiv.org/abs/2403.08299},
	doi = {10.48550/arXiv.2403.08299},
	shorttitle = {{AutoDev}},
	abstract = {The landscape of software development has witnessed a paradigm shift with the advent of {AI}-powered assistants, exemplified by {GitHub} Copilot. However, existing solutions are not leveraging all the potential capabilities available in an {IDE} such as building, testing, executing code, git operations, etc. Therefore, they are constrained by their limited capabilities, primarily focusing on suggesting code snippets and file manipulation within a chat-based interface. To fill this gap, we present {AutoDev}, a fully automated {AI}-driven software development framework, designed for autonomous planning and execution of intricate software engineering tasks. {AutoDev} enables users to define complex software engineering objectives, which are assigned to {AutoDev}'s autonomous {AI} Agents to achieve. These {AI} agents can perform diverse operations on a codebase, including file editing, retrieval, build processes, execution, testing, and git operations. They also have access to files, compiler output, build and testing logs, static analysis tools, and more. This enables the {AI} Agents to execute tasks in a fully automated manner with a comprehensive understanding of the contextual information required. Furthermore, {AutoDev} establishes a secure development environment by confining all operations within Docker containers. This framework incorporates guardrails to ensure user privacy and file security, allowing users to define specific permitted or restricted commands and operations within {AutoDev}. In our evaluation, we tested {AutoDev} on the {HumanEval} dataset, obtaining promising results with 91.5\% and 87.8\% of Pass@1 for code generation and test generation respectively, demonstrating its effectiveness in automating software engineering tasks while maintaining a secure and user-controlled development environment.},
	number = {{arXiv}:2403.08299},
	publisher = {{arXiv}},
	author = {Tufano, Michele and Agarwal, Anisha and Jang, Jinu and Moghaddam, Roshanak Zilouchian and Sundaresan, Neel},
	urldate = {2025-08-03},
	date = {2024-03-13},
	eprinttype = {arxiv},
	eprint = {2403.08299 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Software Engineering},
	file = {Full Text PDF:/Users/d.veragilliard/Zotero/storage/3QMLZLGV/Tufano et al. - 2024 - AutoDev Automated AI-Driven Development.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/EQQM8ZYK/2403.html:text/html},
}

@inproceedings{seth_ai_2025-1,
	title = {{AI} and Generative {AI}-Driven Automation for Multi-Cloud and Hybrid Cloud Architectures: Enhancing Security, Performance, and Operational Efficiency},
	url = {https://ieeexplore.ieee.org/document/10903928},
	doi = {10.1109/CCWC62904.2025.10903928},
	shorttitle = {{AI} and Generative {AI}-Driven Automation for Multi-Cloud and Hybrid Cloud Architectures},
	abstract = {The emergence of cloud and hybrid cloud structures presents {eCommerce} firms with the adaptability and robustness needed to manage expansion and varying user requirements effectively. However, this also brings about challenges concerning security enhancements, distribution of workloads, and cost-effectiveness optimization. Traditional cloud management models often need help to meet these evolving demands efficiently. This research presents a system that leverages Artificial Intelligence ({AI}) and Generative {AI} (Gen {AI}) to effectively automate and enhance cloud and hybrid infrastructures for ecommerce websites. The system adapts infrastructure to traffic times like holidays or sales events by utilizing {AI} to scale resources as needed. It conserves resources during low user activity periods such as overnight. Ensuring optimal system performance and availability during peak traffic times while cutting costs during traffic periods is essential for cost-effectiveness and efficient resource management. In addition, {AI}-powered security automation safeguards against changing cyber dangers, and compliance automation guarantees conformity with rules like {PCI} {DSS} for payment handling. This report also delves into merging Gen {AI} into cloud coordination systems, facilitating workflows, and enhancing {eCommerce} processes. The outcome is a significant drop in operational expenses, a quicker service rollout, and decreased security breaches. Through real-world {eCommerce} case studies, this paper provides actionable insights for cloud engineers and architects on leveraging {AI}-driven cloud management to enhance performance, security, and cost-efficiency in multi-cloud and hybrid environments, ensuring seamless user experiences and business continuity.},
	eventtitle = {2025 {IEEE} 15th Annual Computing and Communication Workshop and Conference ({CCWC})},
	pages = {00784--00793},
	booktitle = {2025 {IEEE} 15th Annual Computing and Communication Workshop and Conference ({CCWC})},
	author = {Seth, Dhruv Kumar and Ratra, Karan Kumar and Sundareswaran, Aneeshkumar P},
	urldate = {2025-08-17},
	date = {2025-01},
	keywords = {Cloud computing, Generative {AI}, Security, Technological innovation, Robustness, Automation, {AI}-based cloud management, {AI}-driven automation, Cloud orchestration, Cloud performance monitoring, Cloud scalability, Cloud security, Cloud security automation, Electronic commerce, Hybrid cloud, Hybrid power systems, Infrastructure automation, Machine learning in cloud, Multi-cloud architecture, Operational efficiency, Optimization, Performance optimization, Resource allocation optimization Introduction, System performance},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/ETLIZD4J/10903928.html:text/html},
}

@report{tabassi_artificial_2023-1,
	location = {Gaithersburg, {MD}},
	title = {Artificial Intelligence Risk Management Framework ({AI} {RMF} 1.0)},
	url = {http://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf},
	abstract = {As directed by the National Artificial Intelligence Initiative Act of 2020 (P.L. 116-283), the goal of the {AI} {RMF} is to offer a resource to the organizations designing, developing, deploying, or using {AI} systems to help manage the many risks of {AI} and promote trustworthy and responsible development and use of {AI} systems. The Framework is intended to be voluntary, rights-preserving, non-sector specific, and use-case agnostic, providing flexibility to organizations of all sizes and in all sectors and throughout society to implement the approaches in the Framework.   The {AI} {RMF} is intended to be practical, to adapt to the {AI} landscape as {AI} technologies continue to develop, and to be operationalized by organizations in varying degrees and capacities so society can benefit from {AI} while also being protected from its potential harms.},
	pages = {NIST AI 100--1},
	number = {{NIST} {AI} 100-1},
	institution = {National Institute of Standards and Technology (U.S.)},
	author = {Tabassi, Elham},
	urldate = {2025-08-17},
	date = {2023-01-26},
	langid = {english},
	doi = {10.6028/NIST.AI.100-1},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/3BC369Z3/Tabassi - 2023 - Artificial Intelligence Risk Management Framework (AI RMF 1.0).pdf:application/pdf},
}

@inproceedings{bringhenti_security_2023-1,
	title = {Security automation for multi-cluster orchestration in Kubernetes},
	url = {https://ieeexplore.ieee.org/document/10175419},
	doi = {10.1109/NetSoft57336.2023.10175419},
	abstract = {In the latest years, multi-domain Kubernetes architectures composed of multiple clusters have been getting more frequent, so as to provide higher workload isolation, resource availability flexibility and scalability for application deployment. However, manually configuring their security may lead to inconsistencies among policies defined in different clusters, or it may require knowledge that the administrator of each domain cannot have. Therefore, this paper proposes an automatic approach for the automatic generation of the network security policies to be deployed in each cluster of a multi-domain Kubernetes deployment. The objectives of this approach are to reduce of configuration errors that human administrators commonly make, and to create transparent cross-cluster communications. This approach has been implemented as a framework named Multi-Cluster Orchestrator, which has been validated in realistic use cases to assess its benefits to Kubernetes orchestration.},
	eventtitle = {2023 {IEEE} 9th International Conference on Network Softwarization ({NetSoft})},
	pages = {480--485},
	booktitle = {2023 {IEEE} 9th International Conference on Network Softwarization ({NetSoft})},
	author = {Bringhenti, Daniele and Sisto, Riccardo and Valenza, Fulvio},
	urldate = {2025-08-17},
	date = {2023-06},
	note = {{ISSN}: 2693-9789},
	keywords = {Network security, Scalability, Automation, cloud orchestration, Kubernetes, security automation},
	file = {Snapshot:/Users/d.veragilliard/Zotero/storage/E53YFVUZ/10175419.html:text/html},
}

@inproceedings{surathunmanun_exploring_2024-1,
	title = {Exploring the Role of Generative Artificial Intelligence in the Energy Sector: A Comprehensive Literature Review},
	url = {https://ieeexplore.ieee.org/document/10795598},
	doi = {10.1109/ICUE63019.2024.10795598},
	shorttitle = {Exploring the Role of Generative Artificial Intelligence in the Energy Sector},
	abstract = {Generative Artificial Intelligence ({GenAI}) enhances productivity by creating data, forecasting, optimizing, and understanding human language. In the energy sector, it is projected to have a \$240 billion global economic impact, though research remains limited. This paper reviews {GenAI}'s benefits, challenges, and research gaps in the energy sector, also focusing on climate change efforts. A {PRISMA}-{SCR}-based literature review from January 2022 to May 2024 was conducted using {IEEE} Xplore, {ScienceDirect}, {ACM} Digital Library, and Google Scholar. {GenAI} tools extracted data, verified by researchers. Analysis of 33 papers shows {GenAI} excels in knowledge integration and prediction. It generates synthetic electricity demand data, manages grids, forecasts energy demand, and optimizes renewable energy systems. Key challenges include hallucinations, data biases, privacy concerns, misuse, and system errors. Solutions involve improving training data, system fine-tuning, human oversight, and security measures. Research gaps include synthetic data realism, model evaluation standards, and integrating {GenAI} with blockchain and {IoT}.},
	eventtitle = {2024 International Conference on Sustainable Energy: Energy Transition and Net-Zero Climate Future ({ICUE})},
	pages = {1--11},
	booktitle = {2024 International Conference on Sustainable Energy: Energy Transition and Net-Zero Climate Future ({ICUE})},
	author = {Surathunmanun, Surasak and Ongsakul, Weerakorn and Singh, Jai Govind},
	urldate = {2025-08-17},
	date = {2024-10},
	keywords = {Generative Artificial Intelligence, Artificial intelligence, Ethics, Accuracy, Synthetic data, Bibliographies, Carbon, Climate change, Climate Change, Energy, Energy Sector, Forecasting, {GenAI}, Renewable energy sources, Sustainable development},
}

@online{noauthor_cyber_nodate-1,
	title = {Cyber Security Risks in the Rapid Development of Generative Artificial Intelligence: A Systematic Literature Review {\textbar} {ComniTech} : Journal of Computational Intelligence and Informatics},
	url = {https://journal.unilak.ac.id/index.php/ComniTech/article/view/24539},
	urldate = {2025-08-17},
	file = {Cyber Security Risks in the Rapid Development of Generative Artificial Intelligence\: A Systematic Literature Review | ComniTech \: Journal of Computational Intelligence and Informatics:/Users/d.veragilliard/Zotero/storage/4SHFB76H/24539.html:text/html},
}

@online{noauthor_pdf_nodate-2,
	title = {({PDF}) Zero-Trust Architecture ({ZTA}): Designing an {AI}-Powered Cloud Security Framework for {LLMs}' Black Box Problems},
	url = {https://www.researchgate.net/publication/379044053_Zero-Trust_Architecture_ZTA_Designing_an_AI-Powered_Cloud_Security_Framework_for_LLMs'_Black_Box_Problems},
	shorttitle = {({PDF}) Zero-Trust Architecture ({ZTA})},
	abstract = {{PDF} {\textbar} Businesses are becoming more interested in developing and testing Large Language Models ({LLMs}) in their own settings to support decision-making... {\textbar} Find, read and cite all the research you need on {ResearchGate}},
	titleaddon = {{ResearchGate}},
	urldate = {2025-08-17},
	langid = {english},
	doi = {10.54026/CTES/1058},
	file = {Full Text:/Users/d.veragilliard/Zotero/storage/V9V3JKHK/(PDF) Zero-Trust Architecture (ZTA) Designing an AI-Powered Cloud Security Framework for LLMs' Blac.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/VTX3IDYU/379044053_Zero-Trust_Architecture_ZTA_Designing_an_AI-Powered_Cloud_Security_Framework_for_LLMs.html:text/html},
}

@misc{fu_ai_2024,
	title = {{AI} for {DevSecOps}: A Landscape and Future Opportunities},
	url = {http://arxiv.org/abs/2404.04839},
	doi = {10.48550/arXiv.2404.04839},
	shorttitle = {{AI} for {DevSecOps}},
	abstract = {{DevOps} has emerged as one of the most rapidly evolving software development paradigms. With the growing concerns surrounding security in software systems, the {DevSecOps} paradigm has gained prominence, urging practitioners to incorporate security practices seamlessly into the {DevOps} workflow. However, integrating security into the {DevOps} workflow can impact agility and impede delivery speed. Recently, the advancement of artificial intelligence ({AI}) has revolutionized automation in various software domains, including software security. {AI}-driven security approaches, particularly those leveraging machine learning or deep learning, hold promise in automating security workflows. They reduce manual efforts, which can be integrated into {DevOps} to ensure uninterrupted delivery speed and align with the {DevSecOps} paradigm simultaneously. This paper seeks to contribute to the critical intersection of {AI} and {DevSecOps} by presenting a comprehensive landscape of {AI}-driven security techniques applicable to {DevOps} and identifying avenues for enhancing security, trust, and efficiency in software development processes. We analyzed 99 research papers spanning from 2017 to 2023. Specifically, we address two key research questions ({RQs}). In {RQ}1, we identified 12 security tasks associated with the {DevSecOps} process and reviewed existing {AI}-driven security approaches, the problems they addressed, and the 65 benchmarks used to evaluate those approaches. Drawing insights from our findings, in {RQ}2, we discussed state-of-the-art {AI}-driven security approaches, highlighted 15 challenges in existing research, and proposed 15 corresponding avenues for future opportunities.},
	number = {{arXiv}:2404.04839},
	publisher = {{arXiv}},
	author = {Fu, Michael and Pasuksmit, Jirat and Tantithamthavorn, Chakkrit},
	urldate = {2025-08-17},
	date = {2024-09-13},
	eprinttype = {arxiv},
	eprint = {2404.04839 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Software Engineering},
	file = {Preprint PDF:/Users/d.veragilliard/Zotero/storage/HZ4YC6EX/Fu et al. - 2024 - AI for DevSecOps A Landscape and Future Opportunities.pdf:application/pdf;Snapshot:/Users/d.veragilliard/Zotero/storage/2WBT77LL/2404.html:text/html},
}

@incollection{nicosia_6_2024,
  author    = {Nicosia, Max and Kristensson, Per Ola},
  title     = {{Risk Management in Human-in-the-Loop AI-Assisted Attention Aware Systems}},
  booktitle = {Putting AI in the Critical Loop},
  publisher = {Academic Press},
  year      = {2024},
  editor    = {Dasgupta, Prithviraj and Llinas, James and Gillespie, Tony and Fouse, Scott and Lawless, William and Mittu, Ranjeev and Sofge, Donald},
  pages     = {81--92},
  chapter   = {6},
  doi       = {10.1016/B978-0-443-15988-6.00013-3}
}

@article{n_koritala_cloud-first_2025,
	title = {Cloud-First Strategies for Financial Data Storage and Processing},
	volume = {7},
	issn = {23955252},
	url = {https://ijaem.net/issue_dcp/Cloud%20First%20Strategies%20for%20Financial%20Data%20Storage%20and%20Processing.pdf},
	doi = {10.35629/5252-0702789799},
	abstract = {The aim of this research paper is to examine cloudfirst approach as a strategy used in storing and processing of financial data with special emphasis on secondary data analysis of risks encompassed, benefits inherent and market trends. The study also includes the historical timeline of cloud adoption, a risk register that outlines the main risks that are bound to affect cloud adoption and their possible solutions, as well as a market share analysis. The study proves that financial organizations have rapidly shifted to utilizing cloud solutions as they served to be cheaper and more flexible than onpremises solutions. The risk register describes a number of risks such as data security, compliance, operational risks etc which matters much for data encryption and multi-cloud, following new regulations. Market share analysis shows that the provider market consists of big players including {AWS}, Microsoft Azure, Google Cloud and therefore highlights the problem of vendor lock in and proper selection to ensure that the chosen provider supports a company’s strategy appropriately. The research reveals that despite significant change in prospects carried by cloudfirst approaches for financial businesses, the key to effectively levering them is in managing the risks inherent with these infrastructure shifts; this applies the identification of risks and adherence to the best practices to be employed in mitigation. With the help of enhanced tools and constant training, the organizations can build the necessary levels of organizational resilience, remain loyal to customers and become strong competitors in the changing environment. Such insights are useful for client organisations especially those considering or those that are thinking of extending their use of the cloud for managing financial information.},
	pages = {789--799},
	number = {2},
	journaltitle = {{IJAEM}},
	author = {N. Koritala, Surendra},
	urldate = {2025-08-17},
	date = {2025-02},
	langid = {english},
	file = {PDF:/Users/d.veragilliard/Zotero/storage/5BWLU8QD/N. Koritala - 2025 - Cloud-First Strategies for Financial Data Storage and Processing.pdf:application/pdf},
}

@online{noauthor_european_nodate,
	title = {European Cloud Providers’ Local Market Share Now Holds Steady at 15\% {\textbar} Synergy Research Group},
	url = {https://www.srgresearch.com/articles/european-cloud-providers-local-market-share-now-holds-steady-at-15},
	urldate = {2025-08-17},
	file = {European Cloud Providers’ Local Market Share Now Holds Steady at 15% | Synergy Research Group:/Users/d.veragilliard/Zotero/storage/FQTMV4HI/european-cloud-providers-local-market-share-now-holds-steady-at-15.html:text/html},
}

@article{patel_comparative_nodate,
  author    = {Patel, Abdul Rashid and Tiwari, Rashmi Vibhav and Khureshi, Rukhsar Afreen},
  title     = {{Comparative Study of Top Cloud Providers on Basis of Service Availability and Cost}},
  journal   = {Int. J. Innov. Res. Comput. Sci. Technol. (IJIRCST)},
  year      = {2022},
  volume    = {10},
  number    = {3},
  pages     = {1--5},
  month     = {May-Jun.}
}

@book{gamma_design_2011,
	location = {Boston, Mass. Munich},
	title = {Design Patterns. Elements of Reusable Object-Oriented Software.},
	isbn = {978-0-201-63361-0},
	abstract = {Capturing a wealth of experience about the design of object-oriented software, four top-notch designers present a catalog of simple and succinct solutions to commonly occurring design problems. Previously undocumented, these 23 patterns allow designers to create more flexible, elegant, and ultimately reusable designs without having to rediscover the design solutions themselves.  The authors begin by describing what patterns are and how they can help you design object-oriented software. They then go on to systematically name, explain, evaluate, and catalog recurring designs in object-oriented systems. With Design Patterns as your guide, you will learn how these important patterns fit into the software development process, and how you can leverage them to solve your own design problems most efficiently. Each pattern describes the circumstances in which it is applicable, when it can be applied in view of other design constraints, and the consequences and trade-offs of using the pattern within a larger design. All patterns are compiled from real systems and are based on real-world examples. Each pattern also includes code that demonstrates how it may be implemented in object-oriented programming languages like C++ or Smalltalk.},
	pagetotal = {416},
	publisher = {Prentice Hall},
	author = {Gamma, Erich and Helm, Richard and Johnson, Ralph and Vlissides, John},
	date = {2011},
}

@inproceedings{vaidya_devsecops_2024,
	title = {{DevSecOps} Automation: A Comprehensive Review of {AI} Integration and Future Directions},
	url = {https://ieeexplore.ieee.org/document/10586919},
	doi = {10.1109/ICRITO59692.2024.10586919},
	abstract = {This paper provides a comprehensive review of integrating artificial intelligence ({AI}) into {DevSecOps} to automate and enhance security throughout the software development lifecycle. We analyze current {AI}-driven tools and methodologies, assess their impact on efficiency and security, and identify key challenges. Our findings indicate that {AI} significantly improves threat detection and response times, although challenges in model accuracy and integration complexity persist. We conclude by outlining future research directions to advance {AI} in {DevSecOps}.},
	booktitle = {2024 12th International Conference on Reliability, Infocom Technologies and Optimization ({ICRITO})},
	author = {Vaidya, R. and Sharma, G.},
	urldate = {2025-09-08},
	date = {2024-06-05},
	keywords = {Artificial Intelligence, Automation, {CI}/{CD}, Cybersecurity, {DevSecOps}},
}

@article{li_automated_2024,
	title = {Automated Policy Generation for Cloud Infrastructure using Large Language Models},
	volume = {12},
	issn = {2168-7161},
	url = {https://www.computer.org/csdl/journal/cc/2024/03/10402123/1I9Z0zE8aBc},
	doi = {10.1109/MCC.2024.3398416},
	abstract = {Large language models ({LLMs}) are transforming security automation for cloud infrastructure. This study presents a framework for automatically generating security policies from infrastructure-as-code artifacts. We evaluated its performance within a simulated {CI}/{CD} pipeline, measuring policy generation latency and accuracy. The results show that {LLM}-based generation is sufficiently fast for real-time feedback loops, with a mean generation time of 8.2 seconds. This approach significantly reduces manual effort and accelerates remediation cycles.},
	pages = {45--54},
	number = {3},
	journaltitle = {{IEEE} Cloud Computing},
	author = {Li, Q. and Zhang, Y. and Chen, W.},
	urldate = {2025-09-08},
	date = {2024-05-15},
	keywords = {{CI}/{CD}, Cloud Security, {IaC}, Large Language Models, Policy Generation},
}

@online{boyter_scc_2024,
  author  = {Boyter, Ben},
  title   = {{scc: Sloc, Cloc and Code}},
  year    = {2024},
  url     = {https://github.com/boyter/scc},
  note    = {GitHub repository}
}

@misc{howard_terraform_2022,
  author     = {Howard, Michael},
  title      = {{Terraform -- Automating Infrastructure as a Service}},
  year       = {2022},
  eprinttype = {arXiv},
  eprint     = {2205.10676},
  doi        = {10.48550/arXiv.2205.10676}
}

@online{noauthor_claude_nodate-1,
	title = {Claude on Amazon Bedrock},
	url = {https://docs.anthropic.com/en/docs/claude-on-amazon-bedrock},
	abstract = {Learn about configuring Claude through Amazon Bedrock, including setup, {IAM} configuration, and troubleshooting.},
	urldate = {2025-07-16},
}

@online{noauthor_introduction_nodate-2,
	title = {Introduction {\textbackslash}textbar Open Policy Agent},
	url = {https://openpolicyagent.org/docs},
	abstract = {The Open Policy Agent ({OPA}, pronounced "oh-pa") is an open source, general-purpose policy engine.},
	urldate = {2025-07-16},
}

@inproceedings{li_iris_2025-1,
	title = {{IRIS}: {LLM}-Assisted Static Analysis for Detecting Security Vulnerabilities},
	url = {http://arxiv.org/abs/2405.17238},
	doi = {10.48550/arXiv.2405.17238},
	shorttitle = {{IRIS}},
	abstract = {We propose {IRIS}, a neuro-symbolic approach that systematically combines {LLMs} with static analysis to perform whole-repository reasoning for security vulnerability detection. Specifically, {IRIS} leverages {LLMs} to infer taint specifications and perform contextual analysis, alleviating needs for human specifications and inspection.},
	publisher = {{arXiv}},
	author = {Li, Ziyang and Dutta, Saikat and Naik, Mayur},
	urldate = {2025-06-18},
	date = {2025-04-06},
	note = {Issue: {arXiv}:2405.17238},
}

@online{noauthor_pytest_nodate-1,
	title = {pytest documentation},
	url = {https://docs.pytest.org/en/stable/},
	urldate = {2025-07-20},
}

@misc{ronacher_click_2024,
	title = {Click: Command Line Interface Creation Kit},
	url = {https://click.palletsprojects.com/},
	publisher = {Pallets},
	author = {Ronacher, Armin and team, the Pallets},
	date = {2024},
}

@inproceedings{zheng_context-aware_2023,
	location = {New York, {NY}, {USA}},
	title = {Context-Aware Vulnerability Detection in Infrastructure-as-Code},
	doi = {10.1145/3576915.3576987},
	pages = {1123--1137},
	booktitle = {Proceedings of the 2023 {ACM} {SIGSAC} Conference on Computer and Communications Security ({CCS} '23)},
	publisher = {Association for Computing Machinery},
	author = {Zheng, Yilun and Liu, Yang},
	date = {2023},
}

@online{aqua_security_tfsec_nodate,
  author = {{Aqua Security}},
  title  = {{tfsec: Static analysis for Terraform code}},
  url    = {https://github.com/aquasecurity/tfsec}
}

@online{amplify_python-hcl2_2025,
  author = {{Amplify}},
  title  = {{python-hcl2}},
  year   = {2025},
  url    = {https://pypi.org/project/python-hcl2/},
  note   = {PyPI Repository}
}

@misc{anthropic_claude_2023,
	title = {Claude 2 on Amazon Bedrock},
	url = {https://www.anthropic.com/news/claude-2-amazon-bedrock},
	author = {{Anthropic}},
	date = {2023-08},
}

@misc{the_opa_authors_open_nodate,
	title = {Open Policy Agent Documentation},
	url = {https://www.openpolicyagent.org/docs/latest/},
	author = {{The OPA Authors}},
	note = {Published: Web page},
}

@misc{textualize_rich_nodate,
	title = {Rich: A Python library for rich text and beautiful formatting in the terminal},
	url = {https://github.com/Textualize/rich},
	author = {{Textualize}},
	note = {Published: Web page},
}

@article{leppanen_use_2025,
	title = {The use of flow and business-oriented metrics in {DevOps}},
	volume = {178},
	pages = {107593},
	journaltitle = {Information and Software Technology},
	author = {Leppänen, Matti and Mäkinen, Simo and Partanen, Juho and Mäntylä, Mika V},
	date = {2025},
	note = {Publisher: Elsevier},
}

@online{akto_shift_2025,
  author  = {{Akto}},
  title   = {{Shift Left in DevSecOps: Benefits \& Best Practices}},
  year    = {2025},
  month   = {Apr.},
  url     = {https://www.akto.io/learn/shift-left-devsecops}
}


@misc{esystems_how_2024,
	title = {How {AI} in {DevOps} Improves Productivity and Automation},
	url = {https://www.esystems.fi/en/blog/how-ai-in-devops-improves-productivity-and-automation},
	author = {{eSystems}},
	date = {2024-11},
}

@online{cloud_security_alliance_mitigating_2023,
  author  = {{Cloud Security Alliance}},
  title   = {{Mitigating Security Risks in Retrieval-Augmented Generation (RAG) LLM Applications}},
  year    = {2023},
  month   = {Nov.},
  url     = {https://cloudsecurityalliance.org/blog/2023/11/22/mitigating-security-risks-in-retrieval-augmented-generation-rag-llm-applications/}
}

@inproceedings{katz_verifying_2017,
	title = {The Verifying Compiler: A Grand Challenge for Computing Research},
	pages = {2--23},
	booktitle = {Proceedings of the 18th International Conference on Verification, Model Checking, and Abstract Interpretation ({VMCAI})},
	publisher = {Springer International Publishing},
	author = {Katz, Guy and Barrett, Clark and Dill, David L. and Kochenderfer, Mykel J. and Reynolds, Kyle},
	date = {2017},
}

@article{ouyang_training_2022,
	title = {Training language models to follow instructions with human feedback},
	volume = {35},
	pages = {27730--27744},
	journaltitle = {Advances in Neural Information Processing Systems ({NeurIPS})},
	author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
	date = {2022},
}

@article{lewis_retrieval-augmented_2020,
	title = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
	volume = {33},
	pages = {9459--9474},
	journaltitle = {Advances in Neural Information Processing Systems ({NeurIPS})},
	author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Küttler, Heinrich and Ott, Myle and Chen, Wen-tau and Smith, Eric and Stoyanov, Veselin and Zettlemoyer, Luke},
	date = {2020},
}

@article{gao_retrieval-augmented_2024,
	title = {Retrieval-Augmented Generation for Large Language Models: A Survey},
	journaltitle = {{arXiv} preprint {arXiv}:2312.10997},
	author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Meng and Han, Haofen},
	date = {2024},
}

@misc{reversinglabs_why_2024,
	title = {Why {GenAI} Fails at Full {SOC} Automation},
	url = {https://www.reversinglabs.com/blog/why-genai-fails-at-full-soc-automation},
	author = {{ReversingLabs}},
	date = {2024-05},
}

@article{mohsin_unified_2024,
	title = {A Unified Framework for Human-{AI} Collaboration in Security Operations Centers with Trusted Autonomy},
	journaltitle = {{arXiv} preprint {arXiv}:2505.23397},
	author = {Mohsin, Ahmad and Janicke, Helge and Ibrahim, Ahmed and Sarker, Iqbal H. and Camtepe, Seyit},
	date = {2024},
}

@misc{ibm_what_2025,
	title = {What Is Human In The Loop ({HITL})?},
	url = {https://www.ibm.com/think/topics/human-in-the-loop},
	author = {{IBM}},
	date = {2025-07},
	note = {Published: Web page},
}

@misc{spacelift_infrastructure_2025,
	title = {Infrastructure as Code ({IaC}) Security: 10 Best Practices},
	url = {https://spacelift.io/blog/infrastructure-as-code-iac-security},
	author = {{Spacelift}},
	date = {2025-09},
}

@article{yao_ecosaferag_2025,
	title = {{EcoSafeRAG}: Efficient Security through Context Analysis in Retrieval-Augmented Generation},
	journaltitle = {{arXiv} preprint {arXiv}:2505.13506},
	author = {Yao, Ruobing and Zhang, Yifei and Song, Shuang and Gao, Neng and Tu, Chenyang},
	date = {2025},
}

@misc{redis_llm_2025,
	title = {{LLM} Chunking: The Key to Better Retrieval, Lower Latency, and Higher Accuracy},
	url = {https://redis.io/blog/llm-chunking/},
	author = {{Redis}},
	date = {2025-06},
}

@article{pearce_deployability-centric_2025,
	title = {Deployability-Centric Infrastructure-as-Code Generation: An {LLM}-driven study with human feedback},
	journaltitle = {{arXiv} preprint {arXiv}:2506.05623},
	author = {Pearce, Hammond and authors, other},
	date = {2025},
}

@misc{zoomin_benefits_2024,
	title = {The Benefits and Mechanics of Semantic Search for {RAG}},
	url = {https://www.zoominsoftware.com/blog/the-benefits-and-mechanics-of-semantic-search-for-rag},
	author = {{Zoomin}},
	date = {2024-08},
}

@misc{openai_retrieval_2025,
	title = {Retrieval Augmented Generation ({RAG}) and Semantic Search for {GPTs}},
	url = {https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts},
	author = {{OpenAI}},
	date = {2025-09},
	note = {Published: Help Center},
}

@misc{doordash_best_nodate,
	title = {Best Practice of Retry Strategy},
	url = {https://developer.doordash.com/docs/drive/reference/retry_pattern},
	author = {{DoorDash}},
	note = {Published: Developer Documentation},
}

@misc{pinecone_chunking_2025,
	title = {Chunking Strategies for {LLM} Applications},
	url = {https://www.pinecone.io/learn/chunking-strategies/},
	author = {{Pinecone}},
	date = {2025-06},
	note = {Published: Learning Center},
}

@article{sahoo_systematic_2024,
	title = {A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications},
	journaltitle = {{arXiv} preprint {arXiv}:2402.07927},
	author = {Sahoo, Pranab and Singh, Ayush Kumar and Saha, Sriparna and Jain, Vinija and Mondal, Samrat and Chadha, Aman},
	date = {2024},
}

@article{hevner_design_2004,
	title = {Design science in information systems research},
	volume = {28},
	issn = {0276-7783},
	url = {https://www.jstor.org/stable/25148625},
	shorttitle = {Design science},
	pages = {75--105},
	number = {1},
	journaltitle = {{MIS} Quarterly},
	author = {Hevner, Alan R. and March, Salvatore T. and Park, Jinsoo and Ram, Sudha},
	date = {2004},
}

@article{peffers_design_2007,
	title = {A design science research methodology for information systems research},
	volume = {24},
	issn = {0742-1222},
	url = {https://www.jstor.org/stable/20159426},
	doi = {10.2753/MIS0742-1222240302},
	pages = {45--77},
	number = {3},
	journaltitle = {Journal of Management Information Systems},
	author = {Peffers, Ken and Tuunanen, Tuure and Rothenberger, Marcus A. and Chatterjee, Samir},
	date = {2007},
}

@article{page_prisma_2021-1,
	title = {The {PRISMA} 2020 statement: an updated guideline for reporting systematic reviews},
	volume = {372},
	issn = {1756-1833},
	doi = {10.1136/bmj.n71},
	pages = {n71},
	journaltitle = {{BMJ}},
	author = {Page, Matthew J. and {McKenzie}, Joanne E. and Bossuyt, Patrick M. and Boutron, Isabelle and Hoffmann, Tammy C. and Mulrow, Cynthia D. and Shamseer, Larissa and Tetzlaff, Jennifer M. and Akl, Elie A. and Brennan, Sue E. and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M. and Hróbjartsson, Asbjørn and Lalu, Manoj M. and Li, Tianjing and Loder, Elizabeth W. and Mayo-Wilson, Evan and {McDonald}, Steve and {McGuinness}, Luke A. and Stewart, Lesley A. and Thomas, James and Tricco, Andrea C. and Welch, Vivian A. and Whiting, Penny and Moher, David},
	date = {2021},
}

@report{mell_nist_2011,
	title = {The {NIST} Definition of Cloud Computing},
	url = {https://nvlpubs.nist.gov/nistpubs/legacy/sp/nistspecialpublication800-145.pdf},
	number = {{NIST} {SP} 800-145},
	institution = {National Institute of Standards and Technology},
	author = {Mell, Peter and Grance, Timothy},
	date = {2011},
}

@report{liu_nist_2011,
	title = {{NIST} Cloud Computing Reference Architecture},
	url = {https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication500-292.pdf},
	number = {{NIST} {SP} 500-292},
	institution = {National Institute of Standards and Technology},
	author = {Liu, Fang and Tong, Jin and Mao, Jian and Bohn, Robert and Messina, John and Badger, Lee and Leaf, Dawn},
	date = {2011},
}

@online{amazon_web_services_shared_2025,
  author = {{Amazon Web Services}},
  title  = {{Shared Responsibility Model}},
  year   = {2025},
  url    = {https://aws.amazon.com/compliance/shared-responsibility-model/}
}

@report{amazon_web_services_aws_2024,
	title = {{AWS} Well-Architected Framework: Security Pillar},
	url = {https://docs.aws.amazon.com/wellarchitected/latest/security-pillar/welcome.html},
	institution = {Amazon Web Services},
	author = {{Amazon Web Services}},
	date = {2024},
}

@inproceedings{de_carne_de_carnavalet_assessing_2021,
	title = {Assessing the Effectiveness of the Shared Responsibility Model for Cloud Databases: the Case of Google's Firebase},
	url = {https://ieeexplore.ieee.org/document/9592496/},
	doi = {10.1109/IC2E52221.2021.00023},
	pages = {123--134},
	booktitle = {2021 {IEEE} International Conference on Cloud Engineering ({IC}2E)},
	author = {de Carné de Carnavalet, Xavier and Samir, Mohamed and Uluagac, A. Selcuk and Mohaisen, Aziz},
	date = {2021},
}

@report{us_dod_cybersecurity_and_infrastructure_security_uphold_2024,
	title = {Uphold the Cloud Shared Responsibility Model},
	url = {https://media.defense.gov/2024/Mar/07/2003407863/-1/-1/0/CSI-CloudTop10-Shared-Responsibility-Model.PDF},
	institution = {Department of Defense},
	author = {{U.S. DoD Cybersecurity and Infrastructure Security}},
	date = {2024},
}

@report{etsi_etsi_2022,
	title = {{ETSI} {TR} 103 305-4 (V3.1.1): Critical Security Controls—Mappings and Navigation},
	url = {https://www.etsi.org/deliver/etsi_tr/103300_103399/10330504/03.01.01_60/tr_10330504v030101p.pdf},
	institution = {{ETSI}},
	author = {{ETSI}},
	date = {2022},
}

@misc{dash_zero-trust_2024-1,
	title = {Zero-Trust Architecture ({ZTA}): Designing an {AI}-Powered Cloud Security Framework for {LLMs}' Black Box Problems},
	url = {https://papers.ssrn.com/abstract=4726625},
	author = {Dash, Biswajit},
	date = {2024},
	doi = {10.2139/ssrn.4726625},
}

@report{amazon_web_services_aws_2024-1,
	title = {{AWS} Well-Architected Framework},
	url = {https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html},
	institution = {Amazon Web Services, Inc.},
	author = {{Amazon Web Services}},
	date = {2024},
}

@misc{flexera_flexera_2024,
	title = {Flexera 2024 State of the Cloud Report},
	url = {https://info.flexera.com/CM-REPORT-State-of-the-Cloud},
	author = {{Flexera}},
	date = {2024},
}

@misc{microsoft_what_2024,
	title = {What is Azure {OpenAI} Service?},
	url = {https://learn.microsoft.com/en-us/azure/ai-services/openai/overview},
	publisher = {Microsoft Learn},
	author = {{Microsoft}},
	urldate = {2025-09-13},
	date = {2024},
}

@article{hevner_design_2004-1,
	title = {Design Science in Information Systems Research},
	volume = {28},
	issn = {0276-7783},
	doi = {10.2307/25148625},
	pages = {75--105},
	number = {1},
	journaltitle = {{MIS} Quarterly},
	author = {Hevner, Alan R. and March, Salvatore T. and Park, Jinsoo and Ram, Sudha},
	date = {2004},
}

@misc{the_opa_authors_open_2025,
	title = {Open Policy Agent Documentation},
	url = {https://www.openpolicyagent.org/docs/latest/},
	author = {{The OPA Authors}},
	date = {2025},
}

@inproceedings{ouyang_training_2022-1,
	title = {Training language models to follow instructions with human feedback},
	volume = {35},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf},
	pages = {27730--27744},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L. and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
	editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
	date = {2022},
}
